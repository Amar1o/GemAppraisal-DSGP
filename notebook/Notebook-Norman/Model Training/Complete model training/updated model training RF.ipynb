{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f49aecf1-26b6-4146-8eeb-b1b7e2ba35c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Hamming Loss: 3.5790660427161534e-05\n",
      "Training Precision: 0.9993629655117898\n",
      "Training Recall: 0.9999860416424334\n",
      "Training F1 Score: 0.9996744064895438\n",
      "Training Subset Accuracy: 0.9980923577992323\n",
      "\n",
      "Validation Hamming Loss: 0.01468281982641476\n",
      "Validation Precision: 0.8853058608237838\n",
      "Validation Recall: 0.8418350373963314\n",
      "Validation F1 Score: 0.8630233853205868\n",
      "Validation Subset Accuracy: 0.5436600714194322\n",
      "\n",
      "Testing Hamming Loss: 0.01472026412995337\n",
      "Testing Precision: 0.8850608842129306\n",
      "Testing Recall: 0.8413543221604017\n",
      "Testing F1 Score: 0.8626543574902081\n",
      "Testing Subset Accuracy: 0.5420952639435473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applied class weight for class imbalance\n",
    "# Applied threashold of 0.4\n",
    "# used multi-output classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, hamming_loss, precision_score, recall_score, f1_score\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "file_path = r\"C:\\Users\\Muralish\\Desktop\\Sapphires_Cleaned\\combine\\final_combined_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = df.iloc[:, 92:120].values  # Features\n",
    "y = df.iloc[:, 1:92].values  # Targets (binary multi-label data)\n",
    "\n",
    "# First split: Separate test set (30%)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Second split: Separate train and validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Compute class weights for each label\n",
    "class_weights = []\n",
    "for i in range(y.shape[1]):  # Loop through each label column\n",
    "    unique_classes = np.unique(y_train[:, i])\n",
    "    if len(unique_classes) > 1:  # Avoid errors with single-class labels\n",
    "        class_weight = compute_class_weight(class_weight='balanced', classes=unique_classes, y=y_train[:, i])\n",
    "        class_weights.append(dict(zip(unique_classes, class_weight)))\n",
    "    else:\n",
    "        class_weights.append(None)  # No weight needed if only one class is present\n",
    "\n",
    "# Initialize MultiOutputClassifier with RandomForestClassifier\n",
    "multi_output_model = MultiOutputClassifier(RandomForestClassifier(random_state=42), n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "multi_output_model.fit(X_train, y_train)\n",
    "\n",
    "# Function to apply a probability threshold (0.4) and evaluate\n",
    "def evaluate_model(X, y, dataset_name, threshold=0.4):\n",
    "    y_pred_probs = []\n",
    "    \n",
    "    # Loop through each label classifier\n",
    "    for i, clf in enumerate(multi_output_model.estimators_):\n",
    "        try:\n",
    "            proba = clf.predict_proba(X)  # Get probabilities for label i\n",
    "            if proba.shape[1] == 2:  # Binary classification check\n",
    "                y_pred_probs.append(proba[:, 1] >= threshold)  # Apply threshold for class 1\n",
    "            else:\n",
    "                y_pred_probs.append(proba.argmax(axis=1))  # Use argmax if multi-class\n",
    "        except AttributeError:\n",
    "            y_pred_probs.append(clf.predict(X))  # Fallback for classifiers without predict_proba\n",
    "    \n",
    "    y_pred = np.array(y_pred_probs).T.astype(int)  # Convert to int and transpose\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    hamming = hamming_loss(y, y_pred)\n",
    "    precision = precision_score(y, y_pred, average='micro', zero_division=0)\n",
    "    recall = recall_score(y, y_pred, average='micro', zero_division=0)\n",
    "    f1 = f1_score(y, y_pred, average='micro', zero_division=0)\n",
    "    subset_accuracy = accuracy_score(y, y_pred)\n",
    "\n",
    "    print(f\"{dataset_name} Hamming Loss: {hamming}\")\n",
    "    print(f\"{dataset_name} Precision: {precision}\")\n",
    "    print(f\"{dataset_name} Recall: {recall}\")\n",
    "    print(f\"{dataset_name} F1 Score: {f1}\")\n",
    "    print(f\"{dataset_name} Subset Accuracy: {subset_accuracy}\")\n",
    "    print()\n",
    "\n",
    "# Evaluate on training, validation, and test sets\n",
    "evaluate_model(X_train, y_train, \"Training\")\n",
    "evaluate_model(X_val, y_val, \"Validation\")\n",
    "evaluate_model(X_test, y_test, \"Testing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "763c185e-ec37-4ecd-b1c4-a00162ae7003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Hamming Loss: 1.712838749014159e-05\n",
      "Training Precision: 0.9998697153279916\n",
      "Training Recall: 0.9998185413516343\n",
      "Training F1 Score: 0.999844127685017\n",
      "Training Subset Accuracy: 0.9995696173083634\n",
      "\n",
      "Validation Hamming Loss: 0.015945192865317093\n",
      "Validation Precision: 0.9265006010791468\n",
      "Validation Recall: 0.7709576485093811\n",
      "Validation F1 Score: 0.8416027020678184\n",
      "Validation Subset Accuracy: 0.47914994591199356\n",
      "\n",
      "Testing Hamming Loss: 0.015978281455279693\n",
      "Testing Precision: 0.9262761219595752\n",
      "Testing Recall: 0.770522458949654\n",
      "Testing F1 Score: 0.8412507685811437\n",
      "Testing Subset Accuracy: 0.4760483104898901\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applied class weight for class imbalance\n",
    "# Applied threashold of 0.5\n",
    "# used multi-output classifier\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, hamming_loss, precision_score, recall_score, f1_score\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "file_path = r\"C:\\Users\\Muralish\\Desktop\\Sapphires_Cleaned\\combine\\final_combined_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = df.iloc[:, 92:120].values  # Features\n",
    "y = df.iloc[:, 1:92].values  # Targets (binary multi-label data)\n",
    "\n",
    "# First split: Separate test set (30%)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Second split: Separate train and validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Compute class weights for each label\n",
    "class_weights = []\n",
    "for i in range(y.shape[1]):  # Loop through each label column\n",
    "    unique_classes = np.unique(y_train[:, i])\n",
    "    if len(unique_classes) > 1:  # Avoid errors with single-class labels\n",
    "        class_weight = compute_class_weight(class_weight='balanced', classes=unique_classes, y=y_train[:, i])\n",
    "        class_weights.append(dict(zip(unique_classes, class_weight)))\n",
    "    else:\n",
    "        class_weights.append(None)  # No weight needed if only one class is present\n",
    "\n",
    "# Initialize MultiOutputClassifier with RandomForestClassifier\n",
    "multi_output_model = MultiOutputClassifier(RandomForestClassifier(random_state=42), n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "multi_output_model.fit(X_train, y_train)\n",
    "\n",
    "# Function to apply a probability threshold (0.4) and evaluate\n",
    "def evaluate_model(X, y, dataset_name, threshold=0.5):\n",
    "    y_pred_probs = []\n",
    "    \n",
    "    # Loop through each label classifier\n",
    "    for i, clf in enumerate(multi_output_model.estimators_):\n",
    "        try:\n",
    "            proba = clf.predict_proba(X)  # Get probabilities for label i\n",
    "            if proba.shape[1] == 2:  # Binary classification check\n",
    "                y_pred_probs.append(proba[:, 1] >= threshold)  # Apply threshold for class 1\n",
    "            else:\n",
    "                y_pred_probs.append(proba.argmax(axis=1))  # Use argmax if multi-class\n",
    "        except AttributeError:\n",
    "            y_pred_probs.append(clf.predict(X))  # Fallback for classifiers without predict_proba\n",
    "    \n",
    "    y_pred = np.array(y_pred_probs).T.astype(int)  # Convert to int and transpose\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    hamming = hamming_loss(y, y_pred)\n",
    "    precision = precision_score(y, y_pred, average='micro', zero_division=0)\n",
    "    recall = recall_score(y, y_pred, average='micro', zero_division=0)\n",
    "    f1 = f1_score(y, y_pred, average='micro', zero_division=0)\n",
    "    subset_accuracy = accuracy_score(y, y_pred)\n",
    "\n",
    "    print(f\"{dataset_name} Hamming Loss: {hamming}\")\n",
    "    print(f\"{dataset_name} Precision: {precision}\")\n",
    "    print(f\"{dataset_name} Recall: {recall}\")\n",
    "    print(f\"{dataset_name} F1 Score: {f1}\")\n",
    "    print(f\"{dataset_name} Subset Accuracy: {subset_accuracy}\")\n",
    "    print()\n",
    "\n",
    "# Evaluate on training, validation, and test sets\n",
    "evaluate_model(X_train, y_train, \"Training\")\n",
    "evaluate_model(X_val, y_val, \"Validation\")\n",
    "evaluate_model(X_test, y_test, \"Testing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe49b5f8-a104-4570-9ff0-a04d4546c73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Hamming Loss: 1.815097778806049e-05\n",
      "Training Precision: 0.9998697129030757\n",
      "Training Recall: 0.9997999302082121\n",
      "Training F1 Score: 0.9998348203380367\n",
      "Training Subset Accuracy: 0.9994998255205304\n",
      "\n",
      "Validation Hamming Loss: 0.016191889905118783\n",
      "Validation Precision: 0.9296866142089389\n",
      "Validation Recall: 0.7630154354375313\n",
      "Validation F1 Score: 0.8381454218824067\n",
      "Validation Subset Accuracy: 0.46719242535273525\n",
      "\n",
      "Testing Hamming Loss: 0.016214644359575828\n",
      "Testing Precision: 0.9295927009037859\n",
      "Testing Recall: 0.7626570769439543\n",
      "Testing F1 Score: 0.8378910268452173\n",
      "Testing Subset Accuracy: 0.4641606730899715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applied class weight for class imbalance\n",
    "# No threashold\n",
    "# used multi-output classifier\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, hamming_loss, precision_score, recall_score, f1_score\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "file_path = r\"C:\\Users\\Muralish\\Desktop\\Sapphires_Cleaned\\combine\\final_combined_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = df.iloc[:, 92:120].values  # Features\n",
    "y = df.iloc[:, 1:92].values  # Targets (binary multi-label data)\n",
    "\n",
    "# First split: Separate test set (30%)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Second split: Separate train and validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Compute class weights for each label\n",
    "class_weights = []\n",
    "for i in range(y.shape[1]):  # Loop through each label column\n",
    "    class_weight = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(y_train[:, i]),\n",
    "        y=y_train[:, i]\n",
    "    )\n",
    "    class_weights.append(dict(enumerate(class_weight)))\n",
    "\n",
    "# Create a list of RandomForestClassifiers with corresponding class weights\n",
    "rf_models = [\n",
    "    RandomForestClassifier(random_state=42, class_weight=class_weights[i])\n",
    "    for i in range(y.shape[1])\n",
    "]\n",
    "\n",
    "# Initialize MultiOutputClassifier with the list of weighted RandomForestClassifiers\n",
    "multi_output_model = MultiOutputClassifier(estimator=RandomForestClassifier(random_state=42), n_jobs=-1)\n",
    "\n",
    "# Fit the MultiOutputClassifier (weights are applied within individual classifiers)\n",
    "multi_output_model.fit(X_train, y_train)\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(X, y, dataset_name):\n",
    "    y_pred = multi_output_model.predict(X)\n",
    "    hamming = hamming_loss(y, y_pred)\n",
    "    precision = precision_score(y, y_pred, average='micro')\n",
    "    recall = recall_score(y, y_pred, average='micro')\n",
    "    f1 = f1_score(y, y_pred, average='micro')\n",
    "    subset_accuracy = accuracy_score(y, y_pred)\n",
    "    print(f\"{dataset_name} Hamming Loss: {hamming}\")\n",
    "    print(f\"{dataset_name} Precision: {precision}\")\n",
    "    print(f\"{dataset_name} Recall: {recall}\")\n",
    "    print(f\"{dataset_name} F1 Score: {f1}\")\n",
    "    print(f\"{dataset_name} Subset Accuracy: {subset_accuracy}\")\n",
    "    print()\n",
    "\n",
    "# Evaluate on training, validation, and test sets\n",
    "evaluate_model(X_train, y_train, \"Training\")\n",
    "evaluate_model(X_val, y_val, \"Validation\")\n",
    "evaluate_model(X_test, y_test, \"Testing\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
