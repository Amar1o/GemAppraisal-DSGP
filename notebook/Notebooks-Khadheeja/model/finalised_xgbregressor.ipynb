{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>total_price</th>\n",
       "      <th>carat</th>\n",
       "      <th>price_per_carat</th>\n",
       "      <th>color</th>\n",
       "      <th>shape</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>clarity</th>\n",
       "      <th>cut</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>origin</th>\n",
       "      <th>treatment</th>\n",
       "      <th>cut_quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blue Sapphire</td>\n",
       "      <td>300</td>\n",
       "      <td>0.96</td>\n",
       "      <td>313.0</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Cushion</td>\n",
       "      <td>8.17</td>\n",
       "      <td>5.26</td>\n",
       "      <td>2.49</td>\n",
       "      <td>Very Slightly Included</td>\n",
       "      <td>Mixed Brilliant</td>\n",
       "      <td>Intense</td>\n",
       "      <td>Nigeria</td>\n",
       "      <td>No Enhancement</td>\n",
       "      <td>Fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blue Sapphire</td>\n",
       "      <td>300</td>\n",
       "      <td>0.75</td>\n",
       "      <td>400.0</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Oval</td>\n",
       "      <td>5.74</td>\n",
       "      <td>4.47</td>\n",
       "      <td>3.73</td>\n",
       "      <td>Very Slightly Included</td>\n",
       "      <td>Emerald Cut</td>\n",
       "      <td>Vivid</td>\n",
       "      <td>Ceylon (Sri Lanka)</td>\n",
       "      <td>Heated</td>\n",
       "      <td>Fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Blue Sapphire</td>\n",
       "      <td>300</td>\n",
       "      <td>0.75</td>\n",
       "      <td>400.0</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Emerald Cut</td>\n",
       "      <td>6.00</td>\n",
       "      <td>4.33</td>\n",
       "      <td>2.87</td>\n",
       "      <td>Slightly Included</td>\n",
       "      <td>Mixed Brilliant</td>\n",
       "      <td>Medium Intense</td>\n",
       "      <td>Ceylon (Sri Lanka)</td>\n",
       "      <td>No Enhancement</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blue Sapphire</td>\n",
       "      <td>300</td>\n",
       "      <td>0.60</td>\n",
       "      <td>500.0</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Asscher - Octagon</td>\n",
       "      <td>4.97</td>\n",
       "      <td>4.90</td>\n",
       "      <td>2.78</td>\n",
       "      <td>Very Slightly Included</td>\n",
       "      <td>Asscher</td>\n",
       "      <td>Vivid</td>\n",
       "      <td>Ceylon (Sri Lanka)</td>\n",
       "      <td>Heated</td>\n",
       "      <td>Fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blue Sapphire</td>\n",
       "      <td>300</td>\n",
       "      <td>0.60</td>\n",
       "      <td>500.0</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Asscher - Octagon</td>\n",
       "      <td>4.78</td>\n",
       "      <td>4.77</td>\n",
       "      <td>2.97</td>\n",
       "      <td>Very Slightly Included</td>\n",
       "      <td>Asscher</td>\n",
       "      <td>Intense</td>\n",
       "      <td>Ceylon (Sri Lanka)</td>\n",
       "      <td>Heated</td>\n",
       "      <td>Fair</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            type  total_price  carat  price_per_carat color  \\\n",
       "0  Blue Sapphire          300   0.96            313.0  Blue   \n",
       "1  Blue Sapphire          300   0.75            400.0  Blue   \n",
       "2  Blue Sapphire          300   0.75            400.0  Blue   \n",
       "3  Blue Sapphire          300   0.60            500.0  Blue   \n",
       "4  Blue Sapphire          300   0.60            500.0  Blue   \n",
       "\n",
       "               shape  length  width  height                 clarity  \\\n",
       "0            Cushion    8.17   5.26    2.49  Very Slightly Included   \n",
       "1               Oval    5.74   4.47    3.73  Very Slightly Included   \n",
       "2        Emerald Cut    6.00   4.33    2.87       Slightly Included   \n",
       "3  Asscher - Octagon    4.97   4.90    2.78  Very Slightly Included   \n",
       "4  Asscher - Octagon    4.78   4.77    2.97  Very Slightly Included   \n",
       "\n",
       "               cut color_intensity              origin       treatment  \\\n",
       "0  Mixed Brilliant         Intense             Nigeria  No Enhancement   \n",
       "1      Emerald Cut           Vivid  Ceylon (Sri Lanka)          Heated   \n",
       "2  Mixed Brilliant  Medium Intense  Ceylon (Sri Lanka)  No Enhancement   \n",
       "3          Asscher           Vivid  Ceylon (Sri Lanka)          Heated   \n",
       "4          Asscher         Intense  Ceylon (Sri Lanka)          Heated   \n",
       "\n",
       "  cut_quality  \n",
       "0        Fair  \n",
       "1        Fair  \n",
       "2        Good  \n",
       "3        Fair  \n",
       "4        Fair  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"full_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = df.drop(['length', 'width', 'height'], axis='columns')\n",
    "X = df[['carat','price_per_carat', 'color', 'shape', 'clarity', 'cut', 'color_intensity', 'origin', 'treatment','cut_quality','type']]\n",
    "y = df['total_price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carat                      float64\n",
      "cut_quality_encoded        float64\n",
      "shape_encoded              float64\n",
      "origin_encoded             float64\n",
      "color_encoded              float64\n",
      "color_intensity_encoded    float64\n",
      "clarity_encoded            float64\n",
      "cut_encoded                float64\n",
      "treatment_encoded          float64\n",
      "type_encoded               float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "oe = OrdinalEncoder(categories=[['Poor', 'Fair', 'Good','Very Good','Excellent']])\n",
    "X_train['cut_quality_encoded'] = oe.fit_transform(X_train[['cut_quality']])\n",
    "X_test['cut_quality_encoded'] = oe.transform(X_test[['cut_quality']])\n",
    "\n",
    "# Handle target\n",
    "type_mean = X_train.groupby('type')['price_per_carat'].mean()\n",
    "shape_means = X_train.groupby('shape')['price_per_carat'].mean()\n",
    "origin_means = X_train.groupby('origin')['price_per_carat'].mean()\n",
    "color_means = X_train.groupby('color')['price_per_carat'].mean()\n",
    "color_intensity_means = X_train.groupby('color_intensity')['price_per_carat'].mean()\n",
    "clarity_means = X_train.groupby('clarity')['price_per_carat'].mean()\n",
    "treatment_means = X_train.groupby('treatment')['price_per_carat'].mean()\n",
    "cut_means = X_train.groupby('cut')['price_per_carat'].mean()\n",
    "\n",
    "# Map target encoding to the training data\n",
    "X_train['shape_encoded'] = X_train['shape'].map(shape_means)\n",
    "X_train['origin_encoded'] = X_train['origin'].map(origin_means)\n",
    "X_train['color_encoded'] = X_train['color'].map(color_means)\n",
    "X_train['color_intensity_encoded'] = X_train['color_intensity'].map(color_intensity_means)\n",
    "X_train['clarity_encoded'] = X_train['clarity'].map(clarity_means)\n",
    "X_train['cut_encoded'] = X_train['cut'].map(cut_means)\n",
    "X_train['treatment_encoded'] = X_train['treatment'].map(treatment_means)\n",
    "X_train['type_encoded'] = X_train['type'].map(type_mean)\n",
    "\n",
    "# Map target encoding to the test data\n",
    "# Handle unseen categories by filling with global mean\n",
    "global_mean = X_train['price_per_carat'].mean()\n",
    "X_test['shape_encoded'] = X_test['shape'].map(shape_means).fillna(global_mean)\n",
    "X_test['origin_encoded'] = X_test['origin'].map(origin_means).fillna(global_mean)\n",
    "X_test['color_encoded'] = X_test['color'].map(color_means).fillna(global_mean)\n",
    "X_test['color_intensity_encoded'] = X_test['color_intensity'].map(color_intensity_means).fillna(global_mean)\n",
    "X_test['clarity_encoded'] = X_test['clarity'].map(clarity_means).fillna(global_mean)\n",
    "X_test['cut_encoded'] = X_test['cut'].map(cut_means).fillna(global_mean)\n",
    "X_test['treatment_encoded'] = X_test['treatment'].map(treatment_means).fillna(global_mean)\n",
    "X_test['type_encoded'] = X_test['type'].map(type_mean).fillna(global_mean)\n",
    "\n",
    "X_train = X_train.drop(columns=['price_per_carat', 'color', 'shape', 'color_intensity', 'origin', 'cut', 'treatment', 'clarity','cut_quality','type'])\n",
    "X_test = X_test.drop(columns=['price_per_carat', 'color', 'shape', 'color_intensity', 'origin', 'cut', 'treatment', 'clarity','cut_quality','type'])\n",
    "print(X_train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Poor': 0, 'Fair': 1, 'Good': 2, 'Very Good': 3, 'Excellent': 4}\n",
      "Shape Mapping: {'Asscher - Octagon': 1926.2276000000002, 'Cushion': 2776.0080550458715, 'Emerald Cut': 2085.432578125, 'Fancy': 1275.3796296296296, 'Heart': 2952.6014835164833, 'Marquise': 2341.0526315789475, 'Oval': 2482.8079529529527, 'Pear': 2304.0555650684933, 'Princess': 1348.6153846153845, 'Radiant': 1483.020996978852, 'Round': 2118.0156686290998, 'Trillion': 1054.6752136752136}\n",
      "Global Mean: 2335.5366704130374\n"
     ]
    }
   ],
   "source": [
    "# OrdinalEncoder mapping\n",
    "cut_quality_mapping = {category: idx for idx, category in enumerate(oe.categories_[0])}\n",
    "print(cut_quality_mapping)\n",
    "\n",
    "# Store target encoding mappings\n",
    "shape_mapping = shape_means.to_dict()\n",
    "origin_mapping = origin_means.to_dict()\n",
    "color_mapping = color_means.to_dict()\n",
    "color_intensity_mapping = color_intensity_means.to_dict()\n",
    "clarity_mapping = clarity_means.to_dict()\n",
    "treatment_mapping = treatment_means.to_dict()\n",
    "cut_mapping = cut_means.to_dict()\n",
    "type_mapping = type_mean.to_dict()\n",
    "\n",
    "# Print one mapping as an example\n",
    "print(\"Shape Mapping:\", shape_mapping)\n",
    "\n",
    "# Store global mean\n",
    "global_mean_value = global_mean\n",
    "print(\"Global Mean:\", global_mean_value)\n",
    "\n",
    "# Combine all mappings into a dictionary\n",
    "all_mappings = {\n",
    "    \"cut_quality_mapping\": cut_quality_mapping,\n",
    "    \"shape_mapping\": shape_mapping,\n",
    "    \"origin_mapping\": origin_mapping,\n",
    "    \"color_mapping\": color_mapping,\n",
    "    \"color_intensity_mapping\": color_intensity_mapping,\n",
    "    \"clarity_mapping\": clarity_mapping,\n",
    "    \"treatment_mapping\": treatment_mapping,\n",
    "    \"cut_mapping\": cut_mapping,\n",
    "    \"type_mapping\": type_mapping,\n",
    "    \"global_mean\": global_mean_value,\n",
    "}\n",
    "\n",
    "# Save as a JSON file\n",
    "with open(\"encoded_features.json\", \"w\") as file:\n",
    "    json.dump(all_mappings, file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Gradient Booster-------\n",
      "r2_score is 0.8973613064869609\n",
      "r2_score for training is 0.9667103724790951\n",
      "mean_squared_error is== 16973274.7744309\n",
      "root_mean_squared_error is== 4119.863441235753\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "import xgboost\n",
    "from sklearn.metrics import *\n",
    "model = XGBRegressor(\n",
    "    n_estimators=20,\n",
    "    random_state=42,\n",
    "    learning_rate=0.4\n",
    "    )\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "y_predict_train = model.predict(X_train)\n",
    "\n",
    "# Predicting the accuracy score for Gradient Booster\n",
    "score=r2_score(y_test, y_predict)\n",
    "score_train = r2_score(y_train, y_predict_train)\n",
    "print('-------Gradient Booster-------')\n",
    "print('r2_score is', score)\n",
    "print('r2_score for training is', score_train)\n",
    "print('mean_squared_error is==', mean_squared_error(y_test,y_predict))\n",
    "print('root_mean_squared_error is==',np.sqrt(mean_squared_error(y_test, y_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model to a pickle file\n",
    "with open(\"xgb_price_predict_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(\"Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Gradient Booster-------\n",
      "r2_score is 0.9069142515687254\n",
      "r2_score for training is 0.966839810970065\n",
      "mean_squared_error is== 15393512.247959943\n",
      "root_mean_squared_error is== 3923.4566708401335\n",
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "import xgboost\n",
    "from sklearn.metrics import *\n",
    "import numpy as np\n",
    "\n",
    "# Log transform the target variable\n",
    "y_train_sqrt = np.sqrt(y_train)\n",
    "\n",
    "model = XGBRegressor(\n",
    "    n_estimators=20,\n",
    "    random_state=42,\n",
    "    learning_rate=0.4\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train_sqrt)\n",
    "\n",
    "# Predict and reverse the square root transformation\n",
    "y_predict_sqrt = model.predict(X_test)\n",
    "y_predict = np.square(y_predict_sqrt)\n",
    "\n",
    "# Evaluate the model\n",
    "score = r2_score(y_test, y_predict)\n",
    "score_train = r2_score(y_train, np.square(model.predict(X_train)))\n",
    "print('-------Gradient Booster-------')\n",
    "print('r2_score is', score)\n",
    "print('r2_score for training is', score_train)\n",
    "print('mean_squared_error is==', mean_squared_error(y_test, y_predict))\n",
    "print('root_mean_squared_error is==', np.sqrt(mean_squared_error(y_test, y_predict)))\n",
    "\n",
    "# Save the trained model to a pickle file\n",
    "with open(\"xgb_price_predict_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(\"Model saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
