{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYVDrLeFfPjK",
        "outputId": "845ee1ce-5ccf-4db4-8cd4-d0a6f2e41663"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/multiclass.py:90: UserWarning: Label not 23 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/multiclass.py:90: UserWarning: Label not 81 is present in all training examples.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Hamming Loss: 1.8534449149780078e-05\n",
            "Training Precision: 0.9997325177061649\n",
            "Training Recall: 0.999930208212167\n",
            "Training F1 Score: 0.999831353187134\n",
            "Training Subset Accuracy: 0.9993718739095033\n",
            "\n",
            "Validation Hamming Loss: 0.016816174020347522\n",
            "Validation Precision: 0.9300840859545313\n",
            "Validation Recall: 0.7503506996545347\n",
            "Validation F1 Score: 0.8306055678091478\n",
            "Validation Subset Accuracy: 0.43691477358644193\n",
            "\n",
            "Testing Hamming Loss: 0.01688138161200992\n",
            "Testing Precision: 0.9288986123853596\n",
            "Testing Recall: 0.7501804858189713\n",
            "Testing F1 Score: 0.8300283328653731\n",
            "Testing Subset Accuracy: 0.4352422309675668\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, hamming_loss, precision_score, recall_score, f1_score\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Updated file path\n",
        "file_path = r\"/content/final_combined_data.csv\"\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Split data into features (X) and target (y)\n",
        "X = df.iloc[:, 92:120].values  # Features\n",
        "y = df.iloc[:, 1:92].values  # Targets (binary multi-label data)\n",
        "\n",
        "\n",
        "\n",
        "# First split: Separate test set (30%) from the rest (70% for train + validate)\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Second split: Separate train set (50%) and validation set (20% of the remaining 70%)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Initialize RandomForestClassifier with class balancing\n",
        "rf_model = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
        "\n",
        "# Use OneVsRestClassifier for multi-label classification\n",
        "model = OneVsRestClassifier(rf_model)\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the training, validation, and testing sets\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_val_pred = model.predict(X_val)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics for training data\n",
        "train_hamming = hamming_loss(y_train, y_train_pred)\n",
        "train_precision = precision_score(y_train, y_train_pred, average='micro')\n",
        "train_recall = recall_score(y_train, y_train_pred, average='micro')\n",
        "train_f1 = f1_score(y_train, y_train_pred, average='micro')\n",
        "train_subset_accuracy = accuracy_score(y_train, y_train_pred)  # Subset accuracy for training\n",
        "\n",
        "# Calculate metrics for validation data\n",
        "val_hamming = hamming_loss(y_val, y_val_pred)\n",
        "val_precision = precision_score(y_val, y_val_pred, average='micro')\n",
        "val_recall = recall_score(y_val, y_val_pred, average='micro')\n",
        "val_f1 = f1_score(y_val, y_val_pred, average='micro')\n",
        "val_subset_accuracy = accuracy_score(y_val, y_val_pred)  # Subset accuracy for validation\n",
        "\n",
        "# Calculate metrics for testing data\n",
        "test_hamming = hamming_loss(y_test, y_test_pred)\n",
        "test_precision = precision_score(y_test, y_test_pred, average='micro')\n",
        "test_recall = recall_score(y_test, y_test_pred, average='micro')\n",
        "test_f1 = f1_score(y_test, y_test_pred, average='micro')\n",
        "test_subset_accuracy = accuracy_score(y_test, y_test_pred)  # Subset accuracy for testing\n",
        "\n",
        "# Print overall metrics\n",
        "print(f\"Training Hamming Loss: {train_hamming}\")\n",
        "print(f\"Training Precision: {train_precision}\")\n",
        "print(f\"Training Recall: {train_recall}\")\n",
        "print(f\"Training F1 Score: {train_f1}\")\n",
        "print(f\"Training Subset Accuracy: {train_subset_accuracy}\")\n",
        "print()\n",
        "\n",
        "print(f\"Validation Hamming Loss: {val_hamming}\")\n",
        "print(f\"Validation Precision: {val_precision}\")\n",
        "print(f\"Validation Recall: {val_recall}\")\n",
        "print(f\"Validation F1 Score: {val_f1}\")\n",
        "print(f\"Validation Subset Accuracy: {val_subset_accuracy}\")\n",
        "print()\n",
        "\n",
        "print(f\"Testing Hamming Loss: {test_hamming}\")\n",
        "print(f\"Testing Precision: {test_precision}\")\n",
        "print(f\"Testing Recall: {test_recall}\")\n",
        "print(f\"Testing F1 Score: {test_f1}\")\n",
        "print(f\"Testing Subset Accuracy: {test_subset_accuracy}\")\n",
        "\n",
        "\n"
      ]
    }
  ]
}