{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/Final_reverse_One_hot_encoded_Processed_data.csv\")\n",
        "\n",
        "# Identify all one-hot encoded columns dynamically\n",
        "target_columns = ['clarity', 'color', 'cut']\n",
        "\n",
        "# Drop all one-hot encoded target columns\n",
        "X = df.drop(columns=target_columns)\n",
        "\n",
        "# OneHotEncode the original target labels\n",
        "encoder = OneHotEncoder(sparse_output=False)  # ✅ Corrected argument\n",
        "\n",
        "y_clarity = encoder.fit_transform(df[[\"clarity\"]])\n",
        "y_color = encoder.fit_transform(df[[\"color\"]])\n",
        "y_cut = encoder.fit_transform(df[[\"cut\"]])\n",
        "\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_clarity_train, y_clarity_test, y_color_train, y_color_test, y_cut_train, y_cut_test = train_test_split(\n",
        "    X, y_clarity, y_color, y_cut, test_size=0.4, random_state=42\n",
        ")\n",
        "\n",
        "X_val, X_test, y_clarity_val, y_clarity_test, y_color_val, y_color_test, y_cut_val, y_cut_test = train_test_split(\n",
        "    X_test, y_clarity_test, y_color_test, y_cut_test, test_size=0.5, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert labels to NumPy arrays (without resampling)\n",
        "Y_clarity_train_array = np.array(y_clarity_train)\n",
        "Y_color_train_array = np.array(y_color_train)\n",
        "Y_cut_train_array = np.array(y_cut_train)\n",
        "\n",
        "Y_clarity_val_array = np.array(y_clarity_val)\n",
        "Y_color_val_array = np.array(y_color_val)\n",
        "Y_cut_val_array = np.array(y_cut_val)\n",
        "\n",
        "Y_clarity_test_array = np.array(y_clarity_test)\n",
        "Y_color_test_array = np.array(y_color_test)\n",
        "Y_cut_test_array = np.array(y_cut_test)\n",
        "\n",
        "\n",
        "\n",
        "# Define the model\n",
        "input_layer = keras.Input(shape=(X_train_scaled.shape[1],))\n",
        "\n",
        "# Shared hidden layers\n",
        "x = layers.Dense(128, activation=\"relu\")(input_layer)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Dense(256, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Dense(128, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "\n",
        "# Output layers\n",
        "clarity_output = layers.Dense(Y_clarity_train_array.shape[1], activation=\"softmax\", name=\"clarity\")(x)\n",
        "color_output = layers.Dense(Y_color_train_array.shape[1], activation=\"softmax\", name=\"color\")(x)\n",
        "cut_output = layers.Dense(Y_cut_train_array.shape[1], activation=\"softmax\", name=\"cut\")(x)\n",
        "\n",
        "# Compile the model\n",
        "model = keras.Model(inputs=input_layer, outputs=[clarity_output, color_output, cut_output])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss={\n",
        "        'clarity': 'categorical_crossentropy',\n",
        "        'color': 'categorical_crossentropy',\n",
        "        'cut': 'categorical_crossentropy'\n",
        "    },\n",
        "    metrics={\n",
        "        'clarity': 'accuracy',\n",
        "        'color': 'accuracy',\n",
        "        'cut': 'accuracy'\n",
        "    }\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train_scaled,\n",
        "    {\"clarity\": Y_clarity_train_array, \"color\": Y_color_train_array, \"cut\": Y_cut_train_array},\n",
        "    validation_data=(X_val_scaled, {\"clarity\": Y_clarity_val_array, \"color\": Y_color_val_array, \"cut\": Y_cut_val_array}),\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "Y_test_pred = model.predict(X_test_scaled)\n",
        "Y_test_pred = [np.argmax(pred, axis=1) for pred in Y_test_pred]  # Convert probabilities to class labels\n",
        "\n",
        "# Convert one-hot test labels back to class labels\n",
        "Y_test_true = [\n",
        "    np.argmax(Y_clarity_test_array, axis=1),\n",
        "    np.argmax(Y_color_test_array, axis=1),\n",
        "    np.argmax(Y_cut_test_array, axis=1)\n",
        "]\n",
        "\n",
        "# Generate classification reports\n",
        "for i, name in enumerate([\"Clarity\", \"Color\", \"Cut\"]):\n",
        "    print(f\"{name} Classification Report:\\n\", classification_report(Y_test_true[i], Y_test_pred[i]))\n",
        "\n",
        "# Save the model\n",
        "model.save(\"DNN_gemstone_quality_model.h5\")\n",
        "print(\"Model saved successfully.\")"
      ],
      "metadata": {
        "id": "-ZqDks1bXWse",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e6d9ac8c-21de-409a-a9f2-8d2fc56f507b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m226\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m29,056\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m33,024\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m32,896\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m8,256\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ clarity (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m260\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ color (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)             │          \u001b[38;5;34m1,820\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ cut (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │            \u001b[38;5;34m910\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">226</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">29,056</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ clarity (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ color (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,820</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ cut (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">910</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m106,222\u001b[0m (414.93 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">106,222</span> (414.93 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m106,222\u001b[0m (414.93 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">106,222</span> (414.93 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - clarity_accuracy: 0.4370 - clarity_loss: 1.1452 - color_accuracy: 0.2756 - color_loss: 2.1985 - cut_accuracy: 0.3597 - cut_loss: 1.6148 - loss: 4.9586 - val_clarity_accuracy: 0.5943 - val_clarity_loss: 0.7872 - val_color_accuracy: 0.3916 - val_color_loss: 1.6163 - val_cut_accuracy: 0.4255 - val_cut_loss: 1.3672 - val_loss: 3.7715\n",
            "Epoch 2/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - clarity_accuracy: 0.5837 - clarity_loss: 0.8111 - color_accuracy: 0.3821 - color_loss: 1.6473 - cut_accuracy: 0.4126 - cut_loss: 1.3825 - loss: 3.8408 - val_clarity_accuracy: 0.6180 - val_clarity_loss: 0.7526 - val_color_accuracy: 0.4120 - val_color_loss: 1.5155 - val_cut_accuracy: 0.4373 - val_cut_loss: 1.3483 - val_loss: 3.6171\n",
            "Epoch 3/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - clarity_accuracy: 0.6024 - clarity_loss: 0.7753 - color_accuracy: 0.3967 - color_loss: 1.5577 - cut_accuracy: 0.4223 - cut_loss: 1.3552 - loss: 3.6882 - val_clarity_accuracy: 0.6306 - val_clarity_loss: 0.7434 - val_color_accuracy: 0.4060 - val_color_loss: 1.4770 - val_cut_accuracy: 0.4275 - val_cut_loss: 1.3332 - val_loss: 3.5543\n",
            "Epoch 4/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - clarity_accuracy: 0.6128 - clarity_loss: 0.7653 - color_accuracy: 0.3988 - color_loss: 1.5266 - cut_accuracy: 0.4317 - cut_loss: 1.3352 - loss: 3.6270 - val_clarity_accuracy: 0.6403 - val_clarity_loss: 0.7458 - val_color_accuracy: 0.4237 - val_color_loss: 1.4577 - val_cut_accuracy: 0.4126 - val_cut_loss: 1.3255 - val_loss: 3.5296\n",
            "Epoch 5/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - clarity_accuracy: 0.6267 - clarity_loss: 0.7452 - color_accuracy: 0.4177 - color_loss: 1.4642 - cut_accuracy: 0.4343 - cut_loss: 1.3142 - loss: 3.5236 - val_clarity_accuracy: 0.6540 - val_clarity_loss: 0.7081 - val_color_accuracy: 0.4129 - val_color_loss: 1.4134 - val_cut_accuracy: 0.4492 - val_cut_loss: 1.2939 - val_loss: 3.4160\n",
            "Epoch 6/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - clarity_accuracy: 0.6327 - clarity_loss: 0.7368 - color_accuracy: 0.4205 - color_loss: 1.4420 - cut_accuracy: 0.4328 - cut_loss: 1.3130 - loss: 3.4918 - val_clarity_accuracy: 0.6625 - val_clarity_loss: 0.6924 - val_color_accuracy: 0.4301 - val_color_loss: 1.3771 - val_cut_accuracy: 0.4476 - val_cut_loss: 1.2792 - val_loss: 3.3493\n",
            "Epoch 7/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - clarity_accuracy: 0.6460 - clarity_loss: 0.7163 - color_accuracy: 0.4294 - color_loss: 1.4348 - cut_accuracy: 0.4472 - cut_loss: 1.2924 - loss: 3.4436 - val_clarity_accuracy: 0.6650 - val_clarity_loss: 0.6893 - val_color_accuracy: 0.4406 - val_color_loss: 1.3680 - val_cut_accuracy: 0.4215 - val_cut_loss: 1.2793 - val_loss: 3.3373\n",
            "Epoch 8/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - clarity_accuracy: 0.6532 - clarity_loss: 0.7109 - color_accuracy: 0.4309 - color_loss: 1.4134 - cut_accuracy: 0.4543 - cut_loss: 1.2706 - loss: 3.3949 - val_clarity_accuracy: 0.6661 - val_clarity_loss: 0.6803 - val_color_accuracy: 0.4465 - val_color_loss: 1.3580 - val_cut_accuracy: 0.4570 - val_cut_loss: 1.2702 - val_loss: 3.3092\n",
            "Epoch 9/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - clarity_accuracy: 0.6647 - clarity_loss: 0.6878 - color_accuracy: 0.4352 - color_loss: 1.3942 - cut_accuracy: 0.4579 - cut_loss: 1.2580 - loss: 3.3400 - val_clarity_accuracy: 0.6895 - val_clarity_loss: 0.6616 - val_color_accuracy: 0.4437 - val_color_loss: 1.3359 - val_cut_accuracy: 0.4220 - val_cut_loss: 1.2494 - val_loss: 3.2474\n",
            "Epoch 10/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - clarity_accuracy: 0.6774 - clarity_loss: 0.6700 - color_accuracy: 0.4316 - color_loss: 1.3635 - cut_accuracy: 0.4572 - cut_loss: 1.2426 - loss: 3.2761 - val_clarity_accuracy: 0.6899 - val_clarity_loss: 0.6659 - val_color_accuracy: 0.4397 - val_color_loss: 1.3482 - val_cut_accuracy: 0.4692 - val_cut_loss: 1.2428 - val_loss: 3.2575\n",
            "Epoch 11/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - clarity_accuracy: 0.6838 - clarity_loss: 0.6624 - color_accuracy: 0.4417 - color_loss: 1.3575 - cut_accuracy: 0.4601 - cut_loss: 1.2419 - loss: 3.2618 - val_clarity_accuracy: 0.7035 - val_clarity_loss: 0.6350 - val_color_accuracy: 0.4504 - val_color_loss: 1.3251 - val_cut_accuracy: 0.4641 - val_cut_loss: 1.2246 - val_loss: 3.1853\n",
            "Epoch 12/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - clarity_accuracy: 0.6895 - clarity_loss: 0.6503 - color_accuracy: 0.4520 - color_loss: 1.3451 - cut_accuracy: 0.4703 - cut_loss: 1.2181 - loss: 3.2135 - val_clarity_accuracy: 0.7036 - val_clarity_loss: 0.6231 - val_color_accuracy: 0.4514 - val_color_loss: 1.3049 - val_cut_accuracy: 0.4781 - val_cut_loss: 1.2095 - val_loss: 3.1382\n",
            "Epoch 13/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - clarity_accuracy: 0.6909 - clarity_loss: 0.6426 - color_accuracy: 0.4495 - color_loss: 1.3266 - cut_accuracy: 0.4786 - cut_loss: 1.2100 - loss: 3.1791 - val_clarity_accuracy: 0.6966 - val_clarity_loss: 0.6374 - val_color_accuracy: 0.4494 - val_color_loss: 1.3173 - val_cut_accuracy: 0.4794 - val_cut_loss: 1.2114 - val_loss: 3.1668\n",
            "Epoch 14/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - clarity_accuracy: 0.7070 - clarity_loss: 0.6256 - color_accuracy: 0.4549 - color_loss: 1.3092 - cut_accuracy: 0.4767 - cut_loss: 1.1952 - loss: 3.1300 - val_clarity_accuracy: 0.7176 - val_clarity_loss: 0.6093 - val_color_accuracy: 0.4529 - val_color_loss: 1.2884 - val_cut_accuracy: 0.4835 - val_cut_loss: 1.1960 - val_loss: 3.0943\n",
            "Epoch 15/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - clarity_accuracy: 0.7043 - clarity_loss: 0.6260 - color_accuracy: 0.4566 - color_loss: 1.3146 - cut_accuracy: 0.4759 - cut_loss: 1.1975 - loss: 3.1381 - val_clarity_accuracy: 0.7245 - val_clarity_loss: 0.6036 - val_color_accuracy: 0.4622 - val_color_loss: 1.2813 - val_cut_accuracy: 0.4899 - val_cut_loss: 1.1851 - val_loss: 3.0706\n",
            "Epoch 16/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - clarity_accuracy: 0.7145 - clarity_loss: 0.6095 - color_accuracy: 0.4611 - color_loss: 1.2983 - cut_accuracy: 0.4915 - cut_loss: 1.1737 - loss: 3.0815 - val_clarity_accuracy: 0.7328 - val_clarity_loss: 0.5898 - val_color_accuracy: 0.4651 - val_color_loss: 1.2730 - val_cut_accuracy: 0.4887 - val_cut_loss: 1.1775 - val_loss: 3.0408\n",
            "Epoch 17/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - clarity_accuracy: 0.7152 - clarity_loss: 0.6039 - color_accuracy: 0.4607 - color_loss: 1.2900 - cut_accuracy: 0.4844 - cut_loss: 1.1749 - loss: 3.0688 - val_clarity_accuracy: 0.7358 - val_clarity_loss: 0.5744 - val_color_accuracy: 0.4690 - val_color_loss: 1.2644 - val_cut_accuracy: 0.4924 - val_cut_loss: 1.1638 - val_loss: 3.0031\n",
            "Epoch 18/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - clarity_accuracy: 0.7253 - clarity_loss: 0.5893 - color_accuracy: 0.4738 - color_loss: 1.2754 - cut_accuracy: 0.4891 - cut_loss: 1.1593 - loss: 3.0240 - val_clarity_accuracy: 0.7462 - val_clarity_loss: 0.5612 - val_color_accuracy: 0.4610 - val_color_loss: 1.2511 - val_cut_accuracy: 0.4946 - val_cut_loss: 1.1558 - val_loss: 2.9685\n",
            "Epoch 19/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - clarity_accuracy: 0.7254 - clarity_loss: 0.5837 - color_accuracy: 0.4683 - color_loss: 1.2618 - cut_accuracy: 0.4903 - cut_loss: 1.1563 - loss: 3.0017 - val_clarity_accuracy: 0.7462 - val_clarity_loss: 0.5595 - val_color_accuracy: 0.4720 - val_color_loss: 1.2529 - val_cut_accuracy: 0.4604 - val_cut_loss: 1.1556 - val_loss: 2.9684\n",
            "Epoch 20/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - clarity_accuracy: 0.7374 - clarity_loss: 0.5701 - color_accuracy: 0.4686 - color_loss: 1.2579 - cut_accuracy: 0.4910 - cut_loss: 1.1457 - loss: 2.9738 - val_clarity_accuracy: 0.7516 - val_clarity_loss: 0.5549 - val_color_accuracy: 0.4775 - val_color_loss: 1.2428 - val_cut_accuracy: 0.4951 - val_cut_loss: 1.1476 - val_loss: 2.9459\n",
            "Epoch 21/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - clarity_accuracy: 0.7339 - clarity_loss: 0.5724 - color_accuracy: 0.4686 - color_loss: 1.2554 - cut_accuracy: 0.4984 - cut_loss: 1.1484 - loss: 2.9762 - val_clarity_accuracy: 0.7495 - val_clarity_loss: 0.5496 - val_color_accuracy: 0.4681 - val_color_loss: 1.2403 - val_cut_accuracy: 0.4912 - val_cut_loss: 1.1462 - val_loss: 2.9366\n",
            "Epoch 22/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - clarity_accuracy: 0.7398 - clarity_loss: 0.5569 - color_accuracy: 0.4741 - color_loss: 1.2489 - cut_accuracy: 0.5012 - cut_loss: 1.1357 - loss: 2.9415 - val_clarity_accuracy: 0.7556 - val_clarity_loss: 0.5423 - val_color_accuracy: 0.4718 - val_color_loss: 1.2327 - val_cut_accuracy: 0.5021 - val_cut_loss: 1.1353 - val_loss: 2.9108\n",
            "Epoch 23/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - clarity_accuracy: 0.7369 - clarity_loss: 0.5676 - color_accuracy: 0.4757 - color_loss: 1.2510 - cut_accuracy: 0.5018 - cut_loss: 1.1308 - loss: 2.9495 - val_clarity_accuracy: 0.7496 - val_clarity_loss: 0.5524 - val_color_accuracy: 0.4723 - val_color_loss: 1.2455 - val_cut_accuracy: 0.4955 - val_cut_loss: 1.1490 - val_loss: 2.9475\n",
            "Epoch 24/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - clarity_accuracy: 0.7464 - clarity_loss: 0.5489 - color_accuracy: 0.4763 - color_loss: 1.2329 - cut_accuracy: 0.5010 - cut_loss: 1.1274 - loss: 2.9092 - val_clarity_accuracy: 0.7580 - val_clarity_loss: 0.5276 - val_color_accuracy: 0.4766 - val_color_loss: 1.2277 - val_cut_accuracy: 0.5067 - val_cut_loss: 1.1275 - val_loss: 2.8833\n",
            "Epoch 25/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - clarity_accuracy: 0.7397 - clarity_loss: 0.5538 - color_accuracy: 0.4763 - color_loss: 1.2307 - cut_accuracy: 0.4993 - cut_loss: 1.1330 - loss: 2.9175 - val_clarity_accuracy: 0.7572 - val_clarity_loss: 0.5327 - val_color_accuracy: 0.4736 - val_color_loss: 1.2341 - val_cut_accuracy: 0.5015 - val_cut_loss: 1.1299 - val_loss: 2.8972\n",
            "Epoch 26/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - clarity_accuracy: 0.7493 - clarity_loss: 0.5391 - color_accuracy: 0.4752 - color_loss: 1.2348 - cut_accuracy: 0.5049 - cut_loss: 1.1194 - loss: 2.8933 - val_clarity_accuracy: 0.7635 - val_clarity_loss: 0.5327 - val_color_accuracy: 0.4797 - val_color_loss: 1.2310 - val_cut_accuracy: 0.5097 - val_cut_loss: 1.1292 - val_loss: 2.8934\n",
            "Epoch 27/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - clarity_accuracy: 0.7534 - clarity_loss: 0.5308 - color_accuracy: 0.4812 - color_loss: 1.2086 - cut_accuracy: 0.5063 - cut_loss: 1.1081 - loss: 2.8475 - val_clarity_accuracy: 0.7642 - val_clarity_loss: 0.5162 - val_color_accuracy: 0.4896 - val_color_loss: 1.2151 - val_cut_accuracy: 0.5107 - val_cut_loss: 1.1120 - val_loss: 2.8437\n",
            "Epoch 28/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - clarity_accuracy: 0.7544 - clarity_loss: 0.5318 - color_accuracy: 0.4806 - color_loss: 1.2203 - cut_accuracy: 0.5132 - cut_loss: 1.1074 - loss: 2.8596 - val_clarity_accuracy: 0.7709 - val_clarity_loss: 0.5053 - val_color_accuracy: 0.4882 - val_color_loss: 1.2105 - val_cut_accuracy: 0.5098 - val_cut_loss: 1.1174 - val_loss: 2.8336\n",
            "Epoch 29/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - clarity_accuracy: 0.7561 - clarity_loss: 0.5300 - color_accuracy: 0.4757 - color_loss: 1.2198 - cut_accuracy: 0.5091 - cut_loss: 1.1028 - loss: 2.8526 - val_clarity_accuracy: 0.7794 - val_clarity_loss: 0.5037 - val_color_accuracy: 0.4835 - val_color_loss: 1.2092 - val_cut_accuracy: 0.5164 - val_cut_loss: 1.1052 - val_loss: 2.8185\n",
            "Epoch 30/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - clarity_accuracy: 0.7574 - clarity_loss: 0.5197 - color_accuracy: 0.4923 - color_loss: 1.2004 - cut_accuracy: 0.5167 - cut_loss: 1.0832 - loss: 2.8032 - val_clarity_accuracy: 0.7761 - val_clarity_loss: 0.4963 - val_color_accuracy: 0.4900 - val_color_loss: 1.2071 - val_cut_accuracy: 0.5101 - val_cut_loss: 1.0985 - val_loss: 2.8024\n",
            "Epoch 31/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - clarity_accuracy: 0.7571 - clarity_loss: 0.5206 - color_accuracy: 0.4820 - color_loss: 1.2156 - cut_accuracy: 0.5078 - cut_loss: 1.1127 - loss: 2.8489 - val_clarity_accuracy: 0.7778 - val_clarity_loss: 0.4940 - val_color_accuracy: 0.4929 - val_color_loss: 1.2067 - val_cut_accuracy: 0.5198 - val_cut_loss: 1.0994 - val_loss: 2.8007\n",
            "Epoch 32/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - clarity_accuracy: 0.7616 - clarity_loss: 0.5092 - color_accuracy: 0.4873 - color_loss: 1.2052 - cut_accuracy: 0.5190 - cut_loss: 1.0915 - loss: 2.8058 - val_clarity_accuracy: 0.7764 - val_clarity_loss: 0.4991 - val_color_accuracy: 0.4815 - val_color_loss: 1.2108 - val_cut_accuracy: 0.5207 - val_cut_loss: 1.1016 - val_loss: 2.8119\n",
            "Epoch 33/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - clarity_accuracy: 0.7678 - clarity_loss: 0.5105 - color_accuracy: 0.4826 - color_loss: 1.2058 - cut_accuracy: 0.5215 - cut_loss: 1.0918 - loss: 2.8081 - val_clarity_accuracy: 0.7715 - val_clarity_loss: 0.5023 - val_color_accuracy: 0.4882 - val_color_loss: 1.2049 - val_cut_accuracy: 0.5167 - val_cut_loss: 1.1064 - val_loss: 2.8142\n",
            "Epoch 34/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - clarity_accuracy: 0.7739 - clarity_loss: 0.4970 - color_accuracy: 0.4873 - color_loss: 1.1900 - cut_accuracy: 0.5224 - cut_loss: 1.0793 - loss: 2.7663 - val_clarity_accuracy: 0.7749 - val_clarity_loss: 0.4937 - val_color_accuracy: 0.4771 - val_color_loss: 1.2063 - val_cut_accuracy: 0.5201 - val_cut_loss: 1.0965 - val_loss: 2.7971\n",
            "Epoch 35/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - clarity_accuracy: 0.7691 - clarity_loss: 0.5002 - color_accuracy: 0.4924 - color_loss: 1.1985 - cut_accuracy: 0.5180 - cut_loss: 1.0945 - loss: 2.7933 - val_clarity_accuracy: 0.7845 - val_clarity_loss: 0.4880 - val_color_accuracy: 0.4960 - val_color_loss: 1.1865 - val_cut_accuracy: 0.5244 - val_cut_loss: 1.0925 - val_loss: 2.7676\n",
            "Epoch 36/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - clarity_accuracy: 0.7739 - clarity_loss: 0.5052 - color_accuracy: 0.4947 - color_loss: 1.2006 - cut_accuracy: 0.5254 - cut_loss: 1.0811 - loss: 2.7870 - val_clarity_accuracy: 0.7851 - val_clarity_loss: 0.4889 - val_color_accuracy: 0.4857 - val_color_loss: 1.1992 - val_cut_accuracy: 0.5156 - val_cut_loss: 1.0968 - val_loss: 2.7855\n",
            "Epoch 37/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - clarity_accuracy: 0.7764 - clarity_loss: 0.4916 - color_accuracy: 0.4906 - color_loss: 1.1899 - cut_accuracy: 0.5211 - cut_loss: 1.0681 - loss: 2.7495 - val_clarity_accuracy: 0.7958 - val_clarity_loss: 0.4731 - val_color_accuracy: 0.4912 - val_color_loss: 1.1857 - val_cut_accuracy: 0.5264 - val_cut_loss: 1.0830 - val_loss: 2.7421\n",
            "Epoch 38/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - clarity_accuracy: 0.7803 - clarity_loss: 0.4861 - color_accuracy: 0.4922 - color_loss: 1.1741 - cut_accuracy: 0.5234 - cut_loss: 1.0704 - loss: 2.7306 - val_clarity_accuracy: 0.7952 - val_clarity_loss: 0.4776 - val_color_accuracy: 0.4933 - val_color_loss: 1.1889 - val_cut_accuracy: 0.5204 - val_cut_loss: 1.0880 - val_loss: 2.7549\n",
            "Epoch 39/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - clarity_accuracy: 0.7778 - clarity_loss: 0.4829 - color_accuracy: 0.4894 - color_loss: 1.1839 - cut_accuracy: 0.5276 - cut_loss: 1.0677 - loss: 2.7344 - val_clarity_accuracy: 0.7882 - val_clarity_loss: 0.4730 - val_color_accuracy: 0.4954 - val_color_loss: 1.1904 - val_cut_accuracy: 0.5179 - val_cut_loss: 1.0878 - val_loss: 2.7516\n",
            "Epoch 40/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - clarity_accuracy: 0.7825 - clarity_loss: 0.4900 - color_accuracy: 0.4978 - color_loss: 1.1929 - cut_accuracy: 0.5165 - cut_loss: 1.0843 - loss: 2.7672 - val_clarity_accuracy: 0.7892 - val_clarity_loss: 0.4765 - val_color_accuracy: 0.4951 - val_color_loss: 1.1919 - val_cut_accuracy: 0.4988 - val_cut_loss: 1.0920 - val_loss: 2.7609\n",
            "Epoch 41/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - clarity_accuracy: 0.7771 - clarity_loss: 0.4922 - color_accuracy: 0.4874 - color_loss: 1.1923 - cut_accuracy: 0.5247 - cut_loss: 1.0709 - loss: 2.7553 - val_clarity_accuracy: 0.7945 - val_clarity_loss: 0.4689 - val_color_accuracy: 0.4999 - val_color_loss: 1.1841 - val_cut_accuracy: 0.5310 - val_cut_loss: 1.0869 - val_loss: 2.7403\n",
            "Epoch 42/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - clarity_accuracy: 0.7881 - clarity_loss: 0.4683 - color_accuracy: 0.5018 - color_loss: 1.1634 - cut_accuracy: 0.5298 - cut_loss: 1.0475 - loss: 2.6792 - val_clarity_accuracy: 0.7925 - val_clarity_loss: 0.4686 - val_color_accuracy: 0.4900 - val_color_loss: 1.1878 - val_cut_accuracy: 0.5223 - val_cut_loss: 1.0839 - val_loss: 2.7407\n",
            "Epoch 43/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - clarity_accuracy: 0.7832 - clarity_loss: 0.4668 - color_accuracy: 0.4997 - color_loss: 1.1668 - cut_accuracy: 0.5273 - cut_loss: 1.0637 - loss: 2.6973 - val_clarity_accuracy: 0.7928 - val_clarity_loss: 0.4753 - val_color_accuracy: 0.4973 - val_color_loss: 1.1883 - val_cut_accuracy: 0.5241 - val_cut_loss: 1.0821 - val_loss: 2.7462\n",
            "Epoch 44/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - clarity_accuracy: 0.7879 - clarity_loss: 0.4712 - color_accuracy: 0.4944 - color_loss: 1.1813 - cut_accuracy: 0.5319 - cut_loss: 1.0515 - loss: 2.7040 - val_clarity_accuracy: 0.7965 - val_clarity_loss: 0.4667 - val_color_accuracy: 0.4949 - val_color_loss: 1.1991 - val_cut_accuracy: 0.4920 - val_cut_loss: 1.0913 - val_loss: 2.7577\n",
            "Epoch 45/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - clarity_accuracy: 0.7881 - clarity_loss: 0.4667 - color_accuracy: 0.5001 - color_loss: 1.1914 - cut_accuracy: 0.5279 - cut_loss: 1.0562 - loss: 2.7143 - val_clarity_accuracy: 0.8000 - val_clarity_loss: 0.4616 - val_color_accuracy: 0.4940 - val_color_loss: 1.1831 - val_cut_accuracy: 0.5279 - val_cut_loss: 1.0772 - val_loss: 2.7223\n",
            "Epoch 46/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - clarity_accuracy: 0.7822 - clarity_loss: 0.4767 - color_accuracy: 0.4985 - color_loss: 1.1840 - cut_accuracy: 0.5327 - cut_loss: 1.0498 - loss: 2.7105 - val_clarity_accuracy: 0.7985 - val_clarity_loss: 0.4653 - val_color_accuracy: 0.4884 - val_color_loss: 1.1864 - val_cut_accuracy: 0.5247 - val_cut_loss: 1.0806 - val_loss: 2.7327\n",
            "Epoch 47/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - clarity_accuracy: 0.7873 - clarity_loss: 0.4692 - color_accuracy: 0.5006 - color_loss: 1.1793 - cut_accuracy: 0.5370 - cut_loss: 1.0454 - loss: 2.6938 - val_clarity_accuracy: 0.7955 - val_clarity_loss: 0.4552 - val_color_accuracy: 0.4879 - val_color_loss: 1.1779 - val_cut_accuracy: 0.5229 - val_cut_loss: 1.0738 - val_loss: 2.7073\n",
            "Epoch 48/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - clarity_accuracy: 0.7923 - clarity_loss: 0.4611 - color_accuracy: 0.5105 - color_loss: 1.1565 - cut_accuracy: 0.5356 - cut_loss: 1.0475 - loss: 2.6652 - val_clarity_accuracy: 0.8091 - val_clarity_loss: 0.4434 - val_color_accuracy: 0.4937 - val_color_loss: 1.1739 - val_cut_accuracy: 0.5337 - val_cut_loss: 1.0683 - val_loss: 2.6858\n",
            "Epoch 49/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - clarity_accuracy: 0.7982 - clarity_loss: 0.4571 - color_accuracy: 0.4954 - color_loss: 1.1629 - cut_accuracy: 0.5374 - cut_loss: 1.0409 - loss: 2.6609 - val_clarity_accuracy: 0.7945 - val_clarity_loss: 0.4568 - val_color_accuracy: 0.4960 - val_color_loss: 1.1840 - val_cut_accuracy: 0.5299 - val_cut_loss: 1.0846 - val_loss: 2.7259\n",
            "Epoch 50/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - clarity_accuracy: 0.7910 - clarity_loss: 0.4562 - color_accuracy: 0.5060 - color_loss: 1.1554 - cut_accuracy: 0.5317 - cut_loss: 1.0436 - loss: 2.6552 - val_clarity_accuracy: 0.8119 - val_clarity_loss: 0.4476 - val_color_accuracy: 0.4936 - val_color_loss: 1.1675 - val_cut_accuracy: 0.5387 - val_cut_loss: 1.0663 - val_loss: 2.6818\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clarity Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.80      0.75      1665\n",
            "           1       1.00      1.00      1.00      1708\n",
            "           2       0.78      0.95      0.85      1631\n",
            "           3       0.69      0.46      0.56      1710\n",
            "\n",
            "    accuracy                           0.80      6714\n",
            "   macro avg       0.80      0.80      0.79      6714\n",
            "weighted avg       0.80      0.80      0.79      6714\n",
            "\n",
            "Color Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.79      0.67       949\n",
            "           1       0.44      0.37      0.40       965\n",
            "           2       0.00      0.00      0.00       987\n",
            "           3       0.50      0.85      0.63      1001\n",
            "           4       0.47      0.83      0.60       972\n",
            "           5       0.58      0.29      0.39       482\n",
            "           7       0.00      0.00      0.00        24\n",
            "           8       0.40      0.26      0.32        23\n",
            "          10       0.00      0.00      0.00        31\n",
            "          11       0.42      0.27      0.33        91\n",
            "          12       0.51      0.60      0.55       265\n",
            "          13       0.00      0.00      0.00         8\n",
            "          14       0.20      0.01      0.02        77\n",
            "          15       0.46      0.12      0.19        50\n",
            "          16       0.51      0.66      0.57       109\n",
            "          17       0.00      0.00      0.00         5\n",
            "          18       0.00      0.00      0.00        71\n",
            "          19       0.00      0.00      0.00        22\n",
            "          20       0.50      0.39      0.44       172\n",
            "          21       0.20      0.05      0.07        22\n",
            "          22       0.00      0.00      0.00        16\n",
            "          23       0.63      0.60      0.61        70\n",
            "          24       0.48      0.45      0.46       219\n",
            "          25       0.00      0.00      0.00         8\n",
            "          26       0.54      0.24      0.33        62\n",
            "          27       0.00      0.00      0.00        13\n",
            "\n",
            "    accuracy                           0.51      6714\n",
            "   macro avg       0.29      0.26      0.25      6714\n",
            "weighted avg       0.41      0.51      0.44      6714\n",
            "\n",
            "Cut Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.40      0.46      1930\n",
            "           1       0.53      0.94      0.68      1944\n",
            "           2       0.00      0.00      0.00       440\n",
            "           3       0.47      0.15      0.23       216\n",
            "           4       0.00      0.00      0.00         8\n",
            "           5       0.00      0.00      0.00        11\n",
            "           7       0.56      0.53      0.54      1938\n",
            "           8       0.00      0.00      0.00        11\n",
            "           9       0.00      0.00      0.00        23\n",
            "          10       0.00      0.00      0.00       110\n",
            "          11       0.00      0.00      0.00         2\n",
            "          12       0.00      0.00      0.00        30\n",
            "          13       0.60      0.06      0.11        51\n",
            "\n",
            "    accuracy                           0.54      6714\n",
            "   macro avg       0.21      0.16      0.15      6714\n",
            "weighted avg       0.49      0.54      0.49      6714\n",
            "\n",
            "Model saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Increase size of layers"
      ],
      "metadata": {
        "id": "StoHPyj7qdU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/Final_reverse_One_hot_encoded_Processed_data (1).csv\")\n",
        "\n",
        "# Identify target columns\n",
        "target_columns = ['clarity', 'color', 'cut']\n",
        "\n",
        "# Drop target columns to get feature set\n",
        "X = df.drop(columns=target_columns)\n",
        "\n",
        "# OneHotEncode target labels\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "y_clarity = encoder.fit_transform(df[[\"clarity\"]])\n",
        "y_color = encoder.fit_transform(df[[\"color\"]])\n",
        "y_cut = encoder.fit_transform(df[[\"cut\"]])\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_clarity_train, y_clarity_test, y_color_train, y_color_test, y_cut_train, y_cut_test = train_test_split(\n",
        "    X, y_clarity, y_color, y_cut, test_size=0.4, random_state=42\n",
        ")\n",
        "\n",
        "X_val, X_test, y_clarity_val, y_clarity_test, y_color_val, y_color_test, y_cut_val, y_cut_test = train_test_split(\n",
        "    X_test, y_clarity_test, y_color_test, y_cut_test, test_size=0.5, random_state=42\n",
        ")\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert labels to NumPy arrays\n",
        "Y_clarity_train_array = np.array(y_clarity_train)\n",
        "Y_color_train_array = np.array(y_color_train)\n",
        "Y_cut_train_array = np.array(y_cut_train)\n",
        "\n",
        "Y_clarity_val_array = np.array(y_clarity_val)\n",
        "Y_color_val_array = np.array(y_color_val)\n",
        "Y_cut_val_array = np.array(y_cut_val)\n",
        "\n",
        "Y_clarity_test_array = np.array(y_clarity_test)\n",
        "Y_color_test_array = np.array(y_color_test)\n",
        "Y_cut_test_array = np.array(y_cut_test)\n",
        "\n",
        "# Define the model with increased layer sizes\n",
        "input_layer = keras.Input(shape=(X_train_scaled.shape[1],))\n",
        "\n",
        "# Deepened and widened hidden layers\n",
        "x = layers.Dense(512, activation=\"relu\")(input_layer)\n",
        "x = layers.Dropout(0.4)(x)\n",
        "x = layers.Dense(512, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.4)(x)\n",
        "x = layers.Dense(256, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.4)(x)\n",
        "x = layers.Dense(128, activation=\"relu\")(x)\n",
        "\n",
        "# Output layers\n",
        "clarity_output = layers.Dense(Y_clarity_train_array.shape[1], activation=\"softmax\", name=\"clarity\")(x)\n",
        "color_output = layers.Dense(Y_color_train_array.shape[1], activation=\"softmax\", name=\"color\")(x)\n",
        "cut_output = layers.Dense(Y_cut_train_array.shape[1], activation=\"softmax\", name=\"cut\")(x)\n",
        "\n",
        "# Compile the model\n",
        "model = keras.Model(inputs=input_layer, outputs=[clarity_output, color_output, cut_output])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss={'clarity': 'categorical_crossentropy', 'color': 'categorical_crossentropy', 'cut': 'categorical_crossentropy'},\n",
        "    metrics={'clarity': 'accuracy', 'color': 'accuracy', 'cut': 'accuracy'}\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train_scaled,\n",
        "    {\"clarity\": Y_clarity_train_array, \"color\": Y_color_train_array, \"cut\": Y_cut_train_array},\n",
        "    validation_data=(X_val_scaled, {\"clarity\": Y_clarity_val_array, \"color\": Y_color_val_array, \"cut\": Y_cut_val_array}),\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "Y_test_pred = model.predict(X_test_scaled)\n",
        "Y_test_pred = [np.argmax(pred, axis=1) for pred in Y_test_pred]  # Convert probabilities to class labels\n",
        "\n",
        "# Convert one-hot test labels back to class labels\n",
        "Y_test_true = [\n",
        "    np.argmax(Y_clarity_test_array, axis=1),\n",
        "    np.argmax(Y_color_test_array, axis=1),\n",
        "    np.argmax(Y_cut_test_array, axis=1)\n",
        "]\n",
        "\n",
        "# Generate classification reports\n",
        "for i, name in enumerate([\"Clarity\", \"Color\", \"Cut\"]):\n",
        "    print(f\"{name} Classification Report:\\n\", classification_report(Y_test_true[i], Y_test_pred[i]))\n",
        "\n",
        "# Save the model\n",
        "model.save(\"DNN_gemstone_quality_model_large.h5\")\n",
        "print(\"Model with increased layers saved successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4qLA5lP7XW5S",
        "outputId": "35800ddb-890d-4680-d6af-a9b3c72895a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m226\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m116,224\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m262,656\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m131,328\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m32,896\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ clarity (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m516\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ color (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)             │          \u001b[38;5;34m3,612\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ cut (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │          \u001b[38;5;34m1,806\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">226</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">116,224</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ clarity (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ color (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">3,612</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ cut (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,806</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m549,038\u001b[0m (2.09 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">549,038</span> (2.09 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m549,038\u001b[0m (2.09 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">549,038</span> (2.09 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - clarity_accuracy: 0.4530 - clarity_loss: 1.1152 - color_accuracy: 0.2820 - color_loss: 2.1560 - cut_accuracy: 0.3509 - cut_loss: 1.5876 - loss: 4.8588 - val_clarity_accuracy: 0.5895 - val_clarity_loss: 0.7893 - val_color_accuracy: 0.3765 - val_color_loss: 1.6101 - val_cut_accuracy: 0.4242 - val_cut_loss: 1.3847 - val_loss: 3.7847\n",
            "Epoch 2/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - clarity_accuracy: 0.5705 - clarity_loss: 0.8259 - color_accuracy: 0.3729 - color_loss: 1.6423 - cut_accuracy: 0.4044 - cut_loss: 1.3936 - loss: 3.8618 - val_clarity_accuracy: 0.6029 - val_clarity_loss: 0.7659 - val_color_accuracy: 0.4074 - val_color_loss: 1.5287 - val_cut_accuracy: 0.4225 - val_cut_loss: 1.3633 - val_loss: 3.6586\n",
            "Epoch 3/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - clarity_accuracy: 0.5955 - clarity_loss: 0.7844 - color_accuracy: 0.3947 - color_loss: 1.5538 - cut_accuracy: 0.4236 - cut_loss: 1.3486 - loss: 3.6868 - val_clarity_accuracy: 0.6354 - val_clarity_loss: 0.7421 - val_color_accuracy: 0.4130 - val_color_loss: 1.4615 - val_cut_accuracy: 0.4416 - val_cut_loss: 1.3302 - val_loss: 3.5345\n",
            "Epoch 4/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - clarity_accuracy: 0.6129 - clarity_loss: 0.7606 - color_accuracy: 0.3992 - color_loss: 1.5261 - cut_accuracy: 0.4251 - cut_loss: 1.3401 - loss: 3.6267 - val_clarity_accuracy: 0.6500 - val_clarity_loss: 0.7240 - val_color_accuracy: 0.4342 - val_color_loss: 1.4352 - val_cut_accuracy: 0.4275 - val_cut_loss: 1.3240 - val_loss: 3.4838\n",
            "Epoch 5/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - clarity_accuracy: 0.6294 - clarity_loss: 0.7423 - color_accuracy: 0.4125 - color_loss: 1.4678 - cut_accuracy: 0.4306 - cut_loss: 1.3192 - loss: 3.5294 - val_clarity_accuracy: 0.6553 - val_clarity_loss: 0.7109 - val_color_accuracy: 0.4312 - val_color_loss: 1.4102 - val_cut_accuracy: 0.4522 - val_cut_loss: 1.3138 - val_loss: 3.4356\n",
            "Epoch 6/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - clarity_accuracy: 0.6330 - clarity_loss: 0.7308 - color_accuracy: 0.4162 - color_loss: 1.4516 - cut_accuracy: 0.4427 - cut_loss: 1.3066 - loss: 3.4890 - val_clarity_accuracy: 0.6525 - val_clarity_loss: 0.7039 - val_color_accuracy: 0.4376 - val_color_loss: 1.4046 - val_cut_accuracy: 0.4540 - val_cut_loss: 1.3119 - val_loss: 3.4211\n",
            "Epoch 7/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - clarity_accuracy: 0.6436 - clarity_loss: 0.7226 - color_accuracy: 0.4190 - color_loss: 1.4360 - cut_accuracy: 0.4375 - cut_loss: 1.3074 - loss: 3.4661 - val_clarity_accuracy: 0.6543 - val_clarity_loss: 0.7050 - val_color_accuracy: 0.4364 - val_color_loss: 1.3862 - val_cut_accuracy: 0.4511 - val_cut_loss: 1.2823 - val_loss: 3.3741\n",
            "Epoch 8/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - clarity_accuracy: 0.6566 - clarity_loss: 0.7107 - color_accuracy: 0.4319 - color_loss: 1.4096 - cut_accuracy: 0.4455 - cut_loss: 1.2831 - loss: 3.4034 - val_clarity_accuracy: 0.6696 - val_clarity_loss: 0.6774 - val_color_accuracy: 0.4446 - val_color_loss: 1.3626 - val_cut_accuracy: 0.4643 - val_cut_loss: 1.2604 - val_loss: 3.3012\n",
            "Epoch 9/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - clarity_accuracy: 0.6586 - clarity_loss: 0.6923 - color_accuracy: 0.4343 - color_loss: 1.4065 - cut_accuracy: 0.4521 - cut_loss: 1.2733 - loss: 3.3721 - val_clarity_accuracy: 0.6759 - val_clarity_loss: 0.6617 - val_color_accuracy: 0.4401 - val_color_loss: 1.3402 - val_cut_accuracy: 0.4663 - val_cut_loss: 1.2445 - val_loss: 3.2470\n",
            "Epoch 10/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - clarity_accuracy: 0.6659 - clarity_loss: 0.6855 - color_accuracy: 0.4361 - color_loss: 1.3792 - cut_accuracy: 0.4518 - cut_loss: 1.2563 - loss: 3.3210 - val_clarity_accuracy: 0.6777 - val_clarity_loss: 0.6677 - val_color_accuracy: 0.4501 - val_color_loss: 1.3436 - val_cut_accuracy: 0.4602 - val_cut_loss: 1.2513 - val_loss: 3.2632\n",
            "Epoch 11/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - clarity_accuracy: 0.6763 - clarity_loss: 0.6721 - color_accuracy: 0.4397 - color_loss: 1.3662 - cut_accuracy: 0.4611 - cut_loss: 1.2504 - loss: 3.2887 - val_clarity_accuracy: 0.6911 - val_clarity_loss: 0.6600 - val_color_accuracy: 0.4458 - val_color_loss: 1.3287 - val_cut_accuracy: 0.4648 - val_cut_loss: 1.2363 - val_loss: 3.2255\n",
            "Epoch 12/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - clarity_accuracy: 0.6876 - clarity_loss: 0.6606 - color_accuracy: 0.4477 - color_loss: 1.3459 - cut_accuracy: 0.4652 - cut_loss: 1.2357 - loss: 3.2421 - val_clarity_accuracy: 0.6944 - val_clarity_loss: 0.6410 - val_color_accuracy: 0.4500 - val_color_loss: 1.3333 - val_cut_accuracy: 0.4784 - val_cut_loss: 1.2292 - val_loss: 3.2043\n",
            "Epoch 13/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - clarity_accuracy: 0.6903 - clarity_loss: 0.6400 - color_accuracy: 0.4455 - color_loss: 1.3321 - cut_accuracy: 0.4701 - cut_loss: 1.2168 - loss: 3.1889 - val_clarity_accuracy: 0.7151 - val_clarity_loss: 0.6284 - val_color_accuracy: 0.4488 - val_color_loss: 1.3086 - val_cut_accuracy: 0.4650 - val_cut_loss: 1.2124 - val_loss: 3.1499\n",
            "Epoch 14/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - clarity_accuracy: 0.6908 - clarity_loss: 0.6409 - color_accuracy: 0.4454 - color_loss: 1.3276 - cut_accuracy: 0.4767 - cut_loss: 1.2121 - loss: 3.1805 - val_clarity_accuracy: 0.7005 - val_clarity_loss: 0.6328 - val_color_accuracy: 0.4601 - val_color_loss: 1.3145 - val_cut_accuracy: 0.4592 - val_cut_loss: 1.2171 - val_loss: 3.1649\n",
            "Epoch 15/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - clarity_accuracy: 0.7046 - clarity_loss: 0.6273 - color_accuracy: 0.4546 - color_loss: 1.3160 - cut_accuracy: 0.4740 - cut_loss: 1.1960 - loss: 3.1393 - val_clarity_accuracy: 0.7179 - val_clarity_loss: 0.6061 - val_color_accuracy: 0.4665 - val_color_loss: 1.2850 - val_cut_accuracy: 0.4797 - val_cut_loss: 1.2008 - val_loss: 3.0923\n",
            "Epoch 16/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - clarity_accuracy: 0.7043 - clarity_loss: 0.6223 - color_accuracy: 0.4534 - color_loss: 1.3150 - cut_accuracy: 0.4765 - cut_loss: 1.2012 - loss: 3.1385 - val_clarity_accuracy: 0.7157 - val_clarity_loss: 0.6065 - val_color_accuracy: 0.4643 - val_color_loss: 1.2905 - val_cut_accuracy: 0.4550 - val_cut_loss: 1.1987 - val_loss: 3.0960\n",
            "Epoch 17/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - clarity_accuracy: 0.7144 - clarity_loss: 0.6112 - color_accuracy: 0.4597 - color_loss: 1.2896 - cut_accuracy: 0.4828 - cut_loss: 1.1856 - loss: 3.0864 - val_clarity_accuracy: 0.7181 - val_clarity_loss: 0.5963 - val_color_accuracy: 0.4581 - val_color_loss: 1.2758 - val_cut_accuracy: 0.4857 - val_cut_loss: 1.1811 - val_loss: 3.0538\n",
            "Epoch 18/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - clarity_accuracy: 0.7187 - clarity_loss: 0.5963 - color_accuracy: 0.4629 - color_loss: 1.2857 - cut_accuracy: 0.4884 - cut_loss: 1.1691 - loss: 3.0510 - val_clarity_accuracy: 0.7309 - val_clarity_loss: 0.5865 - val_color_accuracy: 0.4604 - val_color_loss: 1.2859 - val_cut_accuracy: 0.4920 - val_cut_loss: 1.1713 - val_loss: 3.0440\n",
            "Epoch 19/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - clarity_accuracy: 0.7223 - clarity_loss: 0.5942 - color_accuracy: 0.4603 - color_loss: 1.2922 - cut_accuracy: 0.4849 - cut_loss: 1.1617 - loss: 3.0482 - val_clarity_accuracy: 0.7340 - val_clarity_loss: 0.5722 - val_color_accuracy: 0.4695 - val_color_loss: 1.2692 - val_cut_accuracy: 0.4948 - val_cut_loss: 1.1747 - val_loss: 3.0166\n",
            "Epoch 20/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - clarity_accuracy: 0.7294 - clarity_loss: 0.5882 - color_accuracy: 0.4733 - color_loss: 1.2735 - cut_accuracy: 0.4926 - cut_loss: 1.1591 - loss: 3.0208 - val_clarity_accuracy: 0.7408 - val_clarity_loss: 0.5662 - val_color_accuracy: 0.4754 - val_color_loss: 1.2661 - val_cut_accuracy: 0.4978 - val_cut_loss: 1.1609 - val_loss: 2.9936\n",
            "Epoch 21/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - clarity_accuracy: 0.7366 - clarity_loss: 0.5688 - color_accuracy: 0.4686 - color_loss: 1.2736 - cut_accuracy: 0.4928 - cut_loss: 1.1364 - loss: 2.9788 - val_clarity_accuracy: 0.7373 - val_clarity_loss: 0.5649 - val_color_accuracy: 0.4705 - val_color_loss: 1.2642 - val_cut_accuracy: 0.5009 - val_cut_loss: 1.1653 - val_loss: 2.9949\n",
            "Epoch 22/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - clarity_accuracy: 0.7362 - clarity_loss: 0.5620 - color_accuracy: 0.4736 - color_loss: 1.2507 - cut_accuracy: 0.4920 - cut_loss: 1.1432 - loss: 2.9559 - val_clarity_accuracy: 0.7490 - val_clarity_loss: 0.5586 - val_color_accuracy: 0.4666 - val_color_loss: 1.2574 - val_cut_accuracy: 0.4982 - val_cut_loss: 1.1527 - val_loss: 2.9691\n",
            "Epoch 23/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - clarity_accuracy: 0.7381 - clarity_loss: 0.5591 - color_accuracy: 0.4729 - color_loss: 1.2506 - cut_accuracy: 0.4901 - cut_loss: 1.1373 - loss: 2.9471 - val_clarity_accuracy: 0.7504 - val_clarity_loss: 0.5524 - val_color_accuracy: 0.4736 - val_color_loss: 1.2618 - val_cut_accuracy: 0.4963 - val_cut_loss: 1.1514 - val_loss: 2.9660\n",
            "Epoch 24/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - clarity_accuracy: 0.7442 - clarity_loss: 0.5439 - color_accuracy: 0.4716 - color_loss: 1.2448 - cut_accuracy: 0.4952 - cut_loss: 1.1364 - loss: 2.9251 - val_clarity_accuracy: 0.7495 - val_clarity_loss: 0.5446 - val_color_accuracy: 0.4750 - val_color_loss: 1.2458 - val_cut_accuracy: 0.5046 - val_cut_loss: 1.1409 - val_loss: 2.9319\n",
            "Epoch 25/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - clarity_accuracy: 0.7477 - clarity_loss: 0.5500 - color_accuracy: 0.4817 - color_loss: 1.2316 - cut_accuracy: 0.4992 - cut_loss: 1.1143 - loss: 2.8959 - val_clarity_accuracy: 0.7544 - val_clarity_loss: 0.5309 - val_color_accuracy: 0.4760 - val_color_loss: 1.2365 - val_cut_accuracy: 0.5076 - val_cut_loss: 1.1368 - val_loss: 2.9047\n",
            "Epoch 26/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - clarity_accuracy: 0.7440 - clarity_loss: 0.5513 - color_accuracy: 0.4788 - color_loss: 1.2470 - cut_accuracy: 0.5036 - cut_loss: 1.1137 - loss: 2.9119 - val_clarity_accuracy: 0.7630 - val_clarity_loss: 0.5211 - val_color_accuracy: 0.4711 - val_color_loss: 1.2264 - val_cut_accuracy: 0.5077 - val_cut_loss: 1.1255 - val_loss: 2.8735\n",
            "Epoch 27/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - clarity_accuracy: 0.7577 - clarity_loss: 0.5280 - color_accuracy: 0.4823 - color_loss: 1.2262 - cut_accuracy: 0.5111 - cut_loss: 1.1147 - loss: 2.8690 - val_clarity_accuracy: 0.7654 - val_clarity_loss: 0.5154 - val_color_accuracy: 0.4626 - val_color_loss: 1.2429 - val_cut_accuracy: 0.5131 - val_cut_loss: 1.1228 - val_loss: 2.8817\n",
            "Epoch 28/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - clarity_accuracy: 0.7535 - clarity_loss: 0.5244 - color_accuracy: 0.4834 - color_loss: 1.2253 - cut_accuracy: 0.5124 - cut_loss: 1.1139 - loss: 2.8637 - val_clarity_accuracy: 0.7711 - val_clarity_loss: 0.5153 - val_color_accuracy: 0.4847 - val_color_loss: 1.2370 - val_cut_accuracy: 0.4790 - val_cut_loss: 1.1218 - val_loss: 2.8745\n",
            "Epoch 29/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - clarity_accuracy: 0.7664 - clarity_loss: 0.5056 - color_accuracy: 0.4847 - color_loss: 1.2239 - cut_accuracy: 0.5118 - cut_loss: 1.0977 - loss: 2.8273 - val_clarity_accuracy: 0.7641 - val_clarity_loss: 0.5187 - val_color_accuracy: 0.4753 - val_color_loss: 1.2412 - val_cut_accuracy: 0.4978 - val_cut_loss: 1.1344 - val_loss: 2.8948\n",
            "Epoch 30/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - clarity_accuracy: 0.7594 - clarity_loss: 0.5188 - color_accuracy: 0.4889 - color_loss: 1.2157 - cut_accuracy: 0.5152 - cut_loss: 1.0950 - loss: 2.8295 - val_clarity_accuracy: 0.7703 - val_clarity_loss: 0.5110 - val_color_accuracy: 0.4939 - val_color_loss: 1.2298 - val_cut_accuracy: 0.5089 - val_cut_loss: 1.1251 - val_loss: 2.8664\n",
            "Epoch 31/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - clarity_accuracy: 0.7718 - clarity_loss: 0.5022 - color_accuracy: 0.4852 - color_loss: 1.2084 - cut_accuracy: 0.5177 - cut_loss: 1.0806 - loss: 2.7912 - val_clarity_accuracy: 0.7650 - val_clarity_loss: 0.5134 - val_color_accuracy: 0.4936 - val_color_loss: 1.2316 - val_cut_accuracy: 0.5098 - val_cut_loss: 1.1205 - val_loss: 2.8660\n",
            "Epoch 32/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - clarity_accuracy: 0.7674 - clarity_loss: 0.5048 - color_accuracy: 0.4909 - color_loss: 1.2065 - cut_accuracy: 0.5121 - cut_loss: 1.0864 - loss: 2.7977 - val_clarity_accuracy: 0.7693 - val_clarity_loss: 0.4990 - val_color_accuracy: 0.4797 - val_color_loss: 1.2233 - val_cut_accuracy: 0.5156 - val_cut_loss: 1.1099 - val_loss: 2.8327\n",
            "Epoch 33/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - clarity_accuracy: 0.7692 - clarity_loss: 0.5011 - color_accuracy: 0.4891 - color_loss: 1.1994 - cut_accuracy: 0.5138 - cut_loss: 1.0896 - loss: 2.7901 - val_clarity_accuracy: 0.7785 - val_clarity_loss: 0.4863 - val_color_accuracy: 0.4869 - val_color_loss: 1.2178 - val_cut_accuracy: 0.5223 - val_cut_loss: 1.1051 - val_loss: 2.8098\n",
            "Epoch 34/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - clarity_accuracy: 0.7765 - clarity_loss: 0.4900 - color_accuracy: 0.4948 - color_loss: 1.1942 - cut_accuracy: 0.5185 - cut_loss: 1.0785 - loss: 2.7627 - val_clarity_accuracy: 0.7727 - val_clarity_loss: 0.4979 - val_color_accuracy: 0.4926 - val_color_loss: 1.2198 - val_cut_accuracy: 0.5133 - val_cut_loss: 1.1091 - val_loss: 2.8271\n",
            "Epoch 35/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - clarity_accuracy: 0.7709 - clarity_loss: 0.4946 - color_accuracy: 0.4850 - color_loss: 1.1942 - cut_accuracy: 0.5248 - cut_loss: 1.0679 - loss: 2.7567 - val_clarity_accuracy: 0.7805 - val_clarity_loss: 0.4762 - val_color_accuracy: 0.4943 - val_color_loss: 1.2126 - val_cut_accuracy: 0.4957 - val_cut_loss: 1.1019 - val_loss: 2.7911\n",
            "Epoch 36/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - clarity_accuracy: 0.7741 - clarity_loss: 0.4864 - color_accuracy: 0.4883 - color_loss: 1.2038 - cut_accuracy: 0.5171 - cut_loss: 1.0715 - loss: 2.7617 - val_clarity_accuracy: 0.7800 - val_clarity_loss: 0.4882 - val_color_accuracy: 0.4884 - val_color_loss: 1.2211 - val_cut_accuracy: 0.5049 - val_cut_loss: 1.1080 - val_loss: 2.8178\n",
            "Epoch 37/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - clarity_accuracy: 0.7868 - clarity_loss: 0.4737 - color_accuracy: 0.4949 - color_loss: 1.1874 - cut_accuracy: 0.5225 - cut_loss: 1.0786 - loss: 2.7397 - val_clarity_accuracy: 0.7924 - val_clarity_loss: 0.4668 - val_color_accuracy: 0.4882 - val_color_loss: 1.2014 - val_cut_accuracy: 0.5217 - val_cut_loss: 1.0962 - val_loss: 2.7648\n",
            "Epoch 38/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - clarity_accuracy: 0.7852 - clarity_loss: 0.4659 - color_accuracy: 0.5020 - color_loss: 1.1682 - cut_accuracy: 0.5248 - cut_loss: 1.0667 - loss: 2.7008 - val_clarity_accuracy: 0.8010 - val_clarity_loss: 0.4589 - val_color_accuracy: 0.4917 - val_color_loss: 1.1960 - val_cut_accuracy: 0.5299 - val_cut_loss: 1.0790 - val_loss: 2.7343\n",
            "Epoch 39/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - clarity_accuracy: 0.7843 - clarity_loss: 0.4703 - color_accuracy: 0.5008 - color_loss: 1.1775 - cut_accuracy: 0.5338 - cut_loss: 1.0498 - loss: 2.6976 - val_clarity_accuracy: 0.7891 - val_clarity_loss: 0.4742 - val_color_accuracy: 0.4979 - val_color_loss: 1.2115 - val_cut_accuracy: 0.5301 - val_cut_loss: 1.0906 - val_loss: 2.7767\n",
            "Epoch 40/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - clarity_accuracy: 0.7888 - clarity_loss: 0.4695 - color_accuracy: 0.4928 - color_loss: 1.1850 - cut_accuracy: 0.5263 - cut_loss: 1.0667 - loss: 2.7213 - val_clarity_accuracy: 0.7836 - val_clarity_loss: 0.4762 - val_color_accuracy: 0.4859 - val_color_loss: 1.2099 - val_cut_accuracy: 0.5211 - val_cut_loss: 1.0930 - val_loss: 2.7795\n",
            "Epoch 41/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - clarity_accuracy: 0.7944 - clarity_loss: 0.4615 - color_accuracy: 0.5055 - color_loss: 1.1844 - cut_accuracy: 0.5318 - cut_loss: 1.0526 - loss: 2.6985 - val_clarity_accuracy: 0.7852 - val_clarity_loss: 0.4630 - val_color_accuracy: 0.4924 - val_color_loss: 1.1969 - val_cut_accuracy: 0.5213 - val_cut_loss: 1.0863 - val_loss: 2.7465\n",
            "Epoch 42/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - clarity_accuracy: 0.7958 - clarity_loss: 0.4577 - color_accuracy: 0.4976 - color_loss: 1.1704 - cut_accuracy: 0.5308 - cut_loss: 1.0547 - loss: 2.6828 - val_clarity_accuracy: 0.7922 - val_clarity_loss: 0.4633 - val_color_accuracy: 0.4879 - val_color_loss: 1.2051 - val_cut_accuracy: 0.5261 - val_cut_loss: 1.0859 - val_loss: 2.7547\n",
            "Epoch 43/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - clarity_accuracy: 0.7995 - clarity_loss: 0.4455 - color_accuracy: 0.5099 - color_loss: 1.1669 - cut_accuracy: 0.5392 - cut_loss: 1.0418 - loss: 2.6543 - val_clarity_accuracy: 0.8019 - val_clarity_loss: 0.4478 - val_color_accuracy: 0.4906 - val_color_loss: 1.1978 - val_cut_accuracy: 0.5292 - val_cut_loss: 1.0811 - val_loss: 2.7272\n",
            "Epoch 44/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - clarity_accuracy: 0.7952 - clarity_loss: 0.4460 - color_accuracy: 0.5019 - color_loss: 1.1714 - cut_accuracy: 0.5387 - cut_loss: 1.0416 - loss: 2.6590 - val_clarity_accuracy: 0.8010 - val_clarity_loss: 0.4646 - val_color_accuracy: 0.4957 - val_color_loss: 1.2169 - val_cut_accuracy: 0.5194 - val_cut_loss: 1.0919 - val_loss: 2.7736\n",
            "Epoch 45/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - clarity_accuracy: 0.8012 - clarity_loss: 0.4397 - color_accuracy: 0.5026 - color_loss: 1.1620 - cut_accuracy: 0.5390 - cut_loss: 1.0343 - loss: 2.6360 - val_clarity_accuracy: 0.8129 - val_clarity_loss: 0.4380 - val_color_accuracy: 0.4945 - val_color_loss: 1.1917 - val_cut_accuracy: 0.5313 - val_cut_loss: 1.0738 - val_loss: 2.7039\n",
            "Epoch 46/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - clarity_accuracy: 0.7959 - clarity_loss: 0.4522 - color_accuracy: 0.5028 - color_loss: 1.1829 - cut_accuracy: 0.5348 - cut_loss: 1.0541 - loss: 2.6892 - val_clarity_accuracy: 0.8037 - val_clarity_loss: 0.4521 - val_color_accuracy: 0.4927 - val_color_loss: 1.1928 - val_cut_accuracy: 0.5265 - val_cut_loss: 1.0805 - val_loss: 2.7259\n",
            "Epoch 47/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - clarity_accuracy: 0.7955 - clarity_loss: 0.4486 - color_accuracy: 0.5098 - color_loss: 1.1687 - cut_accuracy: 0.5396 - cut_loss: 1.0490 - loss: 2.6662 - val_clarity_accuracy: 0.8044 - val_clarity_loss: 0.4532 - val_color_accuracy: 0.4918 - val_color_loss: 1.1969 - val_cut_accuracy: 0.5261 - val_cut_loss: 1.0870 - val_loss: 2.7376\n",
            "Epoch 48/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - clarity_accuracy: 0.8014 - clarity_loss: 0.4383 - color_accuracy: 0.5106 - color_loss: 1.1403 - cut_accuracy: 0.5468 - cut_loss: 1.0269 - loss: 2.6054 - val_clarity_accuracy: 0.8091 - val_clarity_loss: 0.4387 - val_color_accuracy: 0.4903 - val_color_loss: 1.1829 - val_cut_accuracy: 0.5295 - val_cut_loss: 1.0736 - val_loss: 2.6957\n",
            "Epoch 49/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - clarity_accuracy: 0.8034 - clarity_loss: 0.4288 - color_accuracy: 0.5086 - color_loss: 1.1493 - cut_accuracy: 0.5455 - cut_loss: 1.0305 - loss: 2.6085 - val_clarity_accuracy: 0.8104 - val_clarity_loss: 0.4377 - val_color_accuracy: 0.4985 - val_color_loss: 1.1919 - val_cut_accuracy: 0.5252 - val_cut_loss: 1.0787 - val_loss: 2.7086\n",
            "Epoch 50/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - clarity_accuracy: 0.8089 - clarity_loss: 0.4229 - color_accuracy: 0.5150 - color_loss: 1.1383 - cut_accuracy: 0.5510 - cut_loss: 1.0170 - loss: 2.5782 - val_clarity_accuracy: 0.8037 - val_clarity_loss: 0.4483 - val_color_accuracy: 0.4882 - val_color_loss: 1.2023 - val_cut_accuracy: 0.5343 - val_cut_loss: 1.0790 - val_loss: 2.7299\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clarity Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.85      0.76      1665\n",
            "           1       1.00      1.00      1.00      1708\n",
            "           2       0.78      0.95      0.86      1631\n",
            "           3       0.73      0.43      0.54      1710\n",
            "\n",
            "    accuracy                           0.80      6714\n",
            "   macro avg       0.80      0.81      0.79      6714\n",
            "weighted avg       0.80      0.80      0.79      6714\n",
            "\n",
            "Color Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.68      0.63       949\n",
            "           1       0.45      0.42      0.43       965\n",
            "           2       0.00      0.00      0.00       987\n",
            "           3       0.50      0.85      0.63      1001\n",
            "           4       0.46      0.87      0.61       972\n",
            "           5       0.63      0.22      0.33       482\n",
            "           7       0.00      0.00      0.00        24\n",
            "           8       0.20      0.04      0.07        23\n",
            "          10       0.00      0.00      0.00        31\n",
            "          11       0.73      0.09      0.16        91\n",
            "          12       0.53      0.44      0.48       265\n",
            "          13       0.00      0.00      0.00         8\n",
            "          14       0.53      0.10      0.17        77\n",
            "          15       0.50      0.14      0.22        50\n",
            "          16       0.51      0.49      0.50       109\n",
            "          17       0.00      0.00      0.00         5\n",
            "          18       0.20      0.06      0.09        71\n",
            "          19       0.00      0.00      0.00        22\n",
            "          20       0.43      0.59      0.50       172\n",
            "          21       0.12      0.05      0.07        22\n",
            "          22       0.00      0.00      0.00        16\n",
            "          23       0.75      0.59      0.66        70\n",
            "          24       0.45      0.61      0.52       219\n",
            "          25       0.00      0.00      0.00         8\n",
            "          26       0.51      0.37      0.43        62\n",
            "          27       0.00      0.00      0.00        13\n",
            "\n",
            "    accuracy                           0.50      6714\n",
            "   macro avg       0.31      0.25      0.25      6714\n",
            "weighted avg       0.43      0.50      0.43      6714\n",
            "\n",
            "Cut Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.40      0.46      1930\n",
            "           1       0.53      0.96      0.68      1944\n",
            "           2       0.00      0.00      0.00       440\n",
            "           3       0.71      0.09      0.16       216\n",
            "           4       0.00      0.00      0.00         8\n",
            "           5       0.00      0.00      0.00        11\n",
            "           7       0.57      0.51      0.54      1938\n",
            "           8       0.00      0.00      0.00        11\n",
            "           9       0.00      0.00      0.00        23\n",
            "          10       0.00      0.00      0.00       110\n",
            "          11       0.00      0.00      0.00         2\n",
            "          12       0.00      0.00      0.00        30\n",
            "          13       0.70      0.14      0.23        51\n",
            "\n",
            "    accuracy                           0.54      6714\n",
            "   macro avg       0.24      0.16      0.16      6714\n",
            "weighted avg       0.50      0.54      0.49      6714\n",
            "\n",
            "Model with increased layers saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/Final_reverse_One_hot_encoded_Processed_data (1).csv\")\n",
        "\n",
        "# Identify target columns\n",
        "target_columns = ['clarity', 'color', 'cut']\n",
        "\n",
        "# Drop target columns to get feature set\n",
        "X = df.drop(columns=target_columns)\n",
        "\n",
        "# OneHotEncode target labels\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "y_clarity = encoder.fit_transform(df[[\"clarity\"]])\n",
        "y_color = encoder.fit_transform(df[[\"color\"]])\n",
        "y_cut = encoder.fit_transform(df[[\"cut\"]])\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_clarity_train, y_clarity_test, y_color_train, y_color_test, y_cut_train, y_cut_test = train_test_split(\n",
        "    X, y_clarity, y_color, y_cut, test_size=0.4, random_state=42\n",
        ")\n",
        "\n",
        "X_val, X_test, y_clarity_val, y_clarity_test, y_color_val, y_color_test, y_cut_val, y_cut_test = train_test_split(\n",
        "    X_test, y_clarity_test, y_color_test, y_cut_test, test_size=0.5, random_state=42\n",
        ")\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert labels to NumPy arrays\n",
        "Y_clarity_train_array = np.array(y_clarity_train)\n",
        "Y_color_train_array = np.array(y_color_train)\n",
        "Y_cut_train_array = np.array(y_cut_train)\n",
        "\n",
        "Y_clarity_val_array = np.array(y_clarity_val)\n",
        "Y_color_val_array = np.array(y_color_val)\n",
        "Y_cut_val_array = np.array(y_cut_val)\n",
        "\n",
        "Y_clarity_test_array = np.array(y_clarity_test)\n",
        "Y_color_test_array = np.array(y_color_test)\n",
        "Y_cut_test_array = np.array(y_cut_test)\n",
        "\n",
        "\n",
        "# Define the model with larger layers and added linear layers\n",
        "input_layer = keras.Input(shape=(X_train_scaled.shape[1],))\n",
        "\n",
        "# First linear layer before activation\n",
        "x = layers.Dense(256, activation=\"linear\")(input_layer)  # Linear transformation\n",
        "x = layers.Dense(512, activation=\"relu\")(x)  # Increased layer size\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Dense(1024, activation=\"relu\")(x)  # Larger hidden layer\n",
        "x = layers.Dense(512, activation=\"linear\")(x)  # Another linear transformation\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Dense(256, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Dense(128, activation=\"relu\")(x)\n",
        "\n",
        "# Output layers (remains the same)\n",
        "clarity_output = layers.Dense(Y_clarity_train_array.shape[1], activation=\"softmax\", name=\"clarity\")(x)\n",
        "color_output = layers.Dense(Y_color_train_array.shape[1], activation=\"softmax\", name=\"color\")(x)\n",
        "cut_output = layers.Dense(Y_cut_train_array.shape[1], activation=\"softmax\", name=\"cut\")(x)\n",
        "\n",
        "# Compile the model\n",
        "model = keras.Model(inputs=input_layer, outputs=[clarity_output, color_output, cut_output])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss={\n",
        "        'clarity': 'categorical_crossentropy',\n",
        "        'color': 'categorical_crossentropy',\n",
        "        'cut': 'categorical_crossentropy'\n",
        "    },\n",
        "    metrics={\n",
        "        'clarity': 'accuracy',\n",
        "        'color': 'accuracy',\n",
        "        'cut': 'accuracy'\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train_scaled,\n",
        "    {\"clarity\": Y_clarity_train_array, \"color\": Y_color_train_array, \"cut\": Y_cut_train_array},\n",
        "    validation_data=(X_val_scaled, {\"clarity\": Y_clarity_val_array, \"color\": Y_color_val_array, \"cut\": Y_cut_val_array}),\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "Y_test_pred = model.predict(X_test_scaled)\n",
        "Y_test_pred = [np.argmax(pred, axis=1) for pred in Y_test_pred]  # Convert probabilities to class labels\n",
        "\n",
        "# Convert one-hot test labels back to class labels\n",
        "Y_test_true = [\n",
        "    np.argmax(Y_clarity_test_array, axis=1),\n",
        "    np.argmax(Y_color_test_array, axis=1),\n",
        "    np.argmax(Y_cut_test_array, axis=1)\n",
        "]\n",
        "\n",
        "# Generate classification reports\n",
        "for i, name in enumerate([\"Clarity\", \"Color\", \"Cut\"]):\n",
        "    print(f\"{name} Classification Report:\\n\", classification_report(Y_test_true[i], Y_test_pred[i]))\n",
        "\n",
        "# Save the model\n",
        "model.save(\"DNN_gemstone_quality_model_large.h5\")\n",
        "print(\"Model with increased layers saved successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5XFRsv9Zqbyh",
        "outputId": "05228828-7633-4560-d336-dedb15114a95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m226\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m58,112\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m131,584\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │        \u001b[38;5;34m525,312\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m524,800\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m131,328\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m32,896\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ clarity (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m516\u001b[0m │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ color (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)             │          \u001b[38;5;34m3,612\u001b[0m │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ cut (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │          \u001b[38;5;34m1,806\u001b[0m │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">226</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">58,112</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ clarity (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ color (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">3,612</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ cut (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,806</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,409,966\u001b[0m (5.38 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,409,966</span> (5.38 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,409,966\u001b[0m (5.38 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,409,966</span> (5.38 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 25ms/step - clarity_accuracy: 0.5007 - clarity_loss: 1.0203 - color_accuracy: 0.3086 - color_loss: 2.0168 - cut_accuracy: 0.3645 - cut_loss: 1.5592 - loss: 4.5963 - val_clarity_accuracy: 0.6046 - val_clarity_loss: 0.7666 - val_color_accuracy: 0.4220 - val_color_loss: 1.5298 - val_cut_accuracy: 0.4245 - val_cut_loss: 1.3459 - val_loss: 3.6431\n",
            "Epoch 2/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - clarity_accuracy: 0.5967 - clarity_loss: 0.7821 - color_accuracy: 0.3985 - color_loss: 1.5682 - cut_accuracy: 0.4217 - cut_loss: 1.3551 - loss: 3.7054 - val_clarity_accuracy: 0.6306 - val_clarity_loss: 0.7452 - val_color_accuracy: 0.4214 - val_color_loss: 1.4722 - val_cut_accuracy: 0.4330 - val_cut_loss: 1.3245 - val_loss: 3.5426\n",
            "Epoch 3/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 24ms/step - clarity_accuracy: 0.6283 - clarity_loss: 0.7463 - color_accuracy: 0.4194 - color_loss: 1.4932 - cut_accuracy: 0.4354 - cut_loss: 1.3181 - loss: 3.5577 - val_clarity_accuracy: 0.6500 - val_clarity_loss: 0.7055 - val_color_accuracy: 0.4261 - val_color_loss: 1.4187 - val_cut_accuracy: 0.4541 - val_cut_loss: 1.2966 - val_loss: 3.4215\n",
            "Epoch 4/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - clarity_accuracy: 0.6515 - clarity_loss: 0.7120 - color_accuracy: 0.4295 - color_loss: 1.4349 - cut_accuracy: 0.4489 - cut_loss: 1.2890 - loss: 3.4359 - val_clarity_accuracy: 0.6725 - val_clarity_loss: 0.6781 - val_color_accuracy: 0.4336 - val_color_loss: 1.4104 - val_cut_accuracy: 0.4519 - val_cut_loss: 1.2661 - val_loss: 3.3551\n",
            "Epoch 5/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - clarity_accuracy: 0.6618 - clarity_loss: 0.6824 - color_accuracy: 0.4349 - color_loss: 1.4072 - cut_accuracy: 0.4484 - cut_loss: 1.2659 - loss: 3.3555 - val_clarity_accuracy: 0.6711 - val_clarity_loss: 0.6763 - val_color_accuracy: 0.4407 - val_color_loss: 1.3888 - val_cut_accuracy: 0.4640 - val_cut_loss: 1.2547 - val_loss: 3.3204\n",
            "Epoch 6/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 22ms/step - clarity_accuracy: 0.6962 - clarity_loss: 0.6445 - color_accuracy: 0.4404 - color_loss: 1.3651 - cut_accuracy: 0.4695 - cut_loss: 1.2192 - loss: 3.2287 - val_clarity_accuracy: 0.6854 - val_clarity_loss: 0.6509 - val_color_accuracy: 0.4383 - val_color_loss: 1.3596 - val_cut_accuracy: 0.4650 - val_cut_loss: 1.2479 - val_loss: 3.2591\n",
            "Epoch 7/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - clarity_accuracy: 0.6964 - clarity_loss: 0.6280 - color_accuracy: 0.4427 - color_loss: 1.3520 - cut_accuracy: 0.4732 - cut_loss: 1.2137 - loss: 3.1937 - val_clarity_accuracy: 0.7057 - val_clarity_loss: 0.6123 - val_color_accuracy: 0.4501 - val_color_loss: 1.3609 - val_cut_accuracy: 0.4470 - val_cut_loss: 1.2061 - val_loss: 3.1799\n",
            "Epoch 8/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 22ms/step - clarity_accuracy: 0.7185 - clarity_loss: 0.5955 - color_accuracy: 0.4622 - color_loss: 1.3203 - cut_accuracy: 0.4893 - cut_loss: 1.1847 - loss: 3.1004 - val_clarity_accuracy: 0.7048 - val_clarity_loss: 0.6461 - val_color_accuracy: 0.4328 - val_color_loss: 1.3815 - val_cut_accuracy: 0.4742 - val_cut_loss: 1.2281 - val_loss: 3.2562\n",
            "Epoch 9/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 22ms/step - clarity_accuracy: 0.7329 - clarity_loss: 0.5793 - color_accuracy: 0.4646 - color_loss: 1.3017 - cut_accuracy: 0.4933 - cut_loss: 1.1638 - loss: 3.0448 - val_clarity_accuracy: 0.7183 - val_clarity_loss: 0.5899 - val_color_accuracy: 0.4541 - val_color_loss: 1.3253 - val_cut_accuracy: 0.4757 - val_cut_loss: 1.1927 - val_loss: 3.1084\n",
            "Epoch 10/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 23ms/step - clarity_accuracy: 0.7400 - clarity_loss: 0.5612 - color_accuracy: 0.4779 - color_loss: 1.2672 - cut_accuracy: 0.5038 - cut_loss: 1.1478 - loss: 2.9761 - val_clarity_accuracy: 0.7097 - val_clarity_loss: 0.6204 - val_color_accuracy: 0.4418 - val_color_loss: 1.3576 - val_cut_accuracy: 0.4827 - val_cut_loss: 1.2046 - val_loss: 3.1832\n",
            "Epoch 11/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 25ms/step - clarity_accuracy: 0.7499 - clarity_loss: 0.5320 - color_accuracy: 0.4806 - color_loss: 1.2653 - cut_accuracy: 0.5034 - cut_loss: 1.1229 - loss: 2.9202 - val_clarity_accuracy: 0.7374 - val_clarity_loss: 0.5646 - val_color_accuracy: 0.4705 - val_color_loss: 1.2882 - val_cut_accuracy: 0.4844 - val_cut_loss: 1.1739 - val_loss: 3.0273\n",
            "Epoch 12/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - clarity_accuracy: 0.7687 - clarity_loss: 0.5131 - color_accuracy: 0.4823 - color_loss: 1.2387 - cut_accuracy: 0.5137 - cut_loss: 1.1059 - loss: 2.8577 - val_clarity_accuracy: 0.7621 - val_clarity_loss: 0.5212 - val_color_accuracy: 0.4671 - val_color_loss: 1.2833 - val_cut_accuracy: 0.5095 - val_cut_loss: 1.1477 - val_loss: 2.9528\n",
            "Epoch 13/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - clarity_accuracy: 0.7755 - clarity_loss: 0.4903 - color_accuracy: 0.4845 - color_loss: 1.2273 - cut_accuracy: 0.5221 - cut_loss: 1.0864 - loss: 2.8040 - val_clarity_accuracy: 0.7602 - val_clarity_loss: 0.5286 - val_color_accuracy: 0.4632 - val_color_loss: 1.2978 - val_cut_accuracy: 0.4996 - val_cut_loss: 1.1522 - val_loss: 2.9791\n",
            "Epoch 14/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - clarity_accuracy: 0.7850 - clarity_loss: 0.4649 - color_accuracy: 0.4991 - color_loss: 1.1927 - cut_accuracy: 0.5373 - cut_loss: 1.0717 - loss: 2.7293 - val_clarity_accuracy: 0.7870 - val_clarity_loss: 0.4922 - val_color_accuracy: 0.4806 - val_color_loss: 1.2576 - val_cut_accuracy: 0.5235 - val_cut_loss: 1.1188 - val_loss: 2.8692\n",
            "Epoch 15/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 22ms/step - clarity_accuracy: 0.7951 - clarity_loss: 0.4584 - color_accuracy: 0.5004 - color_loss: 1.1943 - cut_accuracy: 0.5379 - cut_loss: 1.0538 - loss: 2.7066 - val_clarity_accuracy: 0.7668 - val_clarity_loss: 0.5102 - val_color_accuracy: 0.4830 - val_color_loss: 1.2752 - val_cut_accuracy: 0.4972 - val_cut_loss: 1.1373 - val_loss: 2.9232\n",
            "Epoch 16/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - clarity_accuracy: 0.7940 - clarity_loss: 0.4553 - color_accuracy: 0.4978 - color_loss: 1.1919 - cut_accuracy: 0.5379 - cut_loss: 1.0737 - loss: 2.7208 - val_clarity_accuracy: 0.7839 - val_clarity_loss: 0.4930 - val_color_accuracy: 0.4890 - val_color_loss: 1.2610 - val_cut_accuracy: 0.4860 - val_cut_loss: 1.1246 - val_loss: 2.8789\n",
            "Epoch 17/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - clarity_accuracy: 0.8128 - clarity_loss: 0.4246 - color_accuracy: 0.5162 - color_loss: 1.1591 - cut_accuracy: 0.5450 - cut_loss: 1.0429 - loss: 2.6265 - val_clarity_accuracy: 0.7846 - val_clarity_loss: 0.4808 - val_color_accuracy: 0.4803 - val_color_loss: 1.2738 - val_cut_accuracy: 0.5214 - val_cut_loss: 1.1335 - val_loss: 2.8888\n",
            "Epoch 18/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - clarity_accuracy: 0.8042 - clarity_loss: 0.4422 - color_accuracy: 0.5160 - color_loss: 1.1728 - cut_accuracy: 0.5433 - cut_loss: 1.0444 - loss: 2.6594 - val_clarity_accuracy: 0.7875 - val_clarity_loss: 0.4996 - val_color_accuracy: 0.4745 - val_color_loss: 1.2932 - val_cut_accuracy: 0.5174 - val_cut_loss: 1.1451 - val_loss: 2.9385\n",
            "Epoch 19/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 23ms/step - clarity_accuracy: 0.8155 - clarity_loss: 0.4250 - color_accuracy: 0.5053 - color_loss: 1.1709 - cut_accuracy: 0.5540 - cut_loss: 1.0374 - loss: 2.6333 - val_clarity_accuracy: 0.7946 - val_clarity_loss: 0.4741 - val_color_accuracy: 0.4879 - val_color_loss: 1.2624 - val_cut_accuracy: 0.5107 - val_cut_loss: 1.1290 - val_loss: 2.8662\n",
            "Epoch 20/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - clarity_accuracy: 0.8302 - clarity_loss: 0.3919 - color_accuracy: 0.5174 - color_loss: 1.1352 - cut_accuracy: 0.5551 - cut_loss: 1.0162 - loss: 2.5434 - val_clarity_accuracy: 0.7995 - val_clarity_loss: 0.4518 - val_color_accuracy: 0.4859 - val_color_loss: 1.2335 - val_cut_accuracy: 0.5240 - val_cut_loss: 1.1155 - val_loss: 2.8012\n",
            "Epoch 21/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - clarity_accuracy: 0.8270 - clarity_loss: 0.4006 - color_accuracy: 0.5168 - color_loss: 1.1461 - cut_accuracy: 0.5519 - cut_loss: 1.0193 - loss: 2.5660 - val_clarity_accuracy: 0.7971 - val_clarity_loss: 0.4570 - val_color_accuracy: 0.4929 - val_color_loss: 1.2597 - val_cut_accuracy: 0.5267 - val_cut_loss: 1.1238 - val_loss: 2.8410\n",
            "Epoch 22/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 23ms/step - clarity_accuracy: 0.8310 - clarity_loss: 0.3874 - color_accuracy: 0.5107 - color_loss: 1.1556 - cut_accuracy: 0.5596 - cut_loss: 1.0215 - loss: 2.5645 - val_clarity_accuracy: 0.7976 - val_clarity_loss: 0.4670 - val_color_accuracy: 0.4820 - val_color_loss: 1.2760 - val_cut_accuracy: 0.5223 - val_cut_loss: 1.1319 - val_loss: 2.8754\n",
            "Epoch 23/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - clarity_accuracy: 0.8369 - clarity_loss: 0.3775 - color_accuracy: 0.5219 - color_loss: 1.1414 - cut_accuracy: 0.5714 - cut_loss: 0.9959 - loss: 2.5149 - val_clarity_accuracy: 0.7974 - val_clarity_loss: 0.4696 - val_color_accuracy: 0.4854 - val_color_loss: 1.2889 - val_cut_accuracy: 0.5244 - val_cut_loss: 1.1189 - val_loss: 2.8779\n",
            "Epoch 24/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 27ms/step - clarity_accuracy: 0.8466 - clarity_loss: 0.3653 - color_accuracy: 0.5226 - color_loss: 1.1494 - cut_accuracy: 0.5617 - cut_loss: 1.0137 - loss: 2.5283 - val_clarity_accuracy: 0.8229 - val_clarity_loss: 0.4264 - val_color_accuracy: 0.4984 - val_color_loss: 1.2436 - val_cut_accuracy: 0.5368 - val_cut_loss: 1.1067 - val_loss: 2.7770\n",
            "Epoch 25/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 34ms/step - clarity_accuracy: 0.8492 - clarity_loss: 0.3569 - color_accuracy: 0.5311 - color_loss: 1.1442 - cut_accuracy: 0.5745 - cut_loss: 0.9899 - loss: 2.4911 - val_clarity_accuracy: 0.8181 - val_clarity_loss: 0.4200 - val_color_accuracy: 0.5119 - val_color_loss: 1.2482 - val_cut_accuracy: 0.5460 - val_cut_loss: 1.1078 - val_loss: 2.7765\n",
            "Epoch 26/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 32ms/step - clarity_accuracy: 0.8547 - clarity_loss: 0.3480 - color_accuracy: 0.5423 - color_loss: 1.1140 - cut_accuracy: 0.5730 - cut_loss: 0.9940 - loss: 2.4560 - val_clarity_accuracy: 0.8190 - val_clarity_loss: 0.4340 - val_color_accuracy: 0.4958 - val_color_loss: 1.2369 - val_cut_accuracy: 0.5386 - val_cut_loss: 1.1064 - val_loss: 2.7778\n",
            "Epoch 27/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 32ms/step - clarity_accuracy: 0.8533 - clarity_loss: 0.3494 - color_accuracy: 0.5355 - color_loss: 1.1244 - cut_accuracy: 0.5705 - cut_loss: 0.9929 - loss: 2.4667 - val_clarity_accuracy: 0.8254 - val_clarity_loss: 0.4165 - val_color_accuracy: 0.5012 - val_color_loss: 1.2218 - val_cut_accuracy: 0.5463 - val_cut_loss: 1.1043 - val_loss: 2.7431\n",
            "Epoch 28/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - clarity_accuracy: 0.8598 - clarity_loss: 0.3383 - color_accuracy: 0.5351 - color_loss: 1.1072 - cut_accuracy: 0.5756 - cut_loss: 0.9882 - loss: 2.4337 - val_clarity_accuracy: 0.8214 - val_clarity_loss: 0.4117 - val_color_accuracy: 0.4996 - val_color_loss: 1.2361 - val_cut_accuracy: 0.5354 - val_cut_loss: 1.1171 - val_loss: 2.7651\n",
            "Epoch 29/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 35ms/step - clarity_accuracy: 0.8605 - clarity_loss: 0.3286 - color_accuracy: 0.5413 - color_loss: 1.1015 - cut_accuracy: 0.5881 - cut_loss: 0.9647 - loss: 2.3948 - val_clarity_accuracy: 0.8248 - val_clarity_loss: 0.4005 - val_color_accuracy: 0.5101 - val_color_loss: 1.2465 - val_cut_accuracy: 0.5408 - val_cut_loss: 1.0958 - val_loss: 2.7431\n",
            "Epoch 30/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 34ms/step - clarity_accuracy: 0.8727 - clarity_loss: 0.3097 - color_accuracy: 0.5416 - color_loss: 1.0932 - cut_accuracy: 0.5815 - cut_loss: 0.9578 - loss: 2.3607 - val_clarity_accuracy: 0.8271 - val_clarity_loss: 0.4067 - val_color_accuracy: 0.5082 - val_color_loss: 1.2640 - val_cut_accuracy: 0.5200 - val_cut_loss: 1.1063 - val_loss: 2.7774\n",
            "Epoch 31/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 26ms/step - clarity_accuracy: 0.8704 - clarity_loss: 0.3209 - color_accuracy: 0.5406 - color_loss: 1.0992 - cut_accuracy: 0.5879 - cut_loss: 0.9594 - loss: 2.3795 - val_clarity_accuracy: 0.8237 - val_clarity_loss: 0.4209 - val_color_accuracy: 0.4966 - val_color_loss: 1.2683 - val_cut_accuracy: 0.5337 - val_cut_loss: 1.1080 - val_loss: 2.7974\n",
            "Epoch 32/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - clarity_accuracy: 0.8680 - clarity_loss: 0.3188 - color_accuracy: 0.5476 - color_loss: 1.1082 - cut_accuracy: 0.5792 - cut_loss: 0.9717 - loss: 2.3987 - val_clarity_accuracy: 0.8414 - val_clarity_loss: 0.3919 - val_color_accuracy: 0.5100 - val_color_loss: 1.2445 - val_cut_accuracy: 0.5505 - val_cut_loss: 1.1033 - val_loss: 2.7401\n",
            "Epoch 33/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - clarity_accuracy: 0.8731 - clarity_loss: 0.3048 - color_accuracy: 0.5581 - color_loss: 1.0770 - cut_accuracy: 0.5905 - cut_loss: 0.9522 - loss: 2.3340 - val_clarity_accuracy: 0.8310 - val_clarity_loss: 0.4108 - val_color_accuracy: 0.5061 - val_color_loss: 1.3117 - val_cut_accuracy: 0.5427 - val_cut_loss: 1.1119 - val_loss: 2.8347\n",
            "Epoch 34/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - clarity_accuracy: 0.8751 - clarity_loss: 0.3088 - color_accuracy: 0.5444 - color_loss: 1.1116 - cut_accuracy: 0.5891 - cut_loss: 0.9639 - loss: 2.3843 - val_clarity_accuracy: 0.8333 - val_clarity_loss: 0.4024 - val_color_accuracy: 0.5095 - val_color_loss: 1.2495 - val_cut_accuracy: 0.5432 - val_cut_loss: 1.1022 - val_loss: 2.7545\n",
            "Epoch 35/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 22ms/step - clarity_accuracy: 0.8726 - clarity_loss: 0.3152 - color_accuracy: 0.5521 - color_loss: 1.0972 - cut_accuracy: 0.5835 - cut_loss: 0.9659 - loss: 2.3784 - val_clarity_accuracy: 0.8348 - val_clarity_loss: 0.4024 - val_color_accuracy: 0.4970 - val_color_loss: 1.2739 - val_cut_accuracy: 0.5377 - val_cut_loss: 1.1347 - val_loss: 2.8117\n",
            "Epoch 36/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - clarity_accuracy: 0.8686 - clarity_loss: 0.3232 - color_accuracy: 0.5444 - color_loss: 1.1084 - cut_accuracy: 0.5842 - cut_loss: 0.9557 - loss: 2.3873 - val_clarity_accuracy: 0.8365 - val_clarity_loss: 0.3961 - val_color_accuracy: 0.5040 - val_color_loss: 1.2754 - val_cut_accuracy: 0.5331 - val_cut_loss: 1.1257 - val_loss: 2.7976\n",
            "Epoch 37/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - clarity_accuracy: 0.8753 - clarity_loss: 0.3084 - color_accuracy: 0.5440 - color_loss: 1.1046 - cut_accuracy: 0.5829 - cut_loss: 0.9599 - loss: 2.3728 - val_clarity_accuracy: 0.8400 - val_clarity_loss: 0.3904 - val_color_accuracy: 0.5189 - val_color_loss: 1.2777 - val_cut_accuracy: 0.5518 - val_cut_loss: 1.0957 - val_loss: 2.7641\n",
            "Epoch 38/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - clarity_accuracy: 0.8823 - clarity_loss: 0.2938 - color_accuracy: 0.5557 - color_loss: 1.0808 - cut_accuracy: 0.5947 - cut_loss: 0.9486 - loss: 2.3232 - val_clarity_accuracy: 0.8460 - val_clarity_loss: 0.3923 - val_color_accuracy: 0.5182 - val_color_loss: 1.2680 - val_cut_accuracy: 0.5502 - val_cut_loss: 1.1161 - val_loss: 2.7770\n",
            "Epoch 39/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 22ms/step - clarity_accuracy: 0.8819 - clarity_loss: 0.2849 - color_accuracy: 0.5541 - color_loss: 1.0949 - cut_accuracy: 0.5947 - cut_loss: 0.9450 - loss: 2.3248 - val_clarity_accuracy: 0.8301 - val_clarity_loss: 0.4410 - val_color_accuracy: 0.5077 - val_color_loss: 1.2959 - val_cut_accuracy: 0.5436 - val_cut_loss: 1.1546 - val_loss: 2.8921\n",
            "Epoch 40/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 22ms/step - clarity_accuracy: 0.8820 - clarity_loss: 0.2971 - color_accuracy: 0.5565 - color_loss: 1.0830 - cut_accuracy: 0.5980 - cut_loss: 0.9497 - loss: 2.3299 - val_clarity_accuracy: 0.8375 - val_clarity_loss: 0.3910 - val_color_accuracy: 0.5001 - val_color_loss: 1.2830 - val_cut_accuracy: 0.5405 - val_cut_loss: 1.1226 - val_loss: 2.7969\n",
            "Epoch 41/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - clarity_accuracy: 0.8841 - clarity_loss: 0.2888 - color_accuracy: 0.5586 - color_loss: 1.0682 - cut_accuracy: 0.5949 - cut_loss: 0.9422 - loss: 2.2991 - val_clarity_accuracy: 0.8365 - val_clarity_loss: 0.4087 - val_color_accuracy: 0.5109 - val_color_loss: 1.3054 - val_cut_accuracy: 0.5101 - val_cut_loss: 1.1338 - val_loss: 2.8477\n",
            "Epoch 42/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - clarity_accuracy: 0.8855 - clarity_loss: 0.2910 - color_accuracy: 0.5475 - color_loss: 1.0972 - cut_accuracy: 0.5868 - cut_loss: 0.9515 - loss: 2.3397 - val_clarity_accuracy: 0.8482 - val_clarity_loss: 0.3882 - val_color_accuracy: 0.5076 - val_color_loss: 1.3005 - val_cut_accuracy: 0.5505 - val_cut_loss: 1.1262 - val_loss: 2.8154\n",
            "Epoch 43/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 23ms/step - clarity_accuracy: 0.8859 - clarity_loss: 0.2944 - color_accuracy: 0.5530 - color_loss: 1.0903 - cut_accuracy: 0.5923 - cut_loss: 0.9618 - loss: 2.3465 - val_clarity_accuracy: 0.8426 - val_clarity_loss: 0.3669 - val_color_accuracy: 0.5156 - val_color_loss: 1.2574 - val_cut_accuracy: 0.5547 - val_cut_loss: 1.0933 - val_loss: 2.7179\n",
            "Epoch 44/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - clarity_accuracy: 0.8958 - clarity_loss: 0.2598 - color_accuracy: 0.5688 - color_loss: 1.0543 - cut_accuracy: 0.6032 - cut_loss: 0.9233 - loss: 2.2373 - val_clarity_accuracy: 0.8581 - val_clarity_loss: 0.3628 - val_color_accuracy: 0.5256 - val_color_loss: 1.2691 - val_cut_accuracy: 0.5602 - val_cut_loss: 1.1104 - val_loss: 2.7427\n",
            "Epoch 45/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - clarity_accuracy: 0.8932 - clarity_loss: 0.2761 - color_accuracy: 0.5535 - color_loss: 1.0880 - cut_accuracy: 0.5953 - cut_loss: 0.9499 - loss: 2.3140 - val_clarity_accuracy: 0.8414 - val_clarity_loss: 0.3885 - val_color_accuracy: 0.4857 - val_color_loss: 1.3210 - val_cut_accuracy: 0.5429 - val_cut_loss: 1.1221 - val_loss: 2.8321\n",
            "Epoch 46/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - clarity_accuracy: 0.8948 - clarity_loss: 0.2613 - color_accuracy: 0.5667 - color_loss: 1.0720 - cut_accuracy: 0.6027 - cut_loss: 0.9418 - loss: 2.2751 - val_clarity_accuracy: 0.8496 - val_clarity_loss: 0.3830 - val_color_accuracy: 0.5150 - val_color_loss: 1.2866 - val_cut_accuracy: 0.5581 - val_cut_loss: 1.1063 - val_loss: 2.7763\n",
            "Epoch 47/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 21ms/step - clarity_accuracy: 0.8938 - clarity_loss: 0.2715 - color_accuracy: 0.5563 - color_loss: 1.0868 - cut_accuracy: 0.5939 - cut_loss: 0.9451 - loss: 2.3034 - val_clarity_accuracy: 0.8454 - val_clarity_loss: 0.3831 - val_color_accuracy: 0.5252 - val_color_loss: 1.3190 - val_cut_accuracy: 0.5527 - val_cut_loss: 1.1261 - val_loss: 2.8287\n",
            "Epoch 48/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 24ms/step - clarity_accuracy: 0.8991 - clarity_loss: 0.2604 - color_accuracy: 0.5607 - color_loss: 1.0812 - cut_accuracy: 0.6060 - cut_loss: 0.9328 - loss: 2.2744 - val_clarity_accuracy: 0.8511 - val_clarity_loss: 0.3682 - val_color_accuracy: 0.5131 - val_color_loss: 1.3052 - val_cut_accuracy: 0.5487 - val_cut_loss: 1.0957 - val_loss: 2.7695\n",
            "Epoch 49/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 23ms/step - clarity_accuracy: 0.8977 - clarity_loss: 0.2645 - color_accuracy: 0.5580 - color_loss: 1.0819 - cut_accuracy: 0.6006 - cut_loss: 0.9301 - loss: 2.2765 - val_clarity_accuracy: 0.8549 - val_clarity_loss: 0.3886 - val_color_accuracy: 0.5182 - val_color_loss: 1.3379 - val_cut_accuracy: 0.5573 - val_cut_loss: 1.1311 - val_loss: 2.8583\n",
            "Epoch 50/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - clarity_accuracy: 0.8998 - clarity_loss: 0.2555 - color_accuracy: 0.5679 - color_loss: 1.0804 - cut_accuracy: 0.6094 - cut_loss: 0.9241 - loss: 2.2600 - val_clarity_accuracy: 0.8499 - val_clarity_loss: 0.3870 - val_color_accuracy: 0.5097 - val_color_loss: 1.3243 - val_cut_accuracy: 0.5661 - val_cut_loss: 1.1197 - val_loss: 2.8317\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clarity Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.83      0.79      1665\n",
            "           1       1.00      1.00      1.00      1708\n",
            "           2       0.86      0.96      0.91      1631\n",
            "           3       0.76      0.58      0.66      1710\n",
            "\n",
            "    accuracy                           0.84      6714\n",
            "   macro avg       0.84      0.84      0.84      6714\n",
            "weighted avg       0.84      0.84      0.84      6714\n",
            "\n",
            "Color Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.63      0.66       949\n",
            "           1       0.47      0.67      0.55       965\n",
            "           2       0.00      0.00      0.00       987\n",
            "           3       0.50      0.85      0.63      1001\n",
            "           4       0.49      0.89      0.63       972\n",
            "           5       0.62      0.20      0.30       482\n",
            "           7       0.00      0.00      0.00        24\n",
            "           8       0.50      0.04      0.08        23\n",
            "          10       0.00      0.00      0.00        31\n",
            "          11       0.50      0.16      0.25        91\n",
            "          12       0.51      0.42      0.46       265\n",
            "          13       0.00      0.00      0.00         8\n",
            "          14       0.29      0.05      0.09        77\n",
            "          15       0.45      0.20      0.28        50\n",
            "          16       0.61      0.39      0.47       109\n",
            "          17       0.00      0.00      0.00         5\n",
            "          18       0.00      0.00      0.00        71\n",
            "          19       0.00      0.00      0.00        22\n",
            "          20       0.49      0.30      0.37       172\n",
            "          21       0.20      0.05      0.07        22\n",
            "          22       0.00      0.00      0.00        16\n",
            "          23       0.81      0.49      0.61        70\n",
            "          24       0.44      0.63      0.52       219\n",
            "          25       0.00      0.00      0.00         8\n",
            "          26       0.67      0.16      0.26        62\n",
            "          27       0.00      0.00      0.00        13\n",
            "\n",
            "    accuracy                           0.52      6714\n",
            "   macro avg       0.32      0.24      0.24      6714\n",
            "weighted avg       0.44      0.52      0.45      6714\n",
            "\n",
            "Cut Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.44      0.50      1930\n",
            "           1       0.55      0.97      0.70      1944\n",
            "           2       0.00      0.00      0.00       440\n",
            "           3       0.48      0.15      0.23       216\n",
            "           4       0.00      0.00      0.00         8\n",
            "           5       0.00      0.00      0.00        11\n",
            "           7       0.62      0.54      0.58      1938\n",
            "           8       0.00      0.00      0.00        11\n",
            "           9       0.00      0.00      0.00        23\n",
            "          10       0.14      0.01      0.02       110\n",
            "          11       0.00      0.00      0.00         2\n",
            "          12       0.00      0.00      0.00        30\n",
            "          13       0.64      0.18      0.28        51\n",
            "\n",
            "    accuracy                           0.57      6714\n",
            "   macro avg       0.23      0.18      0.18      6714\n",
            "weighted avg       0.52      0.57      0.52      6714\n",
            "\n",
            "Model with increased layers saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/Final_reverse_One_hot_encoded_Processed_data (1).csv\")\n",
        "\n",
        "# Identify target columns\n",
        "target_columns = ['clarity', 'color', 'cut']\n",
        "\n",
        "# Drop target columns to get feature set\n",
        "X = df.drop(columns=target_columns)\n",
        "\n",
        "# OneHotEncode target labels\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "y_clarity = encoder.fit_transform(df[[\"clarity\"]])\n",
        "y_color = encoder.fit_transform(df[[\"color\"]])\n",
        "y_cut = encoder.fit_transform(df[[\"cut\"]])\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_clarity_train, y_clarity_test, y_color_train, y_color_test, y_cut_train, y_cut_test = train_test_split(\n",
        "    X, y_clarity, y_color, y_cut, test_size=0.4, random_state=42\n",
        ")\n",
        "\n",
        "X_val, X_test, y_clarity_val, y_clarity_test, y_color_val, y_color_test, y_cut_val, y_cut_test = train_test_split(\n",
        "    X_test, y_clarity_test, y_color_test, y_cut_test, test_size=0.5, random_state=42\n",
        ")\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert labels to NumPy arrays\n",
        "Y_clarity_train_array = np.array(y_clarity_train)\n",
        "Y_color_train_array = np.array(y_color_train)\n",
        "Y_cut_train_array = np.array(y_cut_train)\n",
        "\n",
        "Y_clarity_val_array = np.array(y_clarity_val)\n",
        "Y_color_val_array = np.array(y_color_val)\n",
        "Y_cut_val_array = np.array(y_cut_val)\n",
        "\n",
        "Y_clarity_test_array = np.array(y_clarity_test)\n",
        "Y_color_test_array = np.array(y_color_test)\n",
        "Y_cut_test_array = np.array(y_cut_test)\n",
        "\n",
        "\n",
        "# Define the model with larger layers and added linear layers\n",
        "input_layer = keras.Input(shape=(X_train_scaled.shape[1],))\n",
        "\n",
        "\n",
        "# First linear layer before activation\n",
        "x = layers.Dense(256, activation=\"linear\")(input_layer)  # Linear transformation\n",
        "x = layers.Dense(512, activation=\"relu\")(x)  # Increased layer size\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Dense(1024, activation=\"relu\")(x)  # Larger hidden layer\n",
        "x = layers.Dense(512, activation=\"linear\")(x)  # Another linear transformation\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Dense(256, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Dense(128, activation=\"relu\")(x)\n",
        "# Add a 64-unit layer after the 128-unit layer\n",
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "\n",
        "\n",
        "\n",
        "# Output layers (remains the same)\n",
        "clarity_output = layers.Dense(Y_clarity_train_array.shape[1], activation=\"softmax\", name=\"clarity\")(x)\n",
        "color_output = layers.Dense(Y_color_train_array.shape[1], activation=\"softmax\", name=\"color\")(x)\n",
        "cut_output = layers.Dense(Y_cut_train_array.shape[1], activation=\"softmax\", name=\"cut\")(x)\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model = keras.Model(inputs=input_layer, outputs=[clarity_output, color_output, cut_output])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss={\n",
        "        'clarity': 'categorical_crossentropy',\n",
        "        'color': 'categorical_crossentropy',\n",
        "        'cut': 'categorical_crossentropy'\n",
        "    },\n",
        "    metrics={\n",
        "        'clarity': 'accuracy',\n",
        "        'color': 'accuracy',\n",
        "        'cut': 'accuracy'\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train_scaled,\n",
        "    {\"clarity\": Y_clarity_train_array, \"color\": Y_color_train_array, \"cut\": Y_cut_train_array},\n",
        "    validation_data=(X_val_scaled, {\"clarity\": Y_clarity_val_array, \"color\": Y_color_val_array, \"cut\": Y_cut_val_array}),\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "Y_test_pred = model.predict(X_test_scaled)\n",
        "Y_test_pred = [np.argmax(pred, axis=1) for pred in Y_test_pred]  # Convert probabilities to class labels\n",
        "\n",
        "# Convert one-hot test labels back to class labels\n",
        "Y_test_true = [\n",
        "    np.argmax(Y_clarity_test_array, axis=1),\n",
        "    np.argmax(Y_color_test_array, axis=1),\n",
        "    np.argmax(Y_cut_test_array, axis=1)\n",
        "]\n",
        "\n",
        "# Generate classification reports\n",
        "for i, name in enumerate([\"Clarity\", \"Color\", \"Cut\"]):\n",
        "    print(f\"{name} Classification Report:\\n\", classification_report(Y_test_true[i], Y_test_pred[i]))\n",
        "\n",
        "# Save the model\n",
        "model.save(\"DNN_gemstone_quality_model_large.h5\")\n",
        "print(\"Model with increased layers saved successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "emR5XhcZvyQA",
        "outputId": "b7936821-cf1c-473a-fa33-8e60b695fe84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m226\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m58,112\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m131,584\u001b[0m │ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │        \u001b[38;5;34m525,312\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m524,800\u001b[0m │ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m131,328\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m32,896\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m8,256\u001b[0m │ dense_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ clarity (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m260\u001b[0m │ dense_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ color (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)             │          \u001b[38;5;34m1,820\u001b[0m │ dense_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ cut (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │            \u001b[38;5;34m910\u001b[0m │ dense_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">226</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">58,112</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ clarity (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │ dense_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ color (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,820</span> │ dense_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ cut (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">910</span> │ dense_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,415,278\u001b[0m (5.40 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,415,278</span> (5.40 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,415,278\u001b[0m (5.40 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,415,278</span> (5.40 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - clarity_accuracy: 0.4916 - clarity_loss: 1.0303 - color_accuracy: 0.3018 - color_loss: 2.0893 - cut_accuracy: 0.3721 - cut_loss: 1.5557 - loss: 4.6753 - val_clarity_accuracy: 0.5952 - val_clarity_loss: 0.7829 - val_color_accuracy: 0.3996 - val_color_loss: 1.5999 - val_cut_accuracy: 0.4285 - val_cut_loss: 1.3825 - val_loss: 3.7658\n",
            "Epoch 2/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - clarity_accuracy: 0.5981 - clarity_loss: 0.7894 - color_accuracy: 0.3918 - color_loss: 1.5852 - cut_accuracy: 0.4187 - cut_loss: 1.3634 - loss: 3.7381 - val_clarity_accuracy: 0.6032 - val_clarity_loss: 0.7740 - val_color_accuracy: 0.4051 - val_color_loss: 1.5375 - val_cut_accuracy: 0.3996 - val_cut_loss: 1.3563 - val_loss: 3.6685\n",
            "Epoch 3/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - clarity_accuracy: 0.6135 - clarity_loss: 0.7571 - color_accuracy: 0.4086 - color_loss: 1.5072 - cut_accuracy: 0.4308 - cut_loss: 1.3313 - loss: 3.5957 - val_clarity_accuracy: 0.6413 - val_clarity_loss: 0.7289 - val_color_accuracy: 0.4173 - val_color_loss: 1.4658 - val_cut_accuracy: 0.4450 - val_cut_loss: 1.3081 - val_loss: 3.5035\n",
            "Epoch 4/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - clarity_accuracy: 0.6403 - clarity_loss: 0.7293 - color_accuracy: 0.4159 - color_loss: 1.4707 - cut_accuracy: 0.4408 - cut_loss: 1.3102 - loss: 3.5101 - val_clarity_accuracy: 0.6470 - val_clarity_loss: 0.7051 - val_color_accuracy: 0.4209 - val_color_loss: 1.4485 - val_cut_accuracy: 0.4170 - val_cut_loss: 1.2950 - val_loss: 3.4492\n",
            "Epoch 5/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - clarity_accuracy: 0.6516 - clarity_loss: 0.7018 - color_accuracy: 0.4274 - color_loss: 1.4133 - cut_accuracy: 0.4468 - cut_loss: 1.2843 - loss: 3.3994 - val_clarity_accuracy: 0.6659 - val_clarity_loss: 0.6730 - val_color_accuracy: 0.4413 - val_color_loss: 1.4016 - val_cut_accuracy: 0.4666 - val_cut_loss: 1.2607 - val_loss: 3.3360\n",
            "Epoch 6/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - clarity_accuracy: 0.6770 - clarity_loss: 0.6627 - color_accuracy: 0.4418 - color_loss: 1.3835 - cut_accuracy: 0.4663 - cut_loss: 1.2411 - loss: 3.2872 - val_clarity_accuracy: 0.6854 - val_clarity_loss: 0.6602 - val_color_accuracy: 0.4377 - val_color_loss: 1.3813 - val_cut_accuracy: 0.4574 - val_cut_loss: 1.2511 - val_loss: 3.2934\n",
            "Epoch 7/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 23ms/step - clarity_accuracy: 0.6977 - clarity_loss: 0.6406 - color_accuracy: 0.4412 - color_loss: 1.3699 - cut_accuracy: 0.4678 - cut_loss: 1.2303 - loss: 3.2409 - val_clarity_accuracy: 0.6845 - val_clarity_loss: 0.6448 - val_color_accuracy: 0.4479 - val_color_loss: 1.3891 - val_cut_accuracy: 0.4687 - val_cut_loss: 1.2430 - val_loss: 3.2775\n",
            "Epoch 8/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - clarity_accuracy: 0.7068 - clarity_loss: 0.6090 - color_accuracy: 0.4509 - color_loss: 1.3253 - cut_accuracy: 0.4791 - cut_loss: 1.2012 - loss: 3.1354 - val_clarity_accuracy: 0.7084 - val_clarity_loss: 0.6120 - val_color_accuracy: 0.4604 - val_color_loss: 1.3124 - val_cut_accuracy: 0.4596 - val_cut_loss: 1.2192 - val_loss: 3.1442\n",
            "Epoch 9/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 22ms/step - clarity_accuracy: 0.7224 - clarity_loss: 0.6003 - color_accuracy: 0.4512 - color_loss: 1.3195 - cut_accuracy: 0.4754 - cut_loss: 1.1989 - loss: 3.1188 - val_clarity_accuracy: 0.7276 - val_clarity_loss: 0.5802 - val_color_accuracy: 0.4677 - val_color_loss: 1.3149 - val_cut_accuracy: 0.4864 - val_cut_loss: 1.1888 - val_loss: 3.0845\n",
            "Epoch 10/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 24ms/step - clarity_accuracy: 0.7379 - clarity_loss: 0.5587 - color_accuracy: 0.4744 - color_loss: 1.2817 - cut_accuracy: 0.5025 - cut_loss: 1.1536 - loss: 2.9941 - val_clarity_accuracy: 0.7246 - val_clarity_loss: 0.5879 - val_color_accuracy: 0.4628 - val_color_loss: 1.3263 - val_cut_accuracy: 0.4608 - val_cut_loss: 1.2006 - val_loss: 3.1153\n",
            "Epoch 11/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 23ms/step - clarity_accuracy: 0.7440 - clarity_loss: 0.5460 - color_accuracy: 0.4777 - color_loss: 1.2584 - cut_accuracy: 0.5072 - cut_loss: 1.1382 - loss: 2.9425 - val_clarity_accuracy: 0.7402 - val_clarity_loss: 0.5427 - val_color_accuracy: 0.4616 - val_color_loss: 1.2820 - val_cut_accuracy: 0.5033 - val_cut_loss: 1.1602 - val_loss: 2.9854\n",
            "Epoch 12/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 22ms/step - clarity_accuracy: 0.7621 - clarity_loss: 0.5209 - color_accuracy: 0.4796 - color_loss: 1.2388 - cut_accuracy: 0.5096 - cut_loss: 1.1198 - loss: 2.8796 - val_clarity_accuracy: 0.7536 - val_clarity_loss: 0.5430 - val_color_accuracy: 0.4647 - val_color_loss: 1.2969 - val_cut_accuracy: 0.4835 - val_cut_loss: 1.1723 - val_loss: 3.0127\n",
            "Epoch 13/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - clarity_accuracy: 0.7677 - clarity_loss: 0.5056 - color_accuracy: 0.4943 - color_loss: 1.2226 - cut_accuracy: 0.5271 - cut_loss: 1.0977 - loss: 2.8259 - val_clarity_accuracy: 0.7663 - val_clarity_loss: 0.5199 - val_color_accuracy: 0.4724 - val_color_loss: 1.2703 - val_cut_accuracy: 0.5095 - val_cut_loss: 1.1495 - val_loss: 2.9402\n",
            "Epoch 14/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - clarity_accuracy: 0.7821 - clarity_loss: 0.4813 - color_accuracy: 0.4874 - color_loss: 1.2135 - cut_accuracy: 0.5303 - cut_loss: 1.0838 - loss: 2.7787 - val_clarity_accuracy: 0.7659 - val_clarity_loss: 0.5110 - val_color_accuracy: 0.4800 - val_color_loss: 1.2741 - val_cut_accuracy: 0.5086 - val_cut_loss: 1.1413 - val_loss: 2.9266\n",
            "Epoch 15/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - clarity_accuracy: 0.7908 - clarity_loss: 0.4669 - color_accuracy: 0.5021 - color_loss: 1.1899 - cut_accuracy: 0.5452 - cut_loss: 1.0738 - loss: 2.7306 - val_clarity_accuracy: 0.7770 - val_clarity_loss: 0.4954 - val_color_accuracy: 0.4800 - val_color_loss: 1.2744 - val_cut_accuracy: 0.4833 - val_cut_loss: 1.1409 - val_loss: 2.9110\n",
            "Epoch 16/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 23ms/step - clarity_accuracy: 0.7918 - clarity_loss: 0.4558 - color_accuracy: 0.5014 - color_loss: 1.1961 - cut_accuracy: 0.5390 - cut_loss: 1.0610 - loss: 2.7130 - val_clarity_accuracy: 0.7574 - val_clarity_loss: 0.5297 - val_color_accuracy: 0.4757 - val_color_loss: 1.3006 - val_cut_accuracy: 0.4626 - val_cut_loss: 1.1682 - val_loss: 2.9989\n",
            "Epoch 17/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 24ms/step - clarity_accuracy: 0.8035 - clarity_loss: 0.4428 - color_accuracy: 0.5075 - color_loss: 1.1841 - cut_accuracy: 0.5443 - cut_loss: 1.0562 - loss: 2.6832 - val_clarity_accuracy: 0.7925 - val_clarity_loss: 0.4789 - val_color_accuracy: 0.4909 - val_color_loss: 1.2539 - val_cut_accuracy: 0.5153 - val_cut_loss: 1.1300 - val_loss: 2.8634\n",
            "Epoch 18/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - clarity_accuracy: 0.8152 - clarity_loss: 0.4196 - color_accuracy: 0.5091 - color_loss: 1.1624 - cut_accuracy: 0.5561 - cut_loss: 1.0334 - loss: 2.6153 - val_clarity_accuracy: 0.7870 - val_clarity_loss: 0.4724 - val_color_accuracy: 0.4911 - val_color_loss: 1.2654 - val_cut_accuracy: 0.5150 - val_cut_loss: 1.1240 - val_loss: 2.8620\n",
            "Epoch 19/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - clarity_accuracy: 0.8295 - clarity_loss: 0.4062 - color_accuracy: 0.5169 - color_loss: 1.1462 - cut_accuracy: 0.5571 - cut_loss: 1.0204 - loss: 2.5728 - val_clarity_accuracy: 0.7995 - val_clarity_loss: 0.4713 - val_color_accuracy: 0.4942 - val_color_loss: 1.2371 - val_cut_accuracy: 0.5328 - val_cut_loss: 1.1088 - val_loss: 2.8176\n",
            "Epoch 20/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - clarity_accuracy: 0.8260 - clarity_loss: 0.4003 - color_accuracy: 0.5179 - color_loss: 1.1514 - cut_accuracy: 0.5456 - cut_loss: 1.0285 - loss: 2.5801 - val_clarity_accuracy: 0.7976 - val_clarity_loss: 0.4680 - val_color_accuracy: 0.4893 - val_color_loss: 1.2362 - val_cut_accuracy: 0.5343 - val_cut_loss: 1.1113 - val_loss: 2.8162\n",
            "Epoch 21/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - clarity_accuracy: 0.8366 - clarity_loss: 0.3853 - color_accuracy: 0.5327 - color_loss: 1.1294 - cut_accuracy: 0.5643 - cut_loss: 1.0161 - loss: 2.5309 - val_clarity_accuracy: 0.7925 - val_clarity_loss: 0.4615 - val_color_accuracy: 0.4884 - val_color_loss: 1.2501 - val_cut_accuracy: 0.5174 - val_cut_loss: 1.1273 - val_loss: 2.8393\n",
            "Epoch 22/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - clarity_accuracy: 0.8358 - clarity_loss: 0.3868 - color_accuracy: 0.5304 - color_loss: 1.1308 - cut_accuracy: 0.5723 - cut_loss: 1.0119 - loss: 2.5294 - val_clarity_accuracy: 0.8092 - val_clarity_loss: 0.4555 - val_color_accuracy: 0.4900 - val_color_loss: 1.2523 - val_cut_accuracy: 0.5226 - val_cut_loss: 1.1162 - val_loss: 2.8242\n",
            "Epoch 23/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 22ms/step - clarity_accuracy: 0.8430 - clarity_loss: 0.3735 - color_accuracy: 0.5247 - color_loss: 1.1366 - cut_accuracy: 0.5564 - cut_loss: 1.0146 - loss: 2.5247 - val_clarity_accuracy: 0.8198 - val_clarity_loss: 0.4251 - val_color_accuracy: 0.5039 - val_color_loss: 1.2295 - val_cut_accuracy: 0.5402 - val_cut_loss: 1.1045 - val_loss: 2.7594\n",
            "Epoch 24/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - clarity_accuracy: 0.8445 - clarity_loss: 0.3603 - color_accuracy: 0.5294 - color_loss: 1.1180 - cut_accuracy: 0.5722 - cut_loss: 0.9959 - loss: 2.4741 - val_clarity_accuracy: 0.8202 - val_clarity_loss: 0.4219 - val_color_accuracy: 0.5052 - val_color_loss: 1.2385 - val_cut_accuracy: 0.5390 - val_cut_loss: 1.1069 - val_loss: 2.7677\n",
            "Epoch 25/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - clarity_accuracy: 0.8492 - clarity_loss: 0.3607 - color_accuracy: 0.5375 - color_loss: 1.1084 - cut_accuracy: 0.5795 - cut_loss: 0.9914 - loss: 2.4605 - val_clarity_accuracy: 0.8186 - val_clarity_loss: 0.4364 - val_color_accuracy: 0.4966 - val_color_loss: 1.2340 - val_cut_accuracy: 0.5322 - val_cut_loss: 1.0955 - val_loss: 2.7662\n",
            "Epoch 26/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - clarity_accuracy: 0.8535 - clarity_loss: 0.3461 - color_accuracy: 0.5380 - color_loss: 1.0914 - cut_accuracy: 0.5838 - cut_loss: 0.9753 - loss: 2.4129 - val_clarity_accuracy: 0.8238 - val_clarity_loss: 0.4135 - val_color_accuracy: 0.5115 - val_color_loss: 1.2128 - val_cut_accuracy: 0.5399 - val_cut_loss: 1.0828 - val_loss: 2.7093\n",
            "Epoch 27/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - clarity_accuracy: 0.8609 - clarity_loss: 0.3353 - color_accuracy: 0.5383 - color_loss: 1.0831 - cut_accuracy: 0.5776 - cut_loss: 0.9760 - loss: 2.3945 - val_clarity_accuracy: 0.8253 - val_clarity_loss: 0.4308 - val_color_accuracy: 0.4930 - val_color_loss: 1.2452 - val_cut_accuracy: 0.5371 - val_cut_loss: 1.0977 - val_loss: 2.7741\n",
            "Epoch 28/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 21ms/step - clarity_accuracy: 0.8652 - clarity_loss: 0.3242 - color_accuracy: 0.5465 - color_loss: 1.0918 - cut_accuracy: 0.5848 - cut_loss: 0.9713 - loss: 2.3873 - val_clarity_accuracy: 0.8338 - val_clarity_loss: 0.3959 - val_color_accuracy: 0.5164 - val_color_loss: 1.2126 - val_cut_accuracy: 0.5487 - val_cut_loss: 1.0690 - val_loss: 2.6777\n",
            "Epoch 29/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - clarity_accuracy: 0.8671 - clarity_loss: 0.3248 - color_accuracy: 0.5441 - color_loss: 1.0781 - cut_accuracy: 0.5934 - cut_loss: 0.9555 - loss: 2.3585 - val_clarity_accuracy: 0.8146 - val_clarity_loss: 0.4365 - val_color_accuracy: 0.4987 - val_color_loss: 1.2286 - val_cut_accuracy: 0.5354 - val_cut_loss: 1.0948 - val_loss: 2.7603\n",
            "Epoch 30/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - clarity_accuracy: 0.8690 - clarity_loss: 0.3236 - color_accuracy: 0.5467 - color_loss: 1.0919 - cut_accuracy: 0.5903 - cut_loss: 0.9610 - loss: 2.3764 - val_clarity_accuracy: 0.8232 - val_clarity_loss: 0.4329 - val_color_accuracy: 0.5043 - val_color_loss: 1.2703 - val_cut_accuracy: 0.5408 - val_cut_loss: 1.1235 - val_loss: 2.8269\n",
            "Epoch 31/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - clarity_accuracy: 0.8726 - clarity_loss: 0.3119 - color_accuracy: 0.5518 - color_loss: 1.0768 - cut_accuracy: 0.5890 - cut_loss: 0.9708 - loss: 2.3595 - val_clarity_accuracy: 0.8298 - val_clarity_loss: 0.4191 - val_color_accuracy: 0.5103 - val_color_loss: 1.2436 - val_cut_accuracy: 0.5497 - val_cut_loss: 1.0954 - val_loss: 2.7583\n",
            "Epoch 32/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 23ms/step - clarity_accuracy: 0.8761 - clarity_loss: 0.3045 - color_accuracy: 0.5507 - color_loss: 1.0781 - cut_accuracy: 0.5945 - cut_loss: 0.9458 - loss: 2.3285 - val_clarity_accuracy: 0.8354 - val_clarity_loss: 0.4204 - val_color_accuracy: 0.5121 - val_color_loss: 1.2411 - val_cut_accuracy: 0.5490 - val_cut_loss: 1.1080 - val_loss: 2.7699\n",
            "Epoch 33/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 23ms/step - clarity_accuracy: 0.8801 - clarity_loss: 0.3023 - color_accuracy: 0.5540 - color_loss: 1.0707 - cut_accuracy: 0.5899 - cut_loss: 0.9547 - loss: 2.3277 - val_clarity_accuracy: 0.8384 - val_clarity_loss: 0.4028 - val_color_accuracy: 0.5130 - val_color_loss: 1.2456 - val_cut_accuracy: 0.5506 - val_cut_loss: 1.0771 - val_loss: 2.7259\n",
            "Epoch 34/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 25ms/step - clarity_accuracy: 0.8828 - clarity_loss: 0.2948 - color_accuracy: 0.5626 - color_loss: 1.0680 - cut_accuracy: 0.6013 - cut_loss: 0.9345 - loss: 2.2973 - val_clarity_accuracy: 0.8403 - val_clarity_loss: 0.3913 - val_color_accuracy: 0.5109 - val_color_loss: 1.2113 - val_cut_accuracy: 0.5493 - val_cut_loss: 1.0849 - val_loss: 2.6879\n",
            "Epoch 35/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - clarity_accuracy: 0.8871 - clarity_loss: 0.2848 - color_accuracy: 0.5640 - color_loss: 1.0587 - cut_accuracy: 0.5983 - cut_loss: 0.9356 - loss: 2.2791 - val_clarity_accuracy: 0.8377 - val_clarity_loss: 0.4061 - val_color_accuracy: 0.5100 - val_color_loss: 1.2486 - val_cut_accuracy: 0.5420 - val_cut_loss: 1.1052 - val_loss: 2.7603\n",
            "Epoch 36/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - clarity_accuracy: 0.8831 - clarity_loss: 0.2939 - color_accuracy: 0.5584 - color_loss: 1.0602 - cut_accuracy: 0.5922 - cut_loss: 0.9532 - loss: 2.3073 - val_clarity_accuracy: 0.8260 - val_clarity_loss: 0.4027 - val_color_accuracy: 0.5083 - val_color_loss: 1.2286 - val_cut_accuracy: 0.5506 - val_cut_loss: 1.0754 - val_loss: 2.7072\n",
            "Epoch 37/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - clarity_accuracy: 0.8877 - clarity_loss: 0.2778 - color_accuracy: 0.5626 - color_loss: 1.0566 - cut_accuracy: 0.6003 - cut_loss: 0.9338 - loss: 2.2682 - val_clarity_accuracy: 0.8429 - val_clarity_loss: 0.4106 - val_color_accuracy: 0.5101 - val_color_loss: 1.2379 - val_cut_accuracy: 0.5502 - val_cut_loss: 1.0997 - val_loss: 2.7486\n",
            "Epoch 38/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - clarity_accuracy: 0.8858 - clarity_loss: 0.2913 - color_accuracy: 0.5629 - color_loss: 1.0637 - cut_accuracy: 0.6056 - cut_loss: 0.9297 - loss: 2.2848 - val_clarity_accuracy: 0.8321 - val_clarity_loss: 0.3947 - val_color_accuracy: 0.5116 - val_color_loss: 1.2566 - val_cut_accuracy: 0.5499 - val_cut_loss: 1.0969 - val_loss: 2.7485\n",
            "Epoch 39/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - clarity_accuracy: 0.8900 - clarity_loss: 0.2788 - color_accuracy: 0.5622 - color_loss: 1.0689 - cut_accuracy: 0.6020 - cut_loss: 0.9399 - loss: 2.2876 - val_clarity_accuracy: 0.8430 - val_clarity_loss: 0.3944 - val_color_accuracy: 0.5095 - val_color_loss: 1.2347 - val_cut_accuracy: 0.5550 - val_cut_loss: 1.0848 - val_loss: 2.7140\n",
            "Epoch 40/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 22ms/step - clarity_accuracy: 0.8990 - clarity_loss: 0.2687 - color_accuracy: 0.5733 - color_loss: 1.0476 - cut_accuracy: 0.6142 - cut_loss: 0.9230 - loss: 2.2392 - val_clarity_accuracy: 0.8435 - val_clarity_loss: 0.3848 - val_color_accuracy: 0.5150 - val_color_loss: 1.2421 - val_cut_accuracy: 0.5530 - val_cut_loss: 1.0980 - val_loss: 2.7249\n",
            "Epoch 41/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - clarity_accuracy: 0.8961 - clarity_loss: 0.2648 - color_accuracy: 0.5606 - color_loss: 1.0502 - cut_accuracy: 0.6080 - cut_loss: 0.9328 - loss: 2.2478 - val_clarity_accuracy: 0.8564 - val_clarity_loss: 0.3658 - val_color_accuracy: 0.5250 - val_color_loss: 1.2029 - val_cut_accuracy: 0.5585 - val_cut_loss: 1.0741 - val_loss: 2.6428\n",
            "Epoch 42/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - clarity_accuracy: 0.9011 - clarity_loss: 0.2564 - color_accuracy: 0.5667 - color_loss: 1.0516 - cut_accuracy: 0.6017 - cut_loss: 0.9254 - loss: 2.2334 - val_clarity_accuracy: 0.8522 - val_clarity_loss: 0.3891 - val_color_accuracy: 0.5115 - val_color_loss: 1.2584 - val_cut_accuracy: 0.5575 - val_cut_loss: 1.1073 - val_loss: 2.7552\n",
            "Epoch 43/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - clarity_accuracy: 0.8952 - clarity_loss: 0.2814 - color_accuracy: 0.5671 - color_loss: 1.0552 - cut_accuracy: 0.5971 - cut_loss: 0.9353 - loss: 2.2719 - val_clarity_accuracy: 0.8548 - val_clarity_loss: 0.3869 - val_color_accuracy: 0.5204 - val_color_loss: 1.2571 - val_cut_accuracy: 0.5634 - val_cut_loss: 1.0977 - val_loss: 2.7420\n",
            "Epoch 44/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - clarity_accuracy: 0.9041 - clarity_loss: 0.2568 - color_accuracy: 0.5696 - color_loss: 1.0395 - cut_accuracy: 0.6128 - cut_loss: 0.9076 - loss: 2.2039 - val_clarity_accuracy: 0.8481 - val_clarity_loss: 0.3742 - val_color_accuracy: 0.5153 - val_color_loss: 1.2658 - val_cut_accuracy: 0.5587 - val_cut_loss: 1.0700 - val_loss: 2.7100\n",
            "Epoch 45/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - clarity_accuracy: 0.9015 - clarity_loss: 0.2595 - color_accuracy: 0.5738 - color_loss: 1.0331 - cut_accuracy: 0.6116 - cut_loss: 0.9164 - loss: 2.2090 - val_clarity_accuracy: 0.8558 - val_clarity_loss: 0.3821 - val_color_accuracy: 0.5223 - val_color_loss: 1.2461 - val_cut_accuracy: 0.5633 - val_cut_loss: 1.0886 - val_loss: 2.7169\n",
            "Epoch 46/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - clarity_accuracy: 0.9067 - clarity_loss: 0.2447 - color_accuracy: 0.5684 - color_loss: 1.0267 - cut_accuracy: 0.6074 - cut_loss: 0.9091 - loss: 2.1806 - val_clarity_accuracy: 0.8563 - val_clarity_loss: 0.3726 - val_color_accuracy: 0.5273 - val_color_loss: 1.2488 - val_cut_accuracy: 0.5655 - val_cut_loss: 1.0720 - val_loss: 2.6937\n",
            "Epoch 47/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 23ms/step - clarity_accuracy: 0.8979 - clarity_loss: 0.2580 - color_accuracy: 0.5752 - color_loss: 1.0403 - cut_accuracy: 0.6045 - cut_loss: 0.9224 - loss: 2.2207 - val_clarity_accuracy: 0.8482 - val_clarity_loss: 0.3795 - val_color_accuracy: 0.5244 - val_color_loss: 1.2305 - val_cut_accuracy: 0.5590 - val_cut_loss: 1.0882 - val_loss: 2.6983\n",
            "Epoch 48/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 23ms/step - clarity_accuracy: 0.9047 - clarity_loss: 0.2496 - color_accuracy: 0.5780 - color_loss: 1.0198 - cut_accuracy: 0.6122 - cut_loss: 0.9205 - loss: 2.1900 - val_clarity_accuracy: 0.8546 - val_clarity_loss: 0.3709 - val_color_accuracy: 0.5177 - val_color_loss: 1.2422 - val_cut_accuracy: 0.5576 - val_cut_loss: 1.0928 - val_loss: 2.7062\n",
            "Epoch 49/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 22ms/step - clarity_accuracy: 0.9065 - clarity_loss: 0.2414 - color_accuracy: 0.5834 - color_loss: 1.0319 - cut_accuracy: 0.6191 - cut_loss: 0.9098 - loss: 2.1831 - val_clarity_accuracy: 0.8581 - val_clarity_loss: 0.3844 - val_color_accuracy: 0.5134 - val_color_loss: 1.2402 - val_cut_accuracy: 0.5640 - val_cut_loss: 1.0976 - val_loss: 2.7223\n",
            "Epoch 50/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - clarity_accuracy: 0.9110 - clarity_loss: 0.2396 - color_accuracy: 0.5809 - color_loss: 1.0128 - cut_accuracy: 0.6128 - cut_loss: 0.9086 - loss: 2.1611 - val_clarity_accuracy: 0.8576 - val_clarity_loss: 0.3834 - val_color_accuracy: 0.5110 - val_color_loss: 1.2556 - val_cut_accuracy: 0.5618 - val_cut_loss: 1.1094 - val_loss: 2.7487\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clarity Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.77      0.79      1665\n",
            "           1       1.00      1.00      1.00      1708\n",
            "           2       0.84      0.97      0.90      1631\n",
            "           3       0.75      0.67      0.71      1710\n",
            "\n",
            "    accuracy                           0.85      6714\n",
            "   macro avg       0.85      0.85      0.85      6714\n",
            "weighted avg       0.85      0.85      0.85      6714\n",
            "\n",
            "Color Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.75      0.68       949\n",
            "           1       0.48      0.39      0.43       965\n",
            "           2       0.00      0.00      0.00       987\n",
            "           3       0.50      0.85      0.63      1001\n",
            "           4       0.49      0.92      0.63       972\n",
            "           5       0.69      0.19      0.30       482\n",
            "           7       0.00      0.00      0.00        24\n",
            "           8       0.45      0.22      0.29        23\n",
            "          10       0.00      0.00      0.00        31\n",
            "          11       0.46      0.35      0.40        91\n",
            "          12       0.53      0.55      0.54       265\n",
            "          13       0.00      0.00      0.00         8\n",
            "          14       0.52      0.22      0.31        77\n",
            "          15       0.47      0.14      0.22        50\n",
            "          16       0.48      0.59      0.53       109\n",
            "          17       0.00      0.00      0.00         5\n",
            "          18       0.00      0.00      0.00        71\n",
            "          19       0.33      0.05      0.08        22\n",
            "          20       0.44      0.53      0.48       172\n",
            "          21       0.00      0.00      0.00        22\n",
            "          22       0.00      0.00      0.00        16\n",
            "          23       0.67      0.53      0.59        70\n",
            "          24       0.44      0.56      0.49       219\n",
            "          25       0.00      0.00      0.00         8\n",
            "          26       0.47      0.24      0.32        62\n",
            "          27       0.00      0.00      0.00        13\n",
            "\n",
            "    accuracy                           0.52      6714\n",
            "   macro avg       0.31      0.27      0.27      6714\n",
            "weighted avg       0.44      0.52      0.44      6714\n",
            "\n",
            "Cut Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.39      0.47      1930\n",
            "           1       0.54      0.98      0.70      1944\n",
            "           2       0.00      0.00      0.00       440\n",
            "           3       0.55      0.17      0.26       216\n",
            "           4       0.00      0.00      0.00         8\n",
            "           5       0.00      0.00      0.00        11\n",
            "           7       0.61      0.59      0.60      1938\n",
            "           8       0.00      0.00      0.00        11\n",
            "           9       0.00      0.00      0.00        23\n",
            "          10       0.00      0.00      0.00       110\n",
            "          11       0.00      0.00      0.00         2\n",
            "          12       0.00      0.00      0.00        30\n",
            "          13       0.64      0.14      0.23        51\n",
            "\n",
            "    accuracy                           0.57      6714\n",
            "   macro avg       0.23      0.17      0.17      6714\n",
            "weighted avg       0.53      0.57      0.52      6714\n",
            "\n",
            "Model with increased layers saved successfully.\n"
          ]
        }
      ]
    }
  ]
}