{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>total_price</th>\n",
       "      <th>carat</th>\n",
       "      <th>price_per_carat</th>\n",
       "      <th>color</th>\n",
       "      <th>shape</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>clarity</th>\n",
       "      <th>cut</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>origin</th>\n",
       "      <th>treatment</th>\n",
       "      <th>cut_quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blue Sapphire</td>\n",
       "      <td>902</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Princess</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>4.21</td>\n",
       "      <td>Very Slightly Included</td>\n",
       "      <td>Princess Cut</td>\n",
       "      <td>Vivid</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Heated</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blue Sapphire</td>\n",
       "      <td>1008</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>Greyish Blue</td>\n",
       "      <td>Pear</td>\n",
       "      <td>7.33</td>\n",
       "      <td>4.84</td>\n",
       "      <td>3.57</td>\n",
       "      <td>Very Slightly Included</td>\n",
       "      <td>Mixed Brilliant</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Montana</td>\n",
       "      <td>No Enhancement</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Blue Sapphire</td>\n",
       "      <td>1290</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>Bluish Grey</td>\n",
       "      <td>Cushion</td>\n",
       "      <td>6.86</td>\n",
       "      <td>5.74</td>\n",
       "      <td>3.99</td>\n",
       "      <td>Slightly Included</td>\n",
       "      <td>Mixed Brilliant</td>\n",
       "      <td>Medium Light</td>\n",
       "      <td>Montana</td>\n",
       "      <td>Heated</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blue Sapphire</td>\n",
       "      <td>3743</td>\n",
       "      <td>2.13</td>\n",
       "      <td>1757.0</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Princess</td>\n",
       "      <td>7.17</td>\n",
       "      <td>7.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>Eye Clean</td>\n",
       "      <td>Step Cut</td>\n",
       "      <td>Vivid</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Heated</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blue Sapphire</td>\n",
       "      <td>2314</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>Greyish Blue</td>\n",
       "      <td>Cushion</td>\n",
       "      <td>8.37</td>\n",
       "      <td>6.48</td>\n",
       "      <td>3.68</td>\n",
       "      <td>Very Slightly Included</td>\n",
       "      <td>Mixed Brilliant</td>\n",
       "      <td>Intense</td>\n",
       "      <td>Montana</td>\n",
       "      <td>No Enhancement</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            type  total_price  carat  price_per_carat         color     shape  \\\n",
       "0  Blue Sapphire          902   0.82           1100.0          Blue  Princess   \n",
       "1  Blue Sapphire         1008   0.84           1200.0  Greyish Blue      Pear   \n",
       "2  Blue Sapphire         1290   1.29           1000.0   Bluish Grey   Cushion   \n",
       "3  Blue Sapphire         3743   2.13           1757.0          Blue  Princess   \n",
       "4  Blue Sapphire         2314   1.78           1300.0  Greyish Blue   Cushion   \n",
       "\n",
       "   length  width  height                 clarity              cut  \\\n",
       "0    7.00   7.00    4.21  Very Slightly Included     Princess Cut   \n",
       "1    7.33   4.84    3.57  Very Slightly Included  Mixed Brilliant   \n",
       "2    6.86   5.74    3.99       Slightly Included  Mixed Brilliant   \n",
       "3    7.17   7.13    4.10               Eye Clean         Step Cut   \n",
       "4    8.37   6.48    3.68  Very Slightly Included  Mixed Brilliant   \n",
       "\n",
       "  color_intensity    origin       treatment cut_quality  \n",
       "0           Vivid  Thailand          Heated        Good  \n",
       "1          Medium   Montana  No Enhancement   Excellent  \n",
       "2    Medium Light   Montana          Heated        Good  \n",
       "3           Vivid  Thailand          Heated        Good  \n",
       "4         Intense   Montana  No Enhancement        Good  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"full_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = df.drop(['length', 'width', 'height'], axis='columns')\n",
    "X = df[['carat','price_per_carat', 'color', 'shape', 'clarity', 'cut', 'color_intensity', 'origin', 'treatment','cut_quality','type']]\n",
    "y = df['total_price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carat                      float64\n",
      "cut_quality_encoded        float64\n",
      "shape_encoded              float64\n",
      "origin_encoded             float64\n",
      "color_encoded              float64\n",
      "color_intensity_encoded    float64\n",
      "clarity_encoded            float64\n",
      "cut_encoded                float64\n",
      "treatment_encoded          float64\n",
      "type_encoded               float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "oe = OrdinalEncoder(categories=[['Poor', 'Fair', 'Good','Very Good','Excellent']])\n",
    "X_train['cut_quality_encoded'] = oe.fit_transform(X_train[['cut_quality']])\n",
    "X_test['cut_quality_encoded'] = oe.transform(X_test[['cut_quality']])\n",
    "\n",
    "# Handle target\n",
    "type_mean = X_train.groupby('type')['price_per_carat'].mean()\n",
    "shape_means = X_train.groupby('shape')['price_per_carat'].mean()\n",
    "origin_means = X_train.groupby('origin')['price_per_carat'].mean()\n",
    "color_means = X_train.groupby('color')['price_per_carat'].mean()\n",
    "color_intensity_means = X_train.groupby('color_intensity')['price_per_carat'].mean()\n",
    "clarity_means = X_train.groupby('clarity')['price_per_carat'].mean()\n",
    "treatment_means = X_train.groupby('treatment')['price_per_carat'].mean()\n",
    "cut_means = X_train.groupby('cut')['price_per_carat'].mean()\n",
    "\n",
    "# Map target encoding to the training data\n",
    "X_train['shape_encoded'] = X_train['shape'].map(shape_means)\n",
    "X_train['origin_encoded'] = X_train['origin'].map(origin_means)\n",
    "X_train['color_encoded'] = X_train['color'].map(color_means)\n",
    "X_train['color_intensity_encoded'] = X_train['color_intensity'].map(color_intensity_means)\n",
    "X_train['clarity_encoded'] = X_train['clarity'].map(clarity_means)\n",
    "X_train['cut_encoded'] = X_train['cut'].map(cut_means)\n",
    "X_train['treatment_encoded'] = X_train['treatment'].map(treatment_means)\n",
    "X_train['type_encoded'] = X_train['type'].map(type_mean)\n",
    "\n",
    "# Map target encoding to the test data\n",
    "# Handle unseen categories by filling with global mean\n",
    "global_mean = X_train['price_per_carat'].mean()\n",
    "X_test['shape_encoded'] = X_test['shape'].map(shape_means).fillna(global_mean)\n",
    "X_test['origin_encoded'] = X_test['origin'].map(origin_means).fillna(global_mean)\n",
    "X_test['color_encoded'] = X_test['color'].map(color_means).fillna(global_mean)\n",
    "X_test['color_intensity_encoded'] = X_test['color_intensity'].map(color_intensity_means).fillna(global_mean)\n",
    "X_test['clarity_encoded'] = X_test['clarity'].map(clarity_means).fillna(global_mean)\n",
    "X_test['cut_encoded'] = X_test['cut'].map(cut_means).fillna(global_mean)\n",
    "X_test['treatment_encoded'] = X_test['treatment'].map(treatment_means).fillna(global_mean)\n",
    "X_test['type_encoded'] = X_test['type'].map(type_mean).fillna(global_mean)\n",
    "\n",
    "X_train = X_train.drop(columns=['price_per_carat', 'color', 'shape', 'color_intensity', 'origin', 'cut', 'treatment', 'clarity','cut_quality','type'])\n",
    "X_test = X_test.drop(columns=['price_per_carat', 'color', 'shape', 'color_intensity', 'origin', 'cut', 'treatment', 'clarity','cut_quality','type'])\n",
    "print(X_train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Gradient Booster-------\n",
      "r2_score is 0.8336389660835266\n",
      "r2_score for training is 0.9866280555725098\n",
      "mean_squared_error is== 178383520.0\n",
      "root_mean_squared_error is== 13356.029350072573\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "import xgboost\n",
    "from sklearn.metrics import *\n",
    "model = XGBRegressor(\n",
    "    n_estimators=20,\n",
    "    random_state=42,\n",
    "    learning_rate=0.4\n",
    "    )\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "y_predict_train = model.predict(X_train)\n",
    "\n",
    "# Predicting the accuracy score for Gradient Booster\n",
    "score=r2_score(y_test, y_predict)\n",
    "score_train = r2_score(y_train, y_predict_train)\n",
    "print('-------Gradient Booster-------')\n",
    "print('r2_score is', score)\n",
    "print('r2_score for training is', score_train)\n",
    "print('mean_squared_error is==', mean_squared_error(y_test,y_predict))\n",
    "print('root_mean_squared_error is==',np.sqrt(mean_squared_error(y_test, y_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import TargetEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Define the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', TargetEncoder())\n",
    "    ])\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Predict on transformed data\\ny_pred = pipeline.predict(X_test)'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Categorical columns to target encode\n",
    "categorical_columns = ['shape', 'origin', 'color', 'color_intensity', 'clarity', 'cut', 'treatment', 'type', 'cut_quality']\n",
    "\n",
    "# Fit the TargetEncoder directly\n",
    "target_encoder = TargetEncoder(target_type='continuous')\n",
    "target_encoder.fit(X_train[categorical_columns], y=X_train['price_per_carat'])\n",
    "\n",
    "# Now create the preprocessing steps with the fitted encoder\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', target_encoder, categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with the preprocessor and model\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', XGBRegressor())\n",
    "])\n",
    "\n",
    "# Fit the pipeline:\n",
    "# Here, we use 'total_price' as the target for the model training\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# After fitting, you can transform your data and predict:\n",
    "X_train_transformed = pipeline.named_steps['preprocessor'].transform(X_train)\n",
    "X_test_transformed = pipeline.named_steps['preprocessor'].transform(X_test)\n",
    "\n",
    "\"\"\"# Predict on transformed data\n",
    "y_pred = pipeline.predict(X_test)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Categorical columns to target encode\n",
    "categorical_columns = ['shape', 'origin', 'color', 'color_intensity', 'clarity', 'cut', 'treatment', 'type', 'cut_quality']\n",
    "\n",
    "# Columns to keep (all columns except 'price_per_carat')\n",
    "all_columns = X_train.columns.tolist()\n",
    "columns_to_keep = [col for col in all_columns if col != 'price_per_carat']\n",
    "\n",
    "# Fit the TargetEncoder directly\n",
    "target_encoder = TargetEncoder(target_type='continuous')\n",
    "target_encoder.fit(X_train[categorical_columns], y=X_train['price_per_carat'])\n",
    "\n",
    "# Custom transformer to drop 'price_per_carat'\n",
    "class ColumnDropper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns_to_drop):\n",
    "        self.columns_to_drop = columns_to_drop\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.drop(columns=self.columns_to_drop)\n",
    "\n",
    "# Now create the preprocessing steps with the fitted encoder\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', target_encoder, categorical_columns)\n",
    "    ],\n",
    "    remainder='passthrough'  # Pass through all other columns not specified in transformers\n",
    ")\n",
    "\n",
    "# Create a pipeline with the preprocessor and model\n",
    "pipeline = Pipeline([\n",
    "    ('drop_columns', ColumnDropper(columns_to_drop=['price_per_carat'])),  # Corrected here\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor())\n",
    "])\n",
    "\n",
    "# Fit the pipeline:\n",
    "# Here, we use 'total_price' as the target for the model training\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# After fitting, you can transform your data and predict:\n",
    "X_train_transformed = pipeline.named_steps['preprocessor'].transform(X_train)\n",
    "X_test_transformed = pipeline.named_steps['preprocessor'].transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 225357139.49700257\n",
      "R-squared Score: 0.7898311942857734\n",
      "\n",
      "Feature Importances:\n",
      "remainder__carat: 0.6768466730554533\n",
      "cat__cut_quality: 0.08375362835299761\n",
      "cat__origin: 0.05999553680432098\n",
      "cat__shape: 0.05577224384957885\n",
      "cat__color: 0.04515137948735051\n",
      "cat__treatment: 0.022432265729702867\n",
      "cat__type: 0.020827851591269538\n",
      "cat__clarity: 0.016079614011922906\n",
      "cat__color_intensity: 0.01036731246828619\n",
      "cat__cut: 0.0087734946491173\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline:\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "#rmse = mean_squared_error(y_test, y_pred, squared=False)  # Root Mean Squared Error\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "#print(f\"Root Mean Squared Error: {rmse}\")\n",
    "print(f\"R-squared Score: {r2}\")\n",
    "\n",
    "# If you want to see the feature importance from XGBoost (only after fitting)\n",
    "feature_importance = pipeline.named_steps['regressor'].feature_importances_\n",
    "feature_names = pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
    "\n",
    "# Combine feature names with their importance\n",
    "feature_importance_dict = dict(zip(feature_names, feature_importance))\n",
    "sorted_features = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nFeature Importances:\")\n",
    "for feature, importance in sorted_features[:10]:  # Print top 10 features\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
