{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "25218Fs7bmZ1",
        "outputId": "b42d996f-64fc-44a1-e60f-41cfd02bd88d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m226\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m58,112\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m131,584\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │        \u001b[38;5;34m525,312\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m524,800\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m131,328\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m32,896\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m8,256\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ clarity (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m260\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ color (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)             │          \u001b[38;5;34m1,820\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ cut (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │            \u001b[38;5;34m910\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">226</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">58,112</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ clarity (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ color (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,820</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ cut (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">910</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,415,278\u001b[0m (5.40 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,415,278</span> (5.40 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,415,278\u001b[0m (5.40 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,415,278</span> (5.40 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - clarity_accuracy: 0.4888 - clarity_loss: 1.0285 - color_accuracy: 0.3082 - color_loss: 2.0638 - cut_accuracy: 0.3673 - cut_loss: 1.5526 - loss: 4.6450 - val_clarity_accuracy: 0.6127 - val_clarity_loss: 0.7669 - val_color_accuracy: 0.3898 - val_color_loss: 1.5824 - val_cut_accuracy: 0.4172 - val_cut_loss: 1.3845 - val_loss: 3.7345\n",
            "Epoch 2/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 31ms/step - clarity_accuracy: 0.5999 - clarity_loss: 0.7873 - color_accuracy: 0.4004 - color_loss: 1.5878 - cut_accuracy: 0.4243 - cut_loss: 1.3694 - loss: 3.7445 - val_clarity_accuracy: 0.6300 - val_clarity_loss: 0.7467 - val_color_accuracy: 0.4021 - val_color_loss: 1.5211 - val_cut_accuracy: 0.4360 - val_cut_loss: 1.3566 - val_loss: 3.6252\n",
            "Epoch 3/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 28ms/step - clarity_accuracy: 0.6220 - clarity_loss: 0.7486 - color_accuracy: 0.4036 - color_loss: 1.4978 - cut_accuracy: 0.4247 - cut_loss: 1.3316 - loss: 3.5780 - val_clarity_accuracy: 0.6460 - val_clarity_loss: 0.7119 - val_color_accuracy: 0.4306 - val_color_loss: 1.4221 - val_cut_accuracy: 0.4103 - val_cut_loss: 1.3211 - val_loss: 3.4557\n",
            "Epoch 4/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 30ms/step - clarity_accuracy: 0.6497 - clarity_loss: 0.7212 - color_accuracy: 0.4193 - color_loss: 1.4323 - cut_accuracy: 0.4291 - cut_loss: 1.3041 - loss: 3.4576 - val_clarity_accuracy: 0.6390 - val_clarity_loss: 0.7228 - val_color_accuracy: 0.4233 - val_color_loss: 1.4184 - val_cut_accuracy: 0.4383 - val_cut_loss: 1.3133 - val_loss: 3.4553\n",
            "Epoch 5/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 28ms/step - clarity_accuracy: 0.6666 - clarity_loss: 0.6897 - color_accuracy: 0.4366 - color_loss: 1.4034 - cut_accuracy: 0.4589 - cut_loss: 1.2802 - loss: 3.3733 - val_clarity_accuracy: 0.6549 - val_clarity_loss: 0.6882 - val_color_accuracy: 0.4303 - val_color_loss: 1.4030 - val_cut_accuracy: 0.4425 - val_cut_loss: 1.2771 - val_loss: 3.3689\n",
            "Epoch 6/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 30ms/step - clarity_accuracy: 0.6747 - clarity_loss: 0.6720 - color_accuracy: 0.4415 - color_loss: 1.3725 - cut_accuracy: 0.4577 - cut_loss: 1.2477 - loss: 3.2922 - val_clarity_accuracy: 0.6819 - val_clarity_loss: 0.6558 - val_color_accuracy: 0.4397 - val_color_loss: 1.3680 - val_cut_accuracy: 0.4583 - val_cut_loss: 1.2534 - val_loss: 3.2778\n",
            "Epoch 7/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - clarity_accuracy: 0.7049 - clarity_loss: 0.6203 - color_accuracy: 0.4549 - color_loss: 1.3255 - cut_accuracy: 0.4695 - cut_loss: 1.2179 - loss: 3.1638 - val_clarity_accuracy: 0.6975 - val_clarity_loss: 0.6384 - val_color_accuracy: 0.4503 - val_color_loss: 1.3468 - val_cut_accuracy: 0.4760 - val_cut_loss: 1.2397 - val_loss: 3.2251\n",
            "Epoch 8/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 31ms/step - clarity_accuracy: 0.7132 - clarity_loss: 0.6121 - color_accuracy: 0.4581 - color_loss: 1.3258 - cut_accuracy: 0.4716 - cut_loss: 1.2115 - loss: 3.1494 - val_clarity_accuracy: 0.7094 - val_clarity_loss: 0.6227 - val_color_accuracy: 0.4617 - val_color_loss: 1.3388 - val_cut_accuracy: 0.4809 - val_cut_loss: 1.2348 - val_loss: 3.1970\n",
            "Epoch 9/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - clarity_accuracy: 0.7212 - clarity_loss: 0.5853 - color_accuracy: 0.4562 - color_loss: 1.2935 - cut_accuracy: 0.4808 - cut_loss: 1.1837 - loss: 3.0624 - val_clarity_accuracy: 0.7195 - val_clarity_loss: 0.5856 - val_color_accuracy: 0.4665 - val_color_loss: 1.2966 - val_cut_accuracy: 0.4882 - val_cut_loss: 1.1988 - val_loss: 3.0814\n",
            "Epoch 10/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - clarity_accuracy: 0.7406 - clarity_loss: 0.5551 - color_accuracy: 0.4658 - color_loss: 1.2657 - cut_accuracy: 0.4956 - cut_loss: 1.1588 - loss: 2.9796 - val_clarity_accuracy: 0.7255 - val_clarity_loss: 0.5672 - val_color_accuracy: 0.4598 - val_color_loss: 1.3016 - val_cut_accuracy: 0.4951 - val_cut_loss: 1.1926 - val_loss: 3.0621\n",
            "Epoch 11/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - clarity_accuracy: 0.7411 - clarity_loss: 0.5509 - color_accuracy: 0.4713 - color_loss: 1.2647 - cut_accuracy: 0.5018 - cut_loss: 1.1477 - loss: 2.9633 - val_clarity_accuracy: 0.7382 - val_clarity_loss: 0.5618 - val_color_accuracy: 0.4599 - val_color_loss: 1.3159 - val_cut_accuracy: 0.4990 - val_cut_loss: 1.1809 - val_loss: 3.0592\n",
            "Epoch 12/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 30ms/step - clarity_accuracy: 0.7547 - clarity_loss: 0.5243 - color_accuracy: 0.4765 - color_loss: 1.2262 - cut_accuracy: 0.5116 - cut_loss: 1.1176 - loss: 2.8681 - val_clarity_accuracy: 0.7452 - val_clarity_loss: 0.5500 - val_color_accuracy: 0.4631 - val_color_loss: 1.3197 - val_cut_accuracy: 0.4616 - val_cut_loss: 1.1748 - val_loss: 3.0451\n",
            "Epoch 13/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - clarity_accuracy: 0.7678 - clarity_loss: 0.5039 - color_accuracy: 0.4931 - color_loss: 1.2217 - cut_accuracy: 0.5098 - cut_loss: 1.1101 - loss: 2.8356 - val_clarity_accuracy: 0.7574 - val_clarity_loss: 0.5252 - val_color_accuracy: 0.4693 - val_color_loss: 1.2980 - val_cut_accuracy: 0.5009 - val_cut_loss: 1.1665 - val_loss: 2.9903\n",
            "Epoch 14/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - clarity_accuracy: 0.7865 - clarity_loss: 0.4686 - color_accuracy: 0.4886 - color_loss: 1.2152 - cut_accuracy: 0.5226 - cut_loss: 1.0813 - loss: 2.7650 - val_clarity_accuracy: 0.7654 - val_clarity_loss: 0.5266 - val_color_accuracy: 0.4835 - val_color_loss: 1.2771 - val_cut_accuracy: 0.5024 - val_cut_loss: 1.1568 - val_loss: 2.9612\n",
            "Epoch 15/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 30ms/step - clarity_accuracy: 0.7906 - clarity_loss: 0.4659 - color_accuracy: 0.4965 - color_loss: 1.1951 - cut_accuracy: 0.5393 - cut_loss: 1.0688 - loss: 2.7299 - val_clarity_accuracy: 0.7746 - val_clarity_loss: 0.5010 - val_color_accuracy: 0.4878 - val_color_loss: 1.2651 - val_cut_accuracy: 0.5179 - val_cut_loss: 1.1433 - val_loss: 2.9097\n",
            "Epoch 16/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - clarity_accuracy: 0.7909 - clarity_loss: 0.4601 - color_accuracy: 0.4995 - color_loss: 1.1759 - cut_accuracy: 0.5415 - cut_loss: 1.0616 - loss: 2.6976 - val_clarity_accuracy: 0.7724 - val_clarity_loss: 0.4939 - val_color_accuracy: 0.4833 - val_color_loss: 1.2590 - val_cut_accuracy: 0.5237 - val_cut_loss: 1.1234 - val_loss: 2.8767\n",
            "Epoch 17/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 30ms/step - clarity_accuracy: 0.8040 - clarity_loss: 0.4481 - color_accuracy: 0.5046 - color_loss: 1.1780 - cut_accuracy: 0.5403 - cut_loss: 1.0604 - loss: 2.6864 - val_clarity_accuracy: 0.7906 - val_clarity_loss: 0.4699 - val_color_accuracy: 0.4869 - val_color_loss: 1.2507 - val_cut_accuracy: 0.5155 - val_cut_loss: 1.1288 - val_loss: 2.8495\n",
            "Epoch 18/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 29ms/step - clarity_accuracy: 0.8060 - clarity_loss: 0.4267 - color_accuracy: 0.5131 - color_loss: 1.1583 - cut_accuracy: 0.5381 - cut_loss: 1.0565 - loss: 2.6415 - val_clarity_accuracy: 0.7927 - val_clarity_loss: 0.4778 - val_color_accuracy: 0.4879 - val_color_loss: 1.2504 - val_cut_accuracy: 0.5276 - val_cut_loss: 1.1271 - val_loss: 2.8556\n",
            "Epoch 19/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 30ms/step - clarity_accuracy: 0.8213 - clarity_loss: 0.4078 - color_accuracy: 0.5177 - color_loss: 1.1588 - cut_accuracy: 0.5555 - cut_loss: 1.0429 - loss: 2.6095 - val_clarity_accuracy: 0.7937 - val_clarity_loss: 0.4650 - val_color_accuracy: 0.4854 - val_color_loss: 1.2391 - val_cut_accuracy: 0.5229 - val_cut_loss: 1.1113 - val_loss: 2.8156\n",
            "Epoch 20/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - clarity_accuracy: 0.8222 - clarity_loss: 0.4071 - color_accuracy: 0.5149 - color_loss: 1.1533 - cut_accuracy: 0.5585 - cut_loss: 1.0338 - loss: 2.5943 - val_clarity_accuracy: 0.8012 - val_clarity_loss: 0.4518 - val_color_accuracy: 0.4976 - val_color_loss: 1.2289 - val_cut_accuracy: 0.5280 - val_cut_loss: 1.1056 - val_loss: 2.7869\n",
            "Epoch 21/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - clarity_accuracy: 0.8254 - clarity_loss: 0.3957 - color_accuracy: 0.5234 - color_loss: 1.1427 - cut_accuracy: 0.5510 - cut_loss: 1.0396 - loss: 2.5780 - val_clarity_accuracy: 0.7924 - val_clarity_loss: 0.4623 - val_color_accuracy: 0.4903 - val_color_loss: 1.2258 - val_cut_accuracy: 0.5284 - val_cut_loss: 1.1186 - val_loss: 2.8073\n",
            "Epoch 22/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - clarity_accuracy: 0.8386 - clarity_loss: 0.3758 - color_accuracy: 0.5225 - color_loss: 1.1242 - cut_accuracy: 0.5606 - cut_loss: 1.0081 - loss: 2.5081 - val_clarity_accuracy: 0.7989 - val_clarity_loss: 0.4534 - val_color_accuracy: 0.5042 - val_color_loss: 1.2537 - val_cut_accuracy: 0.5354 - val_cut_loss: 1.1152 - val_loss: 2.8228\n",
            "Epoch 23/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 29ms/step - clarity_accuracy: 0.8406 - clarity_loss: 0.3748 - color_accuracy: 0.5264 - color_loss: 1.1210 - cut_accuracy: 0.5619 - cut_loss: 1.0159 - loss: 2.5117 - val_clarity_accuracy: 0.8146 - val_clarity_loss: 0.4268 - val_color_accuracy: 0.5027 - val_color_loss: 1.2265 - val_cut_accuracy: 0.5438 - val_cut_loss: 1.0865 - val_loss: 2.7402\n",
            "Epoch 24/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - clarity_accuracy: 0.8425 - clarity_loss: 0.3682 - color_accuracy: 0.5381 - color_loss: 1.0974 - cut_accuracy: 0.5661 - cut_loss: 1.0037 - loss: 2.4692 - val_clarity_accuracy: 0.8217 - val_clarity_loss: 0.4198 - val_color_accuracy: 0.4961 - val_color_loss: 1.2339 - val_cut_accuracy: 0.5381 - val_cut_loss: 1.0956 - val_loss: 2.7498\n",
            "Epoch 25/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 31ms/step - clarity_accuracy: 0.8528 - clarity_loss: 0.3459 - color_accuracy: 0.5302 - color_loss: 1.0987 - cut_accuracy: 0.5814 - cut_loss: 0.9795 - loss: 2.4240 - val_clarity_accuracy: 0.8076 - val_clarity_loss: 0.4488 - val_color_accuracy: 0.5001 - val_color_loss: 1.2697 - val_cut_accuracy: 0.5359 - val_cut_loss: 1.1132 - val_loss: 2.8324\n",
            "Epoch 26/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 29ms/step - clarity_accuracy: 0.8542 - clarity_loss: 0.3453 - color_accuracy: 0.5460 - color_loss: 1.1115 - cut_accuracy: 0.5747 - cut_loss: 0.9959 - loss: 2.4527 - val_clarity_accuracy: 0.8189 - val_clarity_loss: 0.4308 - val_color_accuracy: 0.4984 - val_color_loss: 1.2340 - val_cut_accuracy: 0.5311 - val_cut_loss: 1.1109 - val_loss: 2.7757\n",
            "Epoch 27/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 32ms/step - clarity_accuracy: 0.8536 - clarity_loss: 0.3525 - color_accuracy: 0.5359 - color_loss: 1.1037 - cut_accuracy: 0.5725 - cut_loss: 0.9875 - loss: 2.4437 - val_clarity_accuracy: 0.8237 - val_clarity_loss: 0.4188 - val_color_accuracy: 0.4996 - val_color_loss: 1.2440 - val_cut_accuracy: 0.5322 - val_cut_loss: 1.1039 - val_loss: 2.7672\n",
            "Epoch 28/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 29ms/step - clarity_accuracy: 0.8577 - clarity_loss: 0.3379 - color_accuracy: 0.5435 - color_loss: 1.0941 - cut_accuracy: 0.5702 - cut_loss: 0.9902 - loss: 2.4222 - val_clarity_accuracy: 0.8387 - val_clarity_loss: 0.3905 - val_color_accuracy: 0.5031 - val_color_loss: 1.2160 - val_cut_accuracy: 0.5506 - val_cut_loss: 1.0855 - val_loss: 2.6920\n",
            "Epoch 29/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 31ms/step - clarity_accuracy: 0.8698 - clarity_loss: 0.3172 - color_accuracy: 0.5427 - color_loss: 1.0778 - cut_accuracy: 0.5780 - cut_loss: 0.9760 - loss: 2.3710 - val_clarity_accuracy: 0.8414 - val_clarity_loss: 0.3946 - val_color_accuracy: 0.5139 - val_color_loss: 1.2107 - val_cut_accuracy: 0.5490 - val_cut_loss: 1.0898 - val_loss: 2.6954\n",
            "Epoch 30/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 29ms/step - clarity_accuracy: 0.8718 - clarity_loss: 0.3192 - color_accuracy: 0.5539 - color_loss: 1.0780 - cut_accuracy: 0.5940 - cut_loss: 0.9685 - loss: 2.3657 - val_clarity_accuracy: 0.8339 - val_clarity_loss: 0.4146 - val_color_accuracy: 0.5083 - val_color_loss: 1.2259 - val_cut_accuracy: 0.5493 - val_cut_loss: 1.0994 - val_loss: 2.7403\n",
            "Epoch 31/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 30ms/step - clarity_accuracy: 0.8704 - clarity_loss: 0.3160 - color_accuracy: 0.5424 - color_loss: 1.0991 - cut_accuracy: 0.5914 - cut_loss: 0.9622 - loss: 2.3773 - val_clarity_accuracy: 0.8312 - val_clarity_loss: 0.4047 - val_color_accuracy: 0.5009 - val_color_loss: 1.2310 - val_cut_accuracy: 0.5323 - val_cut_loss: 1.0897 - val_loss: 2.7257\n",
            "Epoch 32/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 29ms/step - clarity_accuracy: 0.8804 - clarity_loss: 0.3000 - color_accuracy: 0.5571 - color_loss: 1.0705 - cut_accuracy: 0.5924 - cut_loss: 0.9596 - loss: 2.3302 - val_clarity_accuracy: 0.8341 - val_clarity_loss: 0.4063 - val_color_accuracy: 0.5121 - val_color_loss: 1.2241 - val_cut_accuracy: 0.5502 - val_cut_loss: 1.0852 - val_loss: 2.7156\n",
            "Epoch 33/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 29ms/step - clarity_accuracy: 0.8742 - clarity_loss: 0.3052 - color_accuracy: 0.5531 - color_loss: 1.0672 - cut_accuracy: 0.5979 - cut_loss: 0.9433 - loss: 2.3157 - val_clarity_accuracy: 0.8362 - val_clarity_loss: 0.4142 - val_color_accuracy: 0.5149 - val_color_loss: 1.2336 - val_cut_accuracy: 0.5492 - val_cut_loss: 1.0990 - val_loss: 2.7470\n",
            "Epoch 34/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 30ms/step - clarity_accuracy: 0.8808 - clarity_loss: 0.2957 - color_accuracy: 0.5541 - color_loss: 1.0712 - cut_accuracy: 0.5935 - cut_loss: 0.9459 - loss: 2.3128 - val_clarity_accuracy: 0.8393 - val_clarity_loss: 0.4161 - val_color_accuracy: 0.5003 - val_color_loss: 1.2405 - val_cut_accuracy: 0.5484 - val_cut_loss: 1.0965 - val_loss: 2.7537\n",
            "Epoch 35/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 29ms/step - clarity_accuracy: 0.8773 - clarity_loss: 0.2993 - color_accuracy: 0.5584 - color_loss: 1.0704 - cut_accuracy: 0.5927 - cut_loss: 0.9553 - loss: 2.3250 - val_clarity_accuracy: 0.8372 - val_clarity_loss: 0.4093 - val_color_accuracy: 0.5149 - val_color_loss: 1.2443 - val_cut_accuracy: 0.5511 - val_cut_loss: 1.1149 - val_loss: 2.7691\n",
            "Epoch 36/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - clarity_accuracy: 0.8870 - clarity_loss: 0.2857 - color_accuracy: 0.5628 - color_loss: 1.0501 - cut_accuracy: 0.6007 - cut_loss: 0.9503 - loss: 2.2861 - val_clarity_accuracy: 0.8374 - val_clarity_loss: 0.4010 - val_color_accuracy: 0.5112 - val_color_loss: 1.2306 - val_cut_accuracy: 0.5478 - val_cut_loss: 1.0882 - val_loss: 2.7205\n",
            "Epoch 37/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 31ms/step - clarity_accuracy: 0.8841 - clarity_loss: 0.2890 - color_accuracy: 0.5655 - color_loss: 1.0507 - cut_accuracy: 0.5960 - cut_loss: 0.9378 - loss: 2.2775 - val_clarity_accuracy: 0.8438 - val_clarity_loss: 0.3790 - val_color_accuracy: 0.5180 - val_color_loss: 1.2284 - val_cut_accuracy: 0.5556 - val_cut_loss: 1.0855 - val_loss: 2.6933\n",
            "Epoch 38/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 29ms/step - clarity_accuracy: 0.8929 - clarity_loss: 0.2745 - color_accuracy: 0.5733 - color_loss: 1.0302 - cut_accuracy: 0.6098 - cut_loss: 0.9385 - loss: 2.2432 - val_clarity_accuracy: 0.8377 - val_clarity_loss: 0.4179 - val_color_accuracy: 0.5071 - val_color_loss: 1.2509 - val_cut_accuracy: 0.5536 - val_cut_loss: 1.1096 - val_loss: 2.7789\n",
            "Epoch 39/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 31ms/step - clarity_accuracy: 0.8905 - clarity_loss: 0.2773 - color_accuracy: 0.5639 - color_loss: 1.0492 - cut_accuracy: 0.6136 - cut_loss: 0.9279 - loss: 2.2544 - val_clarity_accuracy: 0.8426 - val_clarity_loss: 0.3963 - val_color_accuracy: 0.5136 - val_color_loss: 1.2293 - val_cut_accuracy: 0.5562 - val_cut_loss: 1.0867 - val_loss: 2.7127\n",
            "Epoch 40/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 28ms/step - clarity_accuracy: 0.8915 - clarity_loss: 0.2742 - color_accuracy: 0.5630 - color_loss: 1.0530 - cut_accuracy: 0.6062 - cut_loss: 0.9374 - loss: 2.2646 - val_clarity_accuracy: 0.8374 - val_clarity_loss: 0.4053 - val_color_accuracy: 0.5095 - val_color_loss: 1.2558 - val_cut_accuracy: 0.5517 - val_cut_loss: 1.0945 - val_loss: 2.7562\n",
            "Epoch 41/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 31ms/step - clarity_accuracy: 0.8910 - clarity_loss: 0.2798 - color_accuracy: 0.5604 - color_loss: 1.0638 - cut_accuracy: 0.6031 - cut_loss: 0.9342 - loss: 2.2777 - val_clarity_accuracy: 0.8463 - val_clarity_loss: 0.3947 - val_color_accuracy: 0.5167 - val_color_loss: 1.2546 - val_cut_accuracy: 0.5590 - val_cut_loss: 1.0915 - val_loss: 2.7408\n",
            "Epoch 42/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 29ms/step - clarity_accuracy: 0.8947 - clarity_loss: 0.2727 - color_accuracy: 0.5710 - color_loss: 1.0492 - cut_accuracy: 0.6093 - cut_loss: 0.9372 - loss: 2.2592 - val_clarity_accuracy: 0.8503 - val_clarity_loss: 0.3865 - val_color_accuracy: 0.5177 - val_color_loss: 1.2561 - val_cut_accuracy: 0.5633 - val_cut_loss: 1.0898 - val_loss: 2.7327\n",
            "Epoch 43/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - clarity_accuracy: 0.9031 - clarity_loss: 0.2552 - color_accuracy: 0.5675 - color_loss: 1.0319 - cut_accuracy: 0.6171 - cut_loss: 0.9108 - loss: 2.1979 - val_clarity_accuracy: 0.8345 - val_clarity_loss: 0.4350 - val_color_accuracy: 0.5021 - val_color_loss: 1.2525 - val_cut_accuracy: 0.5419 - val_cut_loss: 1.1236 - val_loss: 2.8116\n",
            "Epoch 44/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 29ms/step - clarity_accuracy: 0.9019 - clarity_loss: 0.2557 - color_accuracy: 0.5803 - color_loss: 1.0357 - cut_accuracy: 0.6130 - cut_loss: 0.9237 - loss: 2.2151 - val_clarity_accuracy: 0.8458 - val_clarity_loss: 0.3850 - val_color_accuracy: 0.5198 - val_color_loss: 1.2369 - val_cut_accuracy: 0.5550 - val_cut_loss: 1.0768 - val_loss: 2.6993\n",
            "Epoch 45/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 31ms/step - clarity_accuracy: 0.8972 - clarity_loss: 0.2667 - color_accuracy: 0.5630 - color_loss: 1.0517 - cut_accuracy: 0.6024 - cut_loss: 0.9394 - loss: 2.2578 - val_clarity_accuracy: 0.8575 - val_clarity_loss: 0.3682 - val_color_accuracy: 0.5194 - val_color_loss: 1.2383 - val_cut_accuracy: 0.5597 - val_cut_loss: 1.0935 - val_loss: 2.7004\n",
            "Epoch 46/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 29ms/step - clarity_accuracy: 0.9067 - clarity_loss: 0.2475 - color_accuracy: 0.5661 - color_loss: 1.0427 - cut_accuracy: 0.6106 - cut_loss: 0.9276 - loss: 2.2179 - val_clarity_accuracy: 0.8534 - val_clarity_loss: 0.3596 - val_color_accuracy: 0.5200 - val_color_loss: 1.2404 - val_cut_accuracy: 0.5596 - val_cut_loss: 1.0712 - val_loss: 2.6715\n",
            "Epoch 47/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 32ms/step - clarity_accuracy: 0.9044 - clarity_loss: 0.2512 - color_accuracy: 0.5617 - color_loss: 1.0590 - cut_accuracy: 0.6088 - cut_loss: 0.9259 - loss: 2.2361 - val_clarity_accuracy: 0.8496 - val_clarity_loss: 0.3763 - val_color_accuracy: 0.5200 - val_color_loss: 1.2547 - val_cut_accuracy: 0.5614 - val_cut_loss: 1.0864 - val_loss: 2.7180\n",
            "Epoch 48/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 29ms/step - clarity_accuracy: 0.9101 - clarity_loss: 0.2389 - color_accuracy: 0.5781 - color_loss: 1.0270 - cut_accuracy: 0.6149 - cut_loss: 0.9165 - loss: 2.1824 - val_clarity_accuracy: 0.8564 - val_clarity_loss: 0.3680 - val_color_accuracy: 0.5191 - val_color_loss: 1.2595 - val_cut_accuracy: 0.5651 - val_cut_loss: 1.0963 - val_loss: 2.7242\n",
            "Epoch 49/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - clarity_accuracy: 0.9117 - clarity_loss: 0.2396 - color_accuracy: 0.5807 - color_loss: 1.0277 - cut_accuracy: 0.6167 - cut_loss: 0.9126 - loss: 2.1799 - val_clarity_accuracy: 0.8607 - val_clarity_loss: 0.3470 - val_color_accuracy: 0.5168 - val_color_loss: 1.2334 - val_cut_accuracy: 0.5620 - val_cut_loss: 1.0606 - val_loss: 2.6415\n",
            "Epoch 50/50\n",
            "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 29ms/step - clarity_accuracy: 0.9097 - clarity_loss: 0.2362 - color_accuracy: 0.5736 - color_loss: 1.0214 - cut_accuracy: 0.6200 - cut_loss: 0.8998 - loss: 2.1574 - val_clarity_accuracy: 0.8709 - val_clarity_loss: 0.3537 - val_color_accuracy: 0.5323 - val_color_loss: 1.2256 - val_cut_accuracy: 0.5594 - val_cut_loss: 1.0756 - val_loss: 2.6556\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clarity Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.81      0.81      1665\n",
            "           1       1.00      1.00      1.00      1708\n",
            "           2       0.90      0.96      0.93      1631\n",
            "           3       0.77      0.72      0.75      1710\n",
            "\n",
            "    accuracy                           0.87      6714\n",
            "   macro avg       0.87      0.87      0.87      6714\n",
            "weighted avg       0.87      0.87      0.87      6714\n",
            "\n",
            "Color Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.66      0.67       949\n",
            "           1       0.51      0.60      0.55       965\n",
            "           2       0.50      0.86      0.63       987\n",
            "           3       0.00      0.00      0.00      1001\n",
            "           4       0.52      0.91      0.66       972\n",
            "           5       0.64      0.25      0.36       482\n",
            "           7       0.00      0.00      0.00        24\n",
            "           8       0.22      0.09      0.12        23\n",
            "          10       0.00      0.00      0.00        31\n",
            "          11       0.54      0.41      0.46        91\n",
            "          12       0.53      0.63      0.58       265\n",
            "          13       0.00      0.00      0.00         8\n",
            "          14       0.25      0.06      0.10        77\n",
            "          15       1.00      0.06      0.11        50\n",
            "          16       0.61      0.39      0.47       109\n",
            "          17       0.00      0.00      0.00         5\n",
            "          18       0.00      0.00      0.00        71\n",
            "          19       0.00      0.00      0.00        22\n",
            "          20       0.43      0.69      0.53       172\n",
            "          21       0.00      0.00      0.00        22\n",
            "          22       0.00      0.00      0.00        16\n",
            "          23       0.83      0.54      0.66        70\n",
            "          24       0.52      0.53      0.53       219\n",
            "          25       0.00      0.00      0.00         8\n",
            "          26       0.49      0.27      0.35        62\n",
            "          27       0.00      0.00      0.00        13\n",
            "\n",
            "    accuracy                           0.54      6714\n",
            "   macro avg       0.32      0.27      0.26      6714\n",
            "weighted avg       0.46      0.54      0.47      6714\n",
            "\n",
            "Cut Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.48      0.53      1930\n",
            "           1       0.56      0.88      0.68      1944\n",
            "           2       0.00      0.00      0.00       440\n",
            "           3       0.73      0.15      0.25       216\n",
            "           4       0.00      0.00      0.00         8\n",
            "           5       0.00      0.00      0.00        11\n",
            "           7       0.61      0.63      0.62      1938\n",
            "           8       0.00      0.00      0.00        11\n",
            "           9       0.00      0.00      0.00        23\n",
            "          10       0.33      0.01      0.02       110\n",
            "          11       0.00      0.00      0.00         2\n",
            "          12       0.00      0.00      0.00        30\n",
            "          13       0.50      0.14      0.22        51\n",
            "\n",
            "    accuracy                           0.58      6714\n",
            "   macro avg       0.25      0.18      0.18      6714\n",
            "weighted avg       0.54      0.58      0.54      6714\n",
            "\n",
            "Model with increased layers saved successfully.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/Final_reverse_One_hot_encoded_Processed_data.csv\")\n",
        "\n",
        "# Identify target columns\n",
        "target_columns = ['clarity', 'color', 'cut']\n",
        "\n",
        "# Drop target columns to get feature set\n",
        "X = df.drop(columns=target_columns)\n",
        "\n",
        "# OneHotEncode target labels\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "y_clarity = encoder.fit_transform(df[[\"clarity\"]])\n",
        "y_color = encoder.fit_transform(df[[\"color\"]])\n",
        "y_cut = encoder.fit_transform(df[[\"cut\"]])\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_clarity_train, y_clarity_test, y_color_train, y_color_test, y_cut_train, y_cut_test = train_test_split(\n",
        "    X, y_clarity, y_color, y_cut, test_size=0.4, random_state=42\n",
        ")\n",
        "\n",
        "X_val, X_test, y_clarity_val, y_clarity_test, y_color_val, y_color_test, y_cut_val, y_cut_test = train_test_split(\n",
        "    X_test, y_clarity_test, y_color_test, y_cut_test, test_size=0.5, random_state=42\n",
        ")\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert labels to NumPy arrays\n",
        "Y_clarity_train_array = np.array(y_clarity_train)\n",
        "Y_color_train_array = np.array(y_color_train)\n",
        "Y_cut_train_array = np.array(y_cut_train)\n",
        "\n",
        "Y_clarity_val_array = np.array(y_clarity_val)\n",
        "Y_color_val_array = np.array(y_color_val)\n",
        "Y_cut_val_array = np.array(y_cut_val)\n",
        "\n",
        "Y_clarity_test_array = np.array(y_clarity_test)\n",
        "Y_color_test_array = np.array(y_color_test)\n",
        "Y_cut_test_array = np.array(y_cut_test)\n",
        "\n",
        "\n",
        "# Define the model with larger layers and added linear layers\n",
        "input_layer = keras.Input(shape=(X_train_scaled.shape[1],))\n",
        "\n",
        "\n",
        "# First linear layer before activation\n",
        "x = layers.Dense(256, activation=\"linear\")(input_layer)  # Linear transformation\n",
        "x = layers.Dense(512, activation=\"relu\")(x)  # Increased layer size\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Dense(1024, activation=\"relu\")(x)  # Larger hidden layer\n",
        "x = layers.Dense(512, activation=\"linear\")(x)  # Another linear transformation\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Dense(256, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Dense(128, activation=\"relu\")(x)\n",
        "# Add a 64-unit layer after the 128-unit layer\n",
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "\n",
        "\n",
        "\n",
        "# Output layers (remains the same)\n",
        "clarity_output = layers.Dense(Y_clarity_train_array.shape[1], activation=\"softmax\", name=\"clarity\")(x)\n",
        "color_output = layers.Dense(Y_color_train_array.shape[1], activation=\"softmax\", name=\"color\")(x)\n",
        "cut_output = layers.Dense(Y_cut_train_array.shape[1], activation=\"softmax\", name=\"cut\")(x)\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model = keras.Model(inputs=input_layer, outputs=[clarity_output, color_output, cut_output])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss={\n",
        "        'clarity': 'categorical_crossentropy',\n",
        "        'color': 'categorical_crossentropy',\n",
        "        'cut': 'categorical_crossentropy'\n",
        "    },\n",
        "    metrics={\n",
        "        'clarity': 'accuracy',\n",
        "        'color': 'accuracy',\n",
        "        'cut': 'accuracy'\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train_scaled,\n",
        "    {\"clarity\": Y_clarity_train_array, \"color\": Y_color_train_array, \"cut\": Y_cut_train_array},\n",
        "    validation_data=(X_val_scaled, {\"clarity\": Y_clarity_val_array, \"color\": Y_color_val_array, \"cut\": Y_cut_val_array}),\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "Y_test_pred = model.predict(X_test_scaled)\n",
        "Y_test_pred = [np.argmax(pred, axis=1) for pred in Y_test_pred]  # Convert probabilities to class labels\n",
        "\n",
        "# Convert one-hot test labels back to class labels\n",
        "Y_test_true = [\n",
        "    np.argmax(Y_clarity_test_array, axis=1),\n",
        "    np.argmax(Y_color_test_array, axis=1),\n",
        "    np.argmax(Y_cut_test_array, axis=1)\n",
        "]\n",
        "\n",
        "# Generate classification reports\n",
        "for i, name in enumerate([\"Clarity\", \"Color\", \"Cut\"]):\n",
        "    print(f\"{name} Classification Report:\\n\", classification_report(Y_test_true[i], Y_test_pred[i]))\n",
        "\n",
        "# Save the model\n",
        "model.save(\"DNN_gemstone_quality_model_large.h5\")\n",
        "print(\"Model with increased layers saved successfully.\")"
      ]
    }
  ]
}